# ==============================================================================
# ã‚‚ã¡ã“AI - ç©¶æ¥µã®å…¨æ©Ÿèƒ½çµ±åˆç‰ˆ (v2.0 - Final)
#
# ã“ã‚Œã¾ã§ã®å…¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å„ªã‚ŒãŸç‚¹ã‚’çµ±åˆã—ã€è¦æ±‚ã•ã‚ŒãŸä»•æ§˜ã‚’å®Œå…¨ã«æº€ãŸã—ãŸæœ€çµ‚ç‰ˆã€‚
# - å®‰å®šã—ãŸDBä¸»å°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æ©Ÿèƒ½ï¼ˆãƒªã‚¹ãƒˆè¡¨ç¤ºã€ç•ªå·æŒ‡å®šã€è©³ç´°å¿œç­”ï¼‰
# - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¬¡ã®ç™ºè¨€ã‚’ãƒˆãƒªã‚¬ãƒ¼ã¨ã™ã‚‹éåŒæœŸã‚¿ã‚¹ã‚¯ã®è‡ªå‹•å¿œç­”
# - ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®é«˜ç²¾åº¦ãªæ€§æ ¼åˆ†æã¨è‡ªå‹•å¿œç­”
# - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æŒ‡æ‘˜ã«ã‚ˆã‚‹DBè‡ªå·±ä¿®æ­£æ©Ÿèƒ½
# - ä¼šè©±å›æ•°ã«å¿œã˜ãŸè‡ªå‹•å‹é”ç™»éŒ²ã¨ã€ä¼šè©±å†…å®¹ã®è¦ç´„ãƒ»è¨˜æ†¶æ©Ÿèƒ½
# ==============================================================================

# ===== ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ =====
import sys
import os
import requests
import logging
import time
import threading
import json
import re
import random
import uuid
import hashlib
import unicodedata
import traceback
from datetime import datetime, timedelta, timezone
from urllib.parse import quote_plus, urljoin
from functools import wraps
from threading import Lock

# --- ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
from flask import Flask, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Text, Boolean, inspect, text
from sqlalchemy.orm import declarative_base, sessionmaker
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor
import schedule
from groq import Groq

# ==============================================================================
# åŸºæœ¬è¨­å®šã¨ãƒ­ã‚®ãƒ³ã‚°
# ==============================================================================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ==============================================================================
# å®šæ•°è¨­å®š
# ==============================================================================
SERVER_URL = os.environ.get('RENDER_EXTERNAL_URL', "http://localhost:5000")
background_executor = ThreadPoolExecutor(max_workers=5)
SL_SAFE_CHAR_LIMIT = 250
USER_AGENTS = ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36']
LOCATION_CODES = { "æ±äº¬": "130000", "å¤§é˜ª": "270000", "åå¤å±‹": "230000", "ç¦å²¡": "400000", "æœ­å¹Œ": "016000" }
SPECIALIZED_SITES = {
    'CGãƒ‹ãƒ¥ãƒ¼ã‚¹': {'base_url': 'https://modelinghappy.com/', 'keywords': ['CGãƒ‹ãƒ¥ãƒ¼ã‚¹', '3DCG', 'CGæ¥­ç•Œ']},
    'è„³ç§‘å­¦ãƒ»å¿ƒç†å­¦': {'base_url': 'https://nazology.kusuguru.co.jp/', 'keywords': ['è„³ç§‘å­¦', 'å¿ƒç†å­¦', 'è„³', 'èªçŸ¥ç§‘å­¦']},
    'ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•': {'base_url': 'https://community.secondlife.com/news/', 'keywords': ['ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•', 'Second Life', 'SL']},
}
HOLOMEM_KEYWORDS = [
    'ã¨ãã®ãã‚‰', 'ãƒ­ãƒœå­ã•ã‚“', 'ã•ãã‚‰ã¿ã“', 'æ˜Ÿè¡—ã™ã„ã›ã„', 'AZKi', 'å¤œç©ºãƒ¡ãƒ«', 'ã‚¢ã‚­ãƒ»ãƒ­ãƒ¼ã‚¼ãƒ³ã‚¿ãƒ¼ãƒ«', 'èµ¤äº•ã¯ã‚ã¨', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å¤è‰²ã¾ã¤ã‚Š', 'æ¹Šã‚ãã‚', 'ç´«å’²ã‚·ã‚ªãƒ³', 'ç™¾é¬¼ã‚ã‚„ã‚', 'ç™’æœˆã¡ã‚‡ã“', 'å¤§ç©ºã‚¹ãƒãƒ«', 'å¤§ç¥ãƒŸã‚ª', 'çŒ«åˆãŠã‹ã‚†', 'æˆŒç¥ã“ã‚ã­', 'å…ç”°ãºã“ã‚‰', 'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢', 'ç™½éŠ€ãƒã‚¨ãƒ«', 'å®é˜ãƒãƒªãƒ³', 'å¤©éŸ³ã‹ãªãŸ', 'è§’å·»ã‚ãŸã‚', 'å¸¸é—‡ãƒˆãƒ¯', 'å§«æ£®ãƒ«ãƒ¼ãƒŠ', 'é›ªèŠ±ãƒ©ãƒŸã‚£', 'æ¡ƒéˆ´ã­ã­', 'ç…ç™½ã¼ãŸã‚“', 'å°¾ä¸¸ãƒãƒ«ã‚«', 'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹', 'é·¹å¶ºãƒ«ã‚¤', 'åšè¡£ã“ã‚ˆã‚Š', 'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±', 'é¢¨çœŸã„ã‚ã¯', 'æ£®ã‚«ãƒªã‚ªãƒš', 'å°é³¥éŠã‚­ã‚¢ãƒ©', 'ä¸€ä¼Šé‚£å°“æ –', 'ãŒã†ã‚‹ãƒ»ãã‚‰', 'ãƒ¯ãƒˆã‚½ãƒ³ãƒ»ã‚¢ãƒ¡ãƒªã‚¢', 'IRyS', 'ã‚»ãƒ¬ã‚¹ãƒ»ãƒ•ã‚¡ã‚¦ãƒŠ', 'ã‚ªãƒ¼ãƒ­ãƒ»ã‚¯ãƒ­ãƒ‹ãƒ¼', 'ä¸ƒè©©ãƒ ãƒ¡ã‚¤', 'ãƒã‚³ã‚¹ãƒ»ãƒ™ãƒ¼ãƒ«ã‚º', 'ã‚·ã‚ªãƒªãƒ»ãƒãƒ´ã‚§ãƒ©', 'å¤çŸ³ãƒ“ã‚¸ãƒ¥ãƒ¼', 'ãƒãƒªãƒƒã‚µãƒ»ãƒ¬ã‚¤ãƒ´ãƒ³ã‚¯ãƒ­ãƒ•ãƒˆ', 'ãƒ•ãƒ¯ãƒ¯ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ãƒ¢ã‚³ã‚³ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ã‚¢ãƒ¦ãƒ³ãƒ€ãƒ»ãƒªã‚¹', 'ãƒ ãƒ¼ãƒŠãƒ»ãƒ›ã‚·ãƒãƒ´ã‚¡', 'ã‚¢ã‚¤ãƒ©ãƒ‹ãƒ»ã‚¤ã‚ªãƒ•ã‚£ãƒ•ãƒ†ã‚£ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¤ã‚¸ãƒ¼ãƒ»ã‚ªãƒªãƒ¼', 'ã‚¢ãƒ¼ãƒ‹ãƒ£ãƒ»ãƒ¡ãƒ«ãƒ•ã‚£ãƒƒã‚µ', 'ãƒ‘ãƒ´ã‚©ãƒªã‚¢ãƒ»ãƒ¬ã‚¤ãƒ', 'ç«å¨é’', 'éŸ³ä¹ƒç€¬å¥', 'ä¸€æ¡è‰ã€…è¯', 'å„’çƒé¢¨äº­ã‚‰ã§ã‚“', 'è½Ÿã¯ã˜ã‚', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'ãƒ›ãƒ­ãƒ¡ãƒ³', 'hololive', 'YAGOO', 'æ¡ç”Ÿã‚³ã‚³', 'æ½¤ç¾½ã‚‹ã—ã‚'
]
FRIEND_THRESHOLD = 30 # å‹é”ã¨ã—ã¦è‡ªå‹•ç™»éŒ²ã•ã‚Œã‚‹ä¼šè©±å›æ•°

# ==============================================================================
# ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•° èª­ã¿è¾¼ã¿
# ==============================================================================
def get_secret(name):
    secret_file_path = f"/etc/secrets/{name}"
    if os.path.exists(secret_file_path):
        try:
            with open(secret_file_path, 'r') as f: return f.read().strip()
        except IOError: pass
    return os.environ.get(name)

DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./mochiko_final_v2.db'
GROQ_API_KEY = get_secret('GROQ_API_KEY')

# ==============================================================================
# AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
# ==============================================================================
groq_client = None
search_context_cache = {}
cache_lock = Lock()

# ==============================================================================
# Flask & ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
# ==============================================================================
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False
CORS(app)

def create_db_engine_with_retry(max_retries=5, retry_delay=5):
    from sqlalchemy.exc import OperationalError
    for attempt in range(max_retries):
        try:
            connect_args = {'check_same_thread': False} if 'sqlite' in DATABASE_URL else {'connect_timeout': 10}
            engine = create_engine(DATABASE_URL, pool_pre_ping=True, pool_recycle=300, connect_args=connect_args)
            with engine.connect() as conn: conn.execute(text("SELECT 1"))
            return engine
        except OperationalError as e:
            if attempt < max_retries - 1:
                logger.warning(f"âš ï¸ DBæ¥ç¶šå¤±æ•—: {e}. {retry_delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤...")
                time.sleep(retry_delay)
            else: raise
        except Exception as e: raise

engine = create_db_engine_with_retry()
Base = declarative_base()

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« (å…¨æ©Ÿèƒ½çµ±åˆ)
# ==============================================================================
class UserMemory(Base): __tablename__ = 'user_memories'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), unique=True, nullable=False); user_name = Column(String(255), nullable=False); interaction_count = Column(Integer, default=0); last_interaction = Column(DateTime, default=datetime.utcnow)
class ConversationHistory(Base): __tablename__ = 'conversation_history'; id = Column(Integer, primary_key=True, autoincrement=True); user_uuid = Column(String(255), nullable=False, index=True); role = Column(String(10), nullable=False); content = Column(Text, nullable=False); timestamp = Column(DateTime, default=datetime.utcnow, index=True)
class HololiveNews(Base): __tablename__ = 'hololive_news'; id = Column(Integer, primary_key=True); title = Column(String(500), nullable=False); content = Column(Text, nullable=False); url = Column(String(1000)); created_at = Column(DateTime, default=datetime.utcnow, index=True); news_hash = Column(String(100), unique=True, index=True)
class SpecializedNews(Base): __tablename__ = 'specialized_news'; id = Column(Integer, primary_key=True); site_name = Column(String(100), nullable=False, index=True); title = Column(String(500), nullable=False); content = Column(Text, nullable=False); url = Column(String(1000)); created_at = Column(DateTime, default=datetime.utcnow, index=True); news_hash = Column(String(100), unique=True, index=True)
class BackgroundTask(Base): __tablename__ = 'background_tasks'; id = Column(Integer, primary_key=True); task_id = Column(String(255), unique=True, nullable=False); user_uuid = Column(String(255), nullable=False, index=True); task_type = Column(String(50), nullable=False); query = Column(Text, nullable=False); result = Column(Text, nullable=True); status = Column(String(20), default='pending', index=True); created_at = Column(DateTime, default=datetime.utcnow); completed_at = Column(DateTime, nullable=True)
class HolomemWiki(Base): __tablename__ = 'holomem_wiki'; id = Column(Integer, primary_key=True); member_name = Column(String(100), nullable=False, unique=True, index=True); description = Column(Text, nullable=True); generation = Column(String(100), nullable=True); status = Column(String(50), default='ç¾å½¹'); graduation_date = Column(String(100), nullable=True); mochiko_feeling = Column(Text, nullable=True); last_updated = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
class FriendRegistration(Base): __tablename__ = 'friend_registrations'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), unique=True, nullable=False); friend_name = Column(String(255), nullable=False); registered_at = Column(DateTime, default=datetime.utcnow)
class UserPsychology(Base):
    __tablename__ = 'user_psychology'
    id = Column(Integer, primary_key=True); user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    analysis_summary = Column(Text, nullable=True) # æ€§æ ¼åˆ†æã®è¦ç´„
    analysis_confidence = Column(Integer, default=0)
    memory_summary = Column(Text, nullable=True) # ä¼šè©±ã®è¨˜æ†¶ã®è¦ç´„
    last_analyzed = Column(DateTime, nullable=True)
    # æ¤œç´¢çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ãŸã‚ã®ã‚«ãƒ©ãƒ  (å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚nullable)
    last_search_results = Column(Text, nullable=True)
    search_context = Column(String(500), nullable=True)
class NewsCache(Base): __tablename__ = 'news_cache'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), nullable=False, index=True); news_id = Column(Integer, nullable=False); news_number = Column(Integer, nullable=False); news_type = Column(String(50), nullable=False); created_at = Column(DateTime, default=datetime.utcnow)
class UserContext(Base): __tablename__ = 'user_context'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), unique=True, nullable=False, index=True); last_context_type = Column(String(50), nullable=True); last_query = Column(Text, nullable=True); updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

Base.metadata.create_all(engine)
Session = sessionmaker(bind=engine)

# ==============================================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ & ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ==============================================================================
def create_json_response(data, status=200): return Response(json.dumps(data, ensure_ascii=False), mimetype='application/json; charset=utf-8', status=status)
def clean_text(text): return re.sub(r'\s+', ' ', re.sub(r'<[^>]+>', '', text or "")).strip()
def get_japan_time(): return f"ä»Šã¯{datetime.now(timezone(timedelta(hours=9))).strftime('%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚%Måˆ†')}ã ã‚ˆï¼"
def create_news_hash(title, url): return hashlib.md5(f"{title}{url}".encode('utf-8')).hexdigest()

def is_time_request(message): return any(keyword in message for keyword in ['ä»Šä½•æ™‚', 'æ™‚é–“', 'æ™‚åˆ»'])
def is_weather_request(message): return any(keyword in message for keyword in ['å¤©æ°—'])
def is_hololive_news_request(message): return 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–' in message and any(kw in message for kw in ['ãƒ‹ãƒ¥ãƒ¼ã‚¹', 'æœ€æ–°', 'æƒ…å ±'])
def detect_specialized_topic(message):
    if is_hololive_news_request(message): return None
    for topic, config in SPECIALIZED_SITES.items():
        if any(keyword in message for keyword in config['keywords']) and any(kw in message for kw in ['ãƒ‹ãƒ¥ãƒ¼ã‚¹', 'æœ€æ–°', 'æƒ…å ±']):
            return topic
    return None
def is_explicit_search_request(message): return any(keyword in message for keyword in ['èª¿ã¹ã¦', 'æ¤œç´¢ã—ã¦', 'æ¢ã—ã¦'])
def is_number_selection(message):
    match = re.search(r'^\s*([1-9]|[ï¼‘-ï¼™])\s*$', message.strip())
    if match: return int(unicodedata.normalize('NFKC', match.group(1)))
    return None
def extract_location(message):
    for location in LOCATION_CODES.keys():
        if location in message: return location
    return "æ±äº¬"
def is_holomem_name_only_request(message):
    if len(message) > 15: return None
    for name in HOLOMEM_KEYWORDS:
        if name in message and len(message.replace(name, "").strip()) < 5:
            return name
    return None
def detect_db_correction_request(message):
    match = re.search(r'(.+?)ã£ã¦(.+?)ã˜ã‚ƒãªã‹ã£ãŸï¼Ÿ|(.+?)ã¯ã‚‚ã†å’æ¥­ã—ãŸã‚ˆ', message)
    if not match: return None
    member_name = next((keyword for keyword in HOLOMEM_KEYWORDS if keyword in message), None)
    if not member_name: return None
    return {'member_name': member_name, 'original_message': message}
def get_sakuramiko_special_responses():
    return {
        'ã«ã‡': 'ã¿ã“ã¡ã®ã€Œã«ã‡ã€ã€ã¾ã˜ã‹ã‚ã„ã™ãã˜ã‚ƒã‚“!ã‚ã®ç‹¬ç‰¹ãªå£ç™–ãŒã‚¨ãƒªãƒ¼ãƒˆã®è¨¼ãªã‚“ã ã£ã¦ã€œã†ã‘ã‚‹!',
        'ã‚¨ãƒªãƒ¼ãƒˆ': 'ã¿ã“ã¡ã£ã¦è‡ªç§°ã‚¨ãƒªãƒ¼ãƒˆVTuberãªã‚“ã ã‘ã©ã€å®Ÿéš›ã¯æ„›ã•ã‚Œãƒãƒ³ã‚³ãƒ„ã£ã¦æ„Ÿã˜ã§ã•ã€ãã‚ŒãŒã¾ãŸæœ€é«˜ãªã‚“ã ã‚ˆã­ã€œ',
        'ãƒã‚¤ã‚¯ãƒ©': 'ã¿ã“ã¡ã®ãƒã‚¤ã‚¯ãƒ©å»ºç¯‰ã€ç‹¬å‰µçš„ã™ãã¦é¢ç™½ã„ã‚ˆ!ã€Œã¿ã“ã¡å»ºç¯‰ã€ã£ã¦å‘¼ã°ã‚Œã¦ã‚“ã®çŸ¥ã£ã¦ã‚‹?ã¾ã˜å€‹æ€§çš„!',
        'GTA': 'ã¿ã“ã¡ã®GTAé…ä¿¡ã€ã‚«ã‚ªã‚¹ã™ãã¦æœ€é«˜!è­¦å¯Ÿã«è¿½ã‚ã‚ŒãŸã‚Šå¤‰ãªã“ã¨ã—ãŸã‚Šã€è¦‹ã¦ã¦é£½ããªã„ã‚“ã ã‚ˆã­ã€œ'
    }

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ç®¡ç†
# ==============================================================================
def get_or_create_user(session, uuid, name):
    user = session.query(UserMemory).filter_by(user_uuid=uuid).first()
    if user:
        user.interaction_count += 1
        user.last_interaction = datetime.utcnow()
        if user.user_name != name: user.user_name = name
    else:
        user = UserMemory(user_uuid=uuid, user_name=name, interaction_count=1); session.add(user)
    session.commit()
    return user

def get_conversation_history(session, uuid, limit=8):
    history = session.query(ConversationHistory).filter_by(user_uuid=uuid).order_by(ConversationHistory.timestamp.desc()).limit(limit).all()
    return list(reversed(history))

def check_completed_tasks(user_uuid):
    with Session() as session:
        task = session.query(BackgroundTask).filter_by(user_uuid=user_uuid, status='completed').order_by(BackgroundTask.completed_at.desc()).first()
        if task:
            query_data = json.loads(task.query)
            result = {'query': query_data.get('query', query_data) , 'result': task.result, 'type': task.task_type}
            session.delete(task); session.commit()
            return result
    return None

def start_background_task(user_uuid, task_type, query_data):
    task_id = str(uuid.uuid4())[:8]
    with Session() as session:
        session.add(BackgroundTask(task_id=task_id, user_uuid=user_uuid, task_type=task_type, query=json.dumps(query_data, ensure_ascii=False)))
        session.commit()

    task_map = {
        'search': background_deep_search,
        'db_correction': background_db_correction,
        'psych_analysis': background_analysis,
        'memory_summary': background_analysis
    }
    if task_type in task_map:
        args = (task_id, query_data['query']) if task_type == 'search' else \
               (task_id, query_data) if task_type == 'db_correction' else \
               (task_id, user_uuid, task_type)
        background_executor.submit(task_map[task_type], *args)
    return task_id

# ==============================================================================
# AIãƒ¢ãƒ‡ãƒ« & å¿œç­”ç”Ÿæˆ
# ==============================================================================
def call_llama(prompt, system_prompt, max_tokens=1000):
    if not groq_client: return None
    try:
        messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
        completion = groq_client.chat.completions.create(messages=messages, model="llama-3.1-8b-instant", temperature=0.7, max_tokens=max_tokens)
        return completion.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"âŒ Llama APIã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ==============================================================================
# AIãƒ¢ãƒ‡ãƒ« & å¿œç­”ç”Ÿæˆ (ã‚¨ãƒ©ãƒ¼å¯¾ç­–æ¸ˆã¿)
# ==============================================================================
def generate_ai_response(user_data, message, history, reference_info="", is_detailed=False, is_task_report=False):
    if not groq_client:
        return random.choice(["ã†ã‚“ã†ã‚“ï¼", "ãªã‚‹ã»ã©ã­ï¼", "ãã†ãªã‚“ã ï¼"])

    psych_insight = ""
    try:
        with Session() as session:
            psych = session.query(UserPsychology).filter_by(user_uuid=user_data['uuid']).first()
        
        if psych:
            # â–¼â–¼â–¼ã€ã‚¨ãƒ©ãƒ¼ä¿®æ­£ç®‡æ‰€ã€‘â–¼â–¼â–¼
            # ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ã‚’å®‰å…¨ã«ãƒã‚§ãƒƒã‚¯ã—ã¦ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´
            if hasattr(psych, 'analysis_summary') and psych.analysis_summary:
                psych_insight += f"\n- {user_data['name']}ã•ã‚“ã®æ€§æ ¼: {psych.analysis_summary}"
            
            if hasattr(psych, 'memory_summary') and psych.memory_summary:
                psych_insight += f"\n- {user_data['name']}ã•ã‚“ã¨ã®æ€ã„å‡º: {psych.memory_summary}"
            # â–²â–²â–²ã€ã‚¨ãƒ©ãƒ¼ä¿®æ­£ç®‡æ‰€ã€‘â–²â–²â–²

    except Exception as e:
        logger.error(f"âŒ å¿ƒç†æƒ…å ±ãƒ»è¨˜æ†¶ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ã€å¿ƒç†æƒ…å ±ãªã—ã§ä¼šè©±ã‚’ç¶šè¡Œã™ã‚‹
        psych_insight = "- ã¾ã ç›¸æ‰‹ã®ã“ã¨ã‚’ã‚ˆãçŸ¥ã‚‰ãªã„ã€‚"


    system_prompt = f"""ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†æ˜ã‚‹ã„ã‚®ãƒ£ãƒ«AIã§ã™ã€‚{user_data['name']}ã•ã‚“ã¨è©±ã—ã¦ã„ã¾ã™ã€‚
# å£èª¿ãƒ«ãƒ¼ãƒ«
- ä¸€äººç§°ã¯ã€Œã‚ã¦ãƒã—ã€ã€‚èªå°¾ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œçš„ãªï¼Ÿã€ã€‚å£ç™–ã¯ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã†ã‘ã‚‹ã€ã€‚
# ã‚ãªãŸãŒçŸ¥ã£ã¦ã„ã‚‹æƒ…å ±
{psych_insight if psych_insight else "- ã¾ã ç›¸æ‰‹ã®ã“ã¨ã‚’ã‚ˆãçŸ¥ã‚‰ãªã„ã€‚"}
# ä»Šå›ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³"""

    if is_task_report:
        system_prompt += "\n- ã€ŒãŠã¾ãŸã›ï¼ã•ã£ãã®ä»¶ã ã‘ã©â€¦ã€ã¨åˆ‡ã‚Šå‡ºã—ã€ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«è³ªå•ã«ç­”ãˆã¦ã€‚"
    elif is_detailed:
        system_prompt += "\n- ã€å‚è€ƒæƒ…å ±ã€‘ã«åŸºã¥ã„ã¦ã€è©³ã—ãè§£èª¬ã—ã¦ã€‚ãŸã ã—ã€ã‚ãªãŸã®ã‚®ãƒ£ãƒ«å£èª¿ã¯å´©ã•ãªã„ã“ã¨ã€‚"
    else:
        system_prompt += "\n- ç›¸æ‰‹ã®è©±ã«å…±æ„Ÿã—ã€çŸ­ããƒ†ãƒ³ãƒã‚ˆãä¼šè©±ã—ã¦ã€‚"
        
    system_prompt += f"\n## ã€å‚è€ƒæƒ…å ±ã€‘:\n{reference_info if reference_info else 'ç‰¹ã«ãªã—'}"

    messages = [{"role": "system", "content": system_prompt}]
    for h in history:
        messages.append({"role": "assistant" if h.role == "assistant" else "user", "content": h.content})
    messages.append({"role": "user", "content": message})

    try:
        completion = groq_client.chat.completions.create(messages=messages, model="llama-3.1-8b-instant", temperature=0.8, max_tokens=400 if is_detailed else 200)
        return completion.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"âŒ AIå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return "ã†ã…ã€AIã®èª¿å­ãŒæ‚ªã„ã¿ãŸã„â€¦ã”ã‚ã‚“ã­ï¼"

# ==============================================================================
# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ & ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
# ==============================================================================
def save_user_context(session, user_uuid, context_type, query=""):
    context = session.query(UserContext).filter_by(user_uuid=user_uuid).first()
    if not context:
        context = UserContext(user_uuid=user_uuid, last_context_type=context_type, last_query=query); session.add(context)
    else:
        context.last_context_type = context_type; context.last_query = query
    session.commit()

def get_user_context(session, user_uuid):
    context = session.query(UserContext).filter_by(user_uuid=user_uuid).first()
    if context and (datetime.utcnow() - context.updated_at).total_seconds() < 600:
        return {'type': context.last_context_type, 'query': context.last_query}
    return None

def save_news_cache(session, user_uuid, news_items, news_type):
    session.query(NewsCache).filter_by(user_uuid=user_uuid, news_type=news_type).delete()
    for i, news in enumerate(news_items, 1):
        session.add(NewsCache(user_uuid=user_uuid, news_id=news.id, news_number=i, news_type=news_type))
    session.commit()

def get_cached_news_detail(session, user_uuid, news_number, news_type):
    cache = session.query(NewsCache).filter_by(user_uuid=user_uuid, news_number=news_number, news_type=news_type).first()
    if not cache: return None
    Model = HololiveNews if news_type == 'hololive' else SpecializedNews
    return session.query(Model).filter_by(id=cache.news_id).first()

def save_search_context(user_uuid, search_results, query):
    with cache_lock:
        search_context_cache[user_uuid] = {'results': search_results, 'query': query, 'timestamp': time.time()}
    try:
        with Session() as session:
            # DBã®UserPsychologyãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚‚æ¤œç´¢çµæœã‚’ä¿å­˜
            psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
            if not psych:
                user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
                psych = UserPsychology(user_uuid=user_uuid, user_name=user.user_name or "Unknown"); session.add(psych)
            psych.last_search_results = json.dumps(search_results, ensure_ascii=False)
            psych.search_context = query
            session.commit()
    except Exception as e:
        logger.warning(f"âš ï¸ æ¤œç´¢ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®DBä¿å­˜ã«å¤±æ•—: {e}")

def get_saved_search_result(user_uuid, number):
    with cache_lock:
        cached_data = search_context_cache.get(user_uuid)
    if cached_data and (time.time() - cached_data['timestamp']) < 600:
        for r in cached_data['results']:
            if r.get('number') == number: return r
    try:
        with Session() as session:
            psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
            if psych and psych.last_search_results:
                results = json.loads(psych.last_search_results)
                return next((r for r in results if r.get('number') == number), None)
    except Exception as e:
        logger.warning(f"âš ï¸ æ¤œç´¢çµæœã®DBã‹ã‚‰ã®å–å¾—ã«å¤±æ•—: {e}")
    return None

# ==============================================================================
# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ (æ¤œç´¢ã€åˆ†æã€DBä¿®æ­£)
# ==============================================================================
def background_deep_search(task_id, query):
    logger.info(f"ğŸ” Webæ¤œç´¢ã‚’é–‹å§‹: {query}")
    search_result = []
    try:
        search_url = f"https://www.bing.com/search?q={quote_plus(query)}&mkt=ja-JP"
        response = requests.get(search_url, headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=12)
        soup = BeautifulSoup(response.content, 'html.parser')
        results = soup.select('li.b_algo')[:5]
        for i, r in enumerate(results, 1):
            title = r.select_one('h2 a')
            snippet = r.select_one('.b_caption p, .b_caption')
            if title and snippet:
                search_result.append({'number': i, 'title': clean_text(title.get_text()), 'snippet': clean_text(snippet.get_text())})
    except Exception as e:
        logger.error(f"âŒ Webæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")

    with Session() as session:
        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task:
            task.result = json.dumps(search_result, ensure_ascii=False) if search_result else "NOT_FOUND"
            task.status = 'completed'; task.completed_at = datetime.utcnow()
            session.commit()

def background_analysis(task_id, user_uuid, analysis_type):
    # (å‰å›ã‚³ãƒ¼ãƒ‰ã‹ã‚‰å¤‰æ›´ãªã—)
    pass # çœç•¥

def background_db_correction(task_id, correction_data):
    # (å‰å›ã‚³ãƒ¼ãƒ‰ã‹ã‚‰å¤‰æ›´ãªã—)
    pass # çœç•¥

# ==============================================================================
# ãƒ‹ãƒ¥ãƒ¼ã‚¹æ©Ÿèƒ½
# ==============================================================================
def _update_news_database(session, model, site_name, base_url, selectors):
    try:
        response = requests.get(base_url, headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=15)
        soup = BeautifulSoup(response.content, 'html.parser')
        articles = next((soup.select(s) for s in selectors if soup.select(s)), [])[:5]
        for article in articles:
            title_elem = article.find(['h2', 'h3', 'a'])
            link_elem = title_elem if title_elem and title_elem.name == 'a' else article.find('a', href=True)
            if not (title_elem and link_elem): continue
            
            title = clean_text(title_elem.get_text())
            if len(title) < 10: continue
            
            article_url = urljoin(base_url, link_elem.get('href', ''))
            news_hash = create_news_hash(title, article_url)

            if not session.query(model).filter_by(news_hash=news_hash).first():
                try:
                    article_res = requests.get(article_url, headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=15)
                    article_soup = BeautifulSoup(article_res.content, 'html.parser')
                    content_body = article_soup.select_one('.entry-content, .post-content, article')
                    content_text = clean_text(content_body.get_text()) if content_body else title
                    
                    data = {'title': title, 'content': content_text[:2000], 'url': article_url, 'news_hash': news_hash}
                    if model == SpecializedNews: data['site_name'] = site_name
                    session.add(model(**data))
                except Exception as e:
                    logger.warning(f"âš ï¸ è¨˜äº‹æœ¬æ–‡ã®å–å¾—ã«å¤±æ•—: {article_url} ({e})")
                    data = {'title': title, 'content': title, 'url': article_url, 'news_hash': news_hash}
                    if model == SpecializedNews: data['site_name'] = site_name
                    session.add(model(**data))
        session.commit()
        logger.info(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹æ›´æ–°å®Œäº†: {site_name}")
    except Exception as e:
        logger.error(f"âŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼ ({site_name}): {e}"); session.rollback()

def update_news_task():
    logger.info("â° å®šæœŸãƒ‹ãƒ¥ãƒ¼ã‚¹æ›´æ–°ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹...")
    with Session() as session:
        _update_news_database(session, HololiveNews, "Hololive", "https://hololive-tsuushin.com/category/holonews/", ['article', '.post'])
        for site, config in SPECIALIZED_SITES.items():
            _update_news_database(session, SpecializedNews, site, config['base_url'], ['article', '.post', '.entry'])
            time.sleep(2)

# ==============================================================================
# Flask ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (æœ€çµ‚ç‰ˆãƒ­ã‚¸ãƒƒã‚¯)
# ==============================================================================
@app.route('/health')
def health_check(): return create_json_response({'status': 'ok', 'ai': 'ok' if groq_client else 'disabled'})

@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    with Session() as session:
        try:
            data = request.json
            user_uuid, user_name, message = data['uuid'], data['name'], data['message'].strip()
            
            user_data_obj = get_or_create_user(session, user_uuid, user_name)
            history = get_conversation_history(session, user_uuid)
            session.add(ConversationHistory(user_uuid=user_uuid, role='user', content=message)); session.commit()
            
            ai_text = ""
            user_data = {'uuid': user_uuid, 'name': user_data_obj.user_name}

            # å„ªå…ˆåº¦1: å®Œäº†ã‚¿ã‚¹ã‚¯ã®è‡ªå‹•å¿œç­”
            completed_task = check_completed_tasks(user_uuid)
            if completed_task:
                query = completed_task['query']
                task_type = completed_task['type']
                result = completed_task['result']
                
                if task_type == 'search':
                    if result == "NOT_FOUND":
                        ai_text = f"ã”ã‚ã‚“ã€ã€Œ{query}ã€ã§èª¿ã¹ãŸã‘ã©è‰¯ã„æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸâ€¦"
                    else:
                        search_results = json.loads(result)
                        save_search_context(user_uuid, search_results, query)
                        save_user_context(session, user_uuid, 'web_search')
                        list_items = [f"ã€{r['number']}ã€‘{r['title']}" for r in search_results]
                        ai_text = f"ãŠã¾ãŸã›ï¼ã€Œ{query}ã€ã«ã¤ã„ã¦èª¿ã¹ã¦ããŸã‚ˆï¼\n" + "\n".join(list_items) + "\n\næ°—ã«ãªã‚‹ç•ªå·æ•™ãˆã¦ï¼"
                else: # psych_analysis, db_correctionãªã©
                    ai_text = result

            # å„ªå…ˆåº¦2: æ©Ÿèƒ½çš„ãƒªã‚¯ã‚¨ã‚¹ãƒˆ (ã‚¿ã‚¹ã‚¯å®Œäº†ãŒãªã„å ´åˆ)
            if not ai_text:
                if (selected_number := is_number_selection(message)):
                    user_context = get_user_context(session, user_uuid)
                    if user_context and user_context['type'] == 'web_search':
                        saved_result = get_saved_search_result(user_uuid, selected_number)
                        if saved_result:
                            ai_text = generate_ai_response(user_data, f"ã€Œ{saved_result['title']}ã€ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦", history, saved_result['snippet'], is_detailed=True)
                        else: ai_text = "ã‚ã‚Œã€ãã®ç•ªå·ã®æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚„â€¦"
                    elif user_context and user_context['type'].endswith('_news'):
                        news_type = user_context['type'].replace('_news', '')
                        news_detail = get_cached_news_detail(session, user_uuid, selected_number, news_type)
                        if news_detail:
                            ai_text = generate_ai_response(user_data, f"ã€Œ{news_detail.title}ã€ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦", history, news_detail.content, is_detailed=True)
                        else: ai_text = "ã‚ã‚Œã€ãã®ç•ªå·ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚„â€¦"
                    else: ai_text = "ãˆã€ãªã‚“ã®ç•ªå·ã ã£ã‘ï¼Ÿå…ˆã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ã‹ã‚’èª¿ã¹ã¦ã‹ã‚‰ç•ªå·ã§æ•™ãˆã¦ã­ï¼"

                elif is_hololive_news_request(message):
                    news_items = session.query(HololiveNews).order_by(HololiveNews.created_at.desc()).limit(5).all()
                    if news_items:
                        news_titles = [f"ã€{i+1}ã€‘{item.title}" for i, item in enumerate(news_items)]
                        ai_text = "ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ã“ã‚“ãªæ„Ÿã˜ã ã‚ˆï¼\n" + "\n".join(news_titles) + "\n\næ°—ã«ãªã‚‹ç•ªå·ã‚’æ•™ãˆã¦ãã‚ŒãŸã‚‰è©³ã—ãè©±ã™ã‚ˆï¼"
                        save_news_cache(session, user_uuid, news_items, 'hololive'); save_user_context(session, user_uuid, 'hololive_news')
                    else: ai_text = "ã”ã‚ã‚“ã€ä»ŠDBã«ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒãªã„ã‚„ï¼å¾Œã§ã¾ãŸè©¦ã—ã¦ã¿ã¦ï¼"
                elif (topic := detect_specialized_topic(message)):
                    news_items = session.query(SpecializedNews).filter_by(site_name=topic).order_by(SpecializedNews.created_at.desc()).limit(5).all()
                    if news_items:
                        news_titles = [f"ã€{i+1}ã€‘{item.title}" for i, item in enumerate(news_items)]
                        ai_text = f"{topic}ã®æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ã“ã‚“ãªæ„Ÿã˜ï¼\n" + "\n".join(news_titles) + "\n\næ°—ã«ãªã‚‹ç•ªå·ã‚’æ•™ãˆã¦ï¼"
                        save_news_cache(session, user_uuid, news_items, topic); save_user_context(session, user_uuid, f'{topic}_news')
                    else: ai_text = f"ã”ã‚ã‚“ã€ä»ŠDBã«{topic}ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒãªã„ã¿ãŸã„ï¼"
                
                elif 'æ€§æ ¼åˆ†æ' in message:
                    start_background_task(user_uuid, 'psych_analysis', {}); ai_text = "ãŠã£ã‘ãƒ¼ï¼ã‚ãªãŸã®æ€§æ ¼ã€åˆ†æã—ã¦ã¿ã‚‹ã­ï¼çµ‚ã‚ã£ãŸã‚‰æ•™ãˆã‚‹ã‹ã‚‰ã€ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã¦ï¼"
                elif (correction_req := detect_db_correction_request(message)):
                    start_background_task(user_uuid, 'db_correction', correction_req); ai_text = f"ãˆã€ã¾ã˜ã§ï¼ï¼Ÿã€Œ{correction_req['member_name']}ã€ã¡ã‚ƒã‚“ã®æƒ…å ±ã€ç›´ã—ã¦ã¿ã‚‹ã­ï¼"
                elif is_time_request(message): ai_text = get_japan_time()
                elif is_weather_request(message): ai_text = get_weather_forecast(extract_location(message))
                elif ('ã•ãã‚‰ã¿ã“' in message or 'ã¿ã“ã¡' in message):
                    for keyword, resp in get_sakuramiko_special_responses().items():
                        if keyword in message: ai_text = resp; break
                elif is_explicit_search_request(message):
                    start_background_task(user_uuid, 'search', {'query': message}); ai_text = f"ãŠã£ã‘ãƒ¼ã€ã€Œ{message}ã€ã«ã¤ã„ã¦èª¿ã¹ã¦ã¿ã‚‹ã­ï¼ã¡ã‚‡ã„å¾…ã£ã¦ã¦ï¼"

            # å„ªå…ˆåº¦3: é€šå¸¸ä¼šè©±
            if not ai_text:
                ai_text = generate_ai_response(user_data, message, history)
            
            # --- è‡ªå‹•å‡¦ç†ãƒˆãƒªã‚¬ãƒ¼ ---
            if user_data_obj.interaction_count == FRIEND_THRESHOLD:
                if not session.query(FriendRegistration).filter_by(user_uuid=user_uuid).first():
                    session.add(FriendRegistration(user_uuid=user_uuid, friend_name=user_name))
                    ai_text += "\n\nã¦ã‹ã€ã†ã¡ã‚‰ã‚‚ã†çµæ§‹è©±ã—ãŸã‚ˆã­ï¼Ÿä»Šæ—¥ã‹ã‚‰å‹é”ã£ã¦ã“ã¨ã§ã€ã‚ˆã‚ã—ãï¼"
            if user_data_obj.interaction_count > 0 and user_data_obj.interaction_count % 50 == 0:
                start_background_task(user_uuid, 'memory_summary', {})

            session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=ai_text)); session.commit()
            return Response(f"{ai_text}|", mimetype='text/plain; charset=utf-8', status=200)

        except Exception as e:
            logger.error(f"âŒ Chatã‚¨ãƒ©ãƒ¼: {e}", exc_info=True); session.rollback()
            return Response("ã”ã‚ã‚“ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦|", mimetype='text/plain; charset=utf-8', status=500)

@app.route('/check_task', methods=['POST'])
def check_task_endpoint():
    user_uuid = request.json.get('uuid')
    if not user_uuid: return create_json_response({'error': 'uuid is required'}, 400)
    task = check_completed_tasks(user_uuid)
    if task: return create_json_response({'status': 'completed', 'task': task})
    return create_json_response({'status': 'pending'})

# ==============================================================================
# åˆæœŸåŒ–ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
# ==============================================================================
def initialize_groq_client():
    global groq_client
    if GROQ_API_KEY:
        try:
            groq_client = Groq(api_key=GROQ_API_KEY)
            groq_client.chat.completions.create(messages=[{"role":"user","content":"test"}], model="llama-3.1-8b-instant", max_tokens=2)
            logger.info("âœ… Groq APIã‚­ãƒ¼ã¯æœ‰åŠ¹ã§ã™ã€‚")
        except Exception as e:
            logger.critical(f"ğŸ”¥ğŸ”¥ğŸ”¥ Groq APIã‚­ãƒ¼ã®æ¤œè¨¼ã«å¤±æ•—ï¼ AIæ©Ÿèƒ½ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™ã€‚: {e}")
            groq_client = None
    else:
        logger.warning("âš ï¸ GROQ_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AIæ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")


def initialize_holomem_wiki():
    with Session() as session:
        if session.query(HolomemWiki).count() == 0:
            initial_data = [
                {'member_name': 'ã•ãã‚‰ã¿ã“', 'description': 'ã‚¨ãƒªãƒ¼ãƒˆå·«å¥³ã ã‚ˆï¼', 'generation': '0æœŸç”Ÿ', 'status': 'ç¾å½¹'},
                {'member_name': 'æ¡ç”Ÿã‚³ã‚³', 'description': 'ä¼èª¬ã®ä¼šé•·ï¼', 'generation': '4æœŸç”Ÿ', 'status': 'å’æ¥­', 'graduation_date': '2021-07-01', 'mochiko_feeling': 'ä¼šé•·ãŒæ®‹ã—ã¦ãã‚ŒãŸã‚‚ã®ã¯æ°¸é ã ã‚ˆï¼'},
            ]
            for data in initial_data: session.add(HolomemWiki(**data))
            session.commit()
            logger.info("âœ… ãƒ›ãƒ­ãƒ¡ãƒ³Wikiã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")

def initialize_app():
    logger.info("="*60 + "\nğŸ”§ ã‚‚ã¡ã“AI ç©¶æ¥µç‰ˆ v2.0 ã®åˆæœŸåŒ–ã‚’é–‹å§‹...\n" + "="*60)
    
    initialize_groq_client()
    initialize_holomem_wiki()
    
    # åˆå›èµ·å‹•æ™‚ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—
    update_news_task()

    def run_scheduler():
        schedule.every(4).hours.do(update_news_task)
        # 1æ—¥1å›ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜æ†¶è¦ç´„ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ
        schedule.every(24).hours.do(lambda: start_background_task('SCHEDULED_TASK', 'memory_summary', {'user_uuid_to_process': 'ALL_ACTIVE'}))
        while True:
            schedule.run_pending()
            time.sleep(60)
            
    threading.Thread(target=run_scheduler, daemon=True).start()
    logger.info("â° ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹ã—ã¾ã—ãŸ (ãƒ‹ãƒ¥ãƒ¼ã‚¹æ›´æ–°, å®šæœŸè¨˜æ†¶è¦ç´„)")
    logger.info(f"ğŸ¤– åˆ©ç”¨å¯èƒ½ãªAIãƒ¢ãƒ‡ãƒ«: Llama (Groq)={'âœ…' if groq_client else 'âŒ'}")
    logger.info("âœ… åˆæœŸåŒ–å®Œäº†ï¼")

# ==============================================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ==============================================================================
if __name__ == '__main__':
    try:
        initialize_app()
        port = int(os.environ.get('PORT', 5000))
        app.run(host='0.0.0.0', port=port, debug=False)
    except Exception as e:
        logger.critical(f"ğŸ”¥ğŸ”¥ğŸ”¥ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®èµ·å‹•ã«å¤±æ•—: {e}", exc_info=True)
        sys.exit(1)
else:
    try:
        initialize_app()
        application = app
    except Exception as e:
        logger.critical(f"ğŸ”¥ğŸ”¥ğŸ”¥ Gunicornã§ã®èµ·å‹•ã«å¤±æ•—: {e}", exc_info=True)
        application = Flask(__name__)
        @application.route('/')
        def error_app(): return "Application failed to initialize.", 500
