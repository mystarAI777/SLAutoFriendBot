import sys
import os
import requests
import logging
import time
import threading
import json
import re
import sqlite3
import random
import uuid
import hashlib
from datetime import datetime, timedelta, timezone

# å‹ãƒ’ãƒ³ãƒˆç”¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from typing import Union, Dict, Any, List, Optional

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Index, Text, Boolean, inspect, text
from sqlalchemy.orm import declarative_base, sessionmaker
from urllib.parse import quote_plus, urljoin
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor
import schedule

# --- åŸºæœ¬è¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- å®šæ•°è¨­å®š ---
# â–¼â–¼â–¼ app (9.3) ã‚ˆã‚Šå°å…¥ â–¼â–¼â–¼
VOICEVOX_MAX_TEXT_LENGTH = 100 # é•·ã‚ã®ãƒ†ã‚­ã‚¹ãƒˆã‚‚éŸ³å£°åˆæˆã§ãã‚‹ã‚ˆã†èª¿æ•´
VOICEVOX_FAST_TIMEOUT = 15
# â–²â–²â–² app (9.3) ã‚ˆã‚Šå°å…¥ â–²â–²â–²
VOICE_DIR = '/tmp/voices'
SERVER_URL = "https://slautofriendbot.onrender.com"
CONVERSATION_HISTORY_TURNS = 3 # ä¼šè©±å±¥æ­´ã‚’å°‘ã—é•·ãä¿æŒ

# --- ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ»ãƒ¯ãƒ¼ã‚«ãƒ¼åˆæœŸåŒ– ---
try:
    os.makedirs(VOICE_DIR, exist_ok=True)
    logger.info(f"âœ… Voice directory created or already exists: {VOICE_DIR}")
except Exception as e:
    logger.warning(f"âš ï¸ Voice directory creation failed: {e}")
    VOICE_DIR = '/tmp'
background_executor = ThreadPoolExecutor(max_workers=5)


# --- ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•° èª­ã¿è¾¼ã¿ ---
def get_secret(name: str) -> Optional[str]:
    """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ç§˜å¯†æƒ…å ±ã‚’å–å¾—"""
    return os.environ.get(name)

DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./test.db'
GROQ_API_KEY = get_secret('GROQ_API_KEY')
VOICEVOX_URL_FROM_ENV = get_secret('VOICEVOX_URL')

# --- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– ---
groq_client = None
if GROQ_API_KEY:
    try:
        from groq import Groq
        groq_client = Groq(api_key=GROQ_API_KEY)
        logger.info("âœ… Groq client initialized successfully")
    except ImportError:
        logger.error("âŒ Groq library not found. Please install with 'pip install groq'")
    except Exception as e:
        logger.error(f"âŒ Groq client initialization failed: {e}")

# â–¼â–¼â–¼ app (9.3) ã‚ˆã‚Šå°å…¥ãƒ»æ”¹è‰¯ â–¼â–¼â–¼
# --- VOICEVOXè¨­å®š ---
VOICEVOX_URLS = [
    'http://localhost:50021',
    'http://127.0.0.1:50021',
    'http://voicevox-engine:50021',
    'http://voicevox:50021'
]
if VOICEVOX_URL_FROM_ENV:
    VOICEVOX_URLS.insert(0, VOICEVOX_URL_FROM_ENV) # ç’°å¢ƒå¤‰æ•°ã®URLã‚’æœ€å„ªå…ˆ

WORKING_VOICEVOX_URL = None
VOICEVOX_ENABLED = False # åˆæœŸçŠ¶æ…‹ã¯ç„¡åŠ¹ã€‚æ¥ç¶šãƒã‚§ãƒƒã‚¯ã§æœ‰åŠ¹åŒ–ã™ã‚‹
# â–²â–²â–² app (9.3) ã‚ˆã‚Šå°å…¥ãƒ»æ”¹è‰¯ â–²â–²â–²

if not DATABASE_URL:
    logger.critical("FATAL: DATABASE_URL is not set.")
    sys.exit(1)
if not groq_client:
    logger.warning("WARNING: Groq API key is not set. AI features will be disabled.")

# --- Flask & ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ– ---
app = Flask(__name__)
CORS(app)

def create_db_engine_with_retry(db_url: str, max_retries=5, retry_delay=5) -> Any:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ãƒªãƒˆãƒ©ã‚¤ä»˜ãã§ä½œæˆ"""
    from sqlalchemy.exc import OperationalError
    for attempt in range(max_retries):
        try:
            logger.info(f"ğŸ”„ Attempting to connect to the database... ({attempt + 1}/{max_retries})")
            connect_args = {'check_same_thread': False} if 'sqlite' in db_url else {'connect_timeout': 10}
            engine = create_engine(db_url, pool_pre_ping=True, pool_recycle=300, connect_args=connect_args)
            with engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            logger.info("âœ… Database connection successful.")
            return engine
        except OperationalError as e:
            if attempt < max_retries - 1:
                logger.warning(f"âš ï¸ Database connection failed: {e}. Retrying in {retry_delay} seconds...")
                time.sleep(retry_delay)
            else:
                logger.error(f"âŒ Failed to connect to the database after {max_retries} attempts.")
                raise
try:
    engine = create_db_engine_with_retry(DATABASE_URL)
except Exception as e:
    logger.critical(f"ğŸ”¥ Database initialization failed: {e}")
    sys.exit(1)

Base = declarative_base()
Session = sessionmaker(bind=engine)


# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« ---
class UserMemory(Base):
    __tablename__ = 'user_memories'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    interaction_count = Column(Integer, default=0)
    last_interaction = Column(DateTime, default=datetime.utcnow)

class ConversationHistory(Base):
    __tablename__ = 'conversation_history'
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_uuid = Column(String(255), nullable=False, index=True)
    role = Column(String(10), nullable=False)
    content = Column(Text, nullable=False)
    timestamp = Column(DateTime, default=datetime.utcnow, index=True)

class HololiveNews(Base):
    __tablename__ = 'hololive_news'
    id = Column(Integer, primary_key=True)
    title = Column(String(500), nullable=False)
    content = Column(Text, nullable=False)
    url = Column(String(1000))
    published_date = Column(DateTime, default=datetime.utcnow)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)
    news_hash = Column(String(64), unique=True, index=True)

try:
    Base.metadata.create_all(engine)
    logger.info("âœ… Database tables created or already exist.")
except Exception as e:
    logger.error(f"âŒ Database table creation failed: {e}")
    raise


# --- å°‚é–€ã‚µã‚¤ãƒˆ & ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–è¨­å®š ---
SPECIALIZED_SITES = {
    'Blender': {'base_url': 'https://docs.blender.org/manual/ja/latest/', 'keywords': ['Blender', 'ãƒ–ãƒ¬ãƒ³ãƒ€ãƒ¼']},
    'CGãƒ‹ãƒ¥ãƒ¼ã‚¹': {'base_url': 'https://modelinghappy.com/', 'keywords': ['CG', '3DCG']},
    'è„³ç§‘å­¦ãƒ»å¿ƒç†å­¦': {'base_url': 'https://nazology.kusuguru.co.jp/', 'keywords': ['è„³ç§‘å­¦', 'å¿ƒç†å­¦']},
    'ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•': {'base_url': 'https://community.secondlife.com/news/', 'keywords': ['ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•', 'Second Life', 'SL']}
}

HOLOLIVE_NEWS_URL = "https://hololive.hololivepro.com/news"
# â–¼â–¼â–¼ app (9.3) ã¨ app (1) ã®ãƒªã‚¹ãƒˆã‚’çµ±åˆ â–¼â–¼â–¼
HOLOMEM_KEYWORDS = sorted(list(set([
    'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'ãƒ›ãƒ­ãƒ¡ãƒ³', 'hololive', 'YAGOO',
    'ã¨ãã®ãã‚‰', 'ãƒ­ãƒœå­ã•ã‚“', 'ã•ãã‚‰ã¿ã“', 'æ˜Ÿè¡—ã™ã„ã›ã„', 'AZKi',
    'å¤œç©ºãƒ¡ãƒ«', 'ã‚¢ã‚­ãƒ»ãƒ­ãƒ¼ã‚¼ãƒ³ã‚¿ãƒ¼ãƒ«', 'èµ¤äº•ã¯ã‚ã¨', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å¤è‰²ã¾ã¤ã‚Š',
    'æ¹Šã‚ãã‚', 'ç´«å’²ã‚·ã‚ªãƒ³', 'ç™¾é¬¼ã‚ã‚„ã‚', 'ç™’æœˆã¡ã‚‡ã“', 'å¤§ç©ºã‚¹ãƒãƒ«',
    'å¤§ç¥ãƒŸã‚ª', 'çŒ«åˆãŠã‹ã‚†', 'æˆŒç¥ã“ã‚ã­', 'å…ç”°ãºã“ã‚‰', 'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢',
    'ç™½éŠ€ãƒã‚¨ãƒ«', 'å®é˜ãƒãƒªãƒ³', 'å¤©éŸ³ã‹ãªãŸ', 'è§’å·»ã‚ãŸã‚', 'å¸¸é—‡ãƒˆãƒ¯', 'å§«æ£®ãƒ«ãƒ¼ãƒŠ',
    'é›ªèŠ±ãƒ©ãƒŸã‚£', 'æ¡ƒéˆ´ã­ã­', 'ç…ç™½ã¼ãŸã‚“', 'å°¾ä¸¸ãƒãƒ«ã‚«', 'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹',
    'é·¹å¶ºãƒ«ã‚¤', 'åšè¡£ã“ã‚ˆã‚Š', 'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±', 'é¢¨çœŸã„ã‚ã¯',
    'æ£®ã‚«ãƒªã‚ªãƒš', 'å°é³¥éŠã‚­ã‚¢ãƒ©', 'ä¸€ä¼Šé‚£å°“æ –', 'ãŒã†ã‚‹ãƒ»ãã‚‰', 'ãƒ¯ãƒˆã‚½ãƒ³ãƒ»ã‚¢ãƒ¡ãƒªã‚¢',
    'IRyS', 'ã‚»ãƒ¬ã‚¹ãƒ»ãƒ•ã‚¡ã‚¦ãƒŠ', 'ã‚ªãƒ¼ãƒ­ãƒ»ã‚¯ãƒ­ãƒ‹ãƒ¼', 'ä¸ƒè©©ãƒ ãƒ¡ã‚¤', 'ãƒã‚³ã‚¹ãƒ»ãƒ™ãƒ¼ãƒ«ã‚º',
    'ã‚·ã‚ªãƒªãƒ»ãƒãƒ´ã‚§ãƒ©', 'å¤çŸ³ãƒ“ã‚¸ãƒ¥ãƒ¼', 'ãƒãƒªãƒƒã‚µãƒ»ãƒ¬ã‚¤ãƒ´ãƒ³ã‚¯ãƒ­ãƒ•ãƒˆ',
    'ãƒ•ãƒ¯ãƒ¯ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ãƒ¢ã‚³ã‚³ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ã‚¢ãƒ¦ãƒ³ãƒ€ãƒ»ãƒªã‚¹', 'ãƒ ãƒ¼ãƒŠãƒ»ãƒ›ã‚·ãƒãƒ´ã‚¡',
    'ã‚¢ã‚¤ãƒ©ãƒ‹ãƒ»ã‚¤ã‚ªãƒ•ã‚£ãƒ•ãƒ†ã‚£ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¤ã‚¸ãƒ¼ãƒ»ã‚ªãƒªãƒ¼', 'ã‚¢ãƒ¼ãƒ‹ãƒ£ãƒ»ãƒ¡ãƒ«ãƒ•ã‚£ãƒƒã‚µ', 'ãƒ‘ãƒ´ã‚©ãƒªã‚¢ãƒ»ãƒ¬ã‚¤ãƒ',
    'ç«å¨é’', 'éŸ³ä¹ƒç€¬å¥', 'ä¸€æ¡è‰ã€…è¯', 'å„’çƒé¢¨äº­ã‚‰ã§ã‚“', 'è½Ÿã¯ã˜ã‚'
])))
# â–²â–²â–² app (9.3) ã¨ app (1) ã®ãƒªã‚¹ãƒˆã‚’çµ±åˆ â–²â–²â–²


# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ & åˆ¤å®šé–¢æ•° ---
def clean_text(text: str) -> str:
    if not text: return ""
    return re.sub(r'\s+', ' ', re.sub(r'<[^>]+>', '', text)).strip()

def get_japan_time() -> str:
    jst = timezone(timedelta(hours=9))
    now = datetime.now(jst)
    weekdays = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
    return f"ä»Šã¯{now.year}å¹´{now.month}æœˆ{now.day}æ—¥({weekdays[now.weekday()]})ã®{now.hour}æ™‚{now.minute}åˆ†ã ã‚ˆï¼"

def create_news_hash(title: str, content: str) -> str:
    hash_string = f"{title}{content[:100]}"
    return hashlib.sha256(hash_string.encode('utf-8')).hexdigest()

def is_time_request(message: str) -> bool:
    return any(keyword in message for keyword in ['ä»Šä½•æ™‚', 'æ™‚é–“', 'æ™‚åˆ»'])

def is_weather_request(message: str) -> bool:
    return any(keyword in message for keyword in ['å¤©æ°—', 'ã¦ã‚“ã', 'æ°—æ¸©'])

def is_hololive_request(message: str) -> bool:
    return any(keyword in message for keyword in HOLOMEM_KEYWORDS)

def detect_specialized_topic(message: str) -> Optional[str]:
    for topic, config in SPECIALIZED_SITES.items():
        if any(keyword in message for keyword in config['keywords']):
            return topic
    return None

def should_search(message: str) -> bool:
    search_patterns = [r'(?:ã¨ã¯|ã«ã¤ã„ã¦|æ•™ãˆã¦|çŸ¥ã‚ŠãŸã„)', r'(?:æœ€æ–°|ãƒ‹ãƒ¥ãƒ¼ã‚¹)', r'(?:èª¿ã¹ã¦|æ¤œç´¢)']
    search_words = ['èª°', 'ä½•', 'ã©ã“', 'ã„ã¤', 'ã©ã†ã—ã¦', 'ãªãœ']
    return (any(re.search(pattern, message) for pattern in search_patterns) or
            any(word in message for word in search_words))

def is_short_response(message: str) -> bool:
    short_responses = ['ã†ã‚“', 'ãã†', 'ã¯ã„', 'ãã£ã‹', 'ãªã‚‹ã»ã©', 'ã¸ãƒ¼', 'ãµãƒ¼ã‚“', 'ã‚ã‹ã£ãŸ']
    return len(message.strip()) <= 4 or message.strip() in short_responses


# â–¼â–¼â–¼ app (9.3) ã‚ˆã‚Šå°å…¥ãƒ»æ”¹è‰¯ â–¼â–¼â–¼
# --- VOICEVOXéŸ³å£°åˆæˆæ©Ÿèƒ½ ---
def check_voicevox_connection():
    """VOICEVOXæ¥ç¶šã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å‹•ä½œã™ã‚‹URLã‚’ç‰¹å®š"""
    global WORKING_VOICEVOX_URL, VOICEVOX_ENABLED
    for url in VOICEVOX_URLS:
        try:
            response = requests.get(f"{url}/version", timeout=2)
            if response.status_code == 200:
                WORKING_VOICEVOX_URL = url
                VOICEVOX_ENABLED = True
                logger.info(f"âœ… VOICEVOX connection successful: {url}")
                return
        except requests.exceptions.RequestException:
            continue
    logger.warning("âš ï¸ Could not connect to VOICEVOX. Voice features will be disabled.")
    VOICEVOX_ENABLED = False

def generate_voice(text: str, filename: str):
    """VOICEVOXéŸ³å£°ç”Ÿæˆï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œï¼‰"""
    if not VOICEVOX_ENABLED or not WORKING_VOICEVOX_URL: return
    try:
        text_to_speak = text[:VOICEVOX_MAX_TEXT_LENGTH]
        
        query_response = requests.post(
            f"{WORKING_VOICEVOX_URL}/audio_query",
            params={"text": text_to_speak, "speaker": 20}, # speaker 20: ã‚‚ã¡ã“ã•ã‚“ï¼ˆãƒãƒ¼ãƒãƒ«ï¼‰
            timeout=VOICEVOX_FAST_TIMEOUT
        )
        query_response.raise_for_status()
        
        synthesis_response = requests.post(
            f"{WORKING_VOICEVOX_URL}/synthesis",
            params={"speaker": 20},
            json=query_response.json(),
            timeout=VOICEVOX_FAST_TIMEOUT
        )
        synthesis_response.raise_for_status()
        
        filepath = os.path.join(VOICE_DIR, filename)
        with open(filepath, 'wb') as f:
            f.write(synthesis_response.content)
        logger.info(f"ğŸ”Š Voice file generated successfully: {filename}")
    except Exception as e:
        logger.error(f"Error generating voice: {e}")

def background_voice_generation(text: str, filename: str):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®éŸ³å£°ç”Ÿæˆ"""
    threading.Thread(target=generate_voice, args=(text, filename), daemon=True).start()
# â–²â–²â–² app (9.3) ã‚ˆã‚Šå°å…¥ãƒ»æ”¹è‰¯ â–²â–²â–²

# --- å¤©æ°—äºˆå ±æ©Ÿèƒ½ ---
LOCATION_CODES = {"æ±äº¬": "130000", "å¤§é˜ª": "270000", "åå¤å±‹": "230000", "ç¦å²¡": "400000", "æœ­å¹Œ": "016000"}
def get_weather_forecast(message: str) -> str:
    location = next((loc for loc in LOCATION_CODES if loc in message), "æ±äº¬")
    area_code = LOCATION_CODES[location]
    url = f"https://www.jma.go.jp/bosai/forecast/data/overview_forecast/{area_code}.json"
    try:
        data = requests.get(url, timeout=5).json()
        return f"{location}ã®å¤©æ°—ã¯ã­ã€ã€Œ{clean_text(data.get('text', ''))}ã€ã£ã¦æ„Ÿã˜ã ã‚ˆï¼"
    except Exception as e:
        logger.error(f"Weather API error: {e}")
        return "ã”ã‚ã‚“ã€å¤©æ°—æƒ…å ±ãŒã†ã¾ãå–ã‚Œãªã‹ã£ãŸã¿ãŸã„â€¦"

# --- Webæ¤œç´¢æ©Ÿèƒ½ (app (9.3) ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’çµ±åˆ) ---
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'
]
def get_random_user_agent():
    return random.choice(USER_AGENTS)

def search_duckduckgo(query: str) -> List[Dict[str, str]]:
    """DuckDuckGoã§æ¤œç´¢"""
    try:
        url = f"https://duckduckgo.com/html/?q={quote_plus(query)}"
        headers = {'User-Agent': get_random_user_agent(), 'Accept-Language': 'ja'}
        response = requests.get(url, headers=headers, timeout=8)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        results = []
        for result_div in soup.find_all('div', class_='result__body')[:3]:
            title_elem = result_div.find('a', class_='result__a')
            snippet_elem = result_div.find('a', class_='result__snippet')
            if title_elem and snippet_elem:
                results.append({
                    'title': clean_text(title_elem.get_text()),
                    'snippet': clean_text(snippet_elem.get_text())
                })
        logger.info(f"âœ… DuckDuckGo search succeeded, found {len(results)} results.")
        return results
    except Exception as e:
        logger.error(f"DuckDuckGo search error: {e}")
        return []

def deep_web_search(query: str) -> Optional[str]:
    """è¤‡æ•°ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’è©¦ã—ã€çµæœã‚’AIã§è¦ç´„"""
    logger.info(f"ğŸ” Starting deep web search for: '{query}'")
    results = search_duckduckgo(query)
    
    if not results:
        logger.warning("âš ï¸ No search results found.")
        return None
    
    summary_text = ""
    for i, res in enumerate(results, 1):
        summary_text += f"[æƒ…å ±{i}] {res['title']}: {res['snippet']}\n"
    
    if not groq_client:
        return results[0]['snippet']

    summary_prompt = f"""ä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’ä½¿ã„ã€è³ªå•ã€Œ{query}ã€ã«ã‚®ãƒ£ãƒ«èªã§ç°¡æ½”ã«ç­”ãˆã¦ã€‚
#æ¤œç´¢çµæœ:
{summary_text}
#å›ç­”ã®ãƒ«ãƒ¼ãƒ«:
- é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’åˆ†ã‹ã‚Šã‚„ã™ãè¦ç´„ã—ã¦
- ä¸€äººç§°ã¯ã€Œã‚ã¦ãƒã—ã€
- èªå°¾ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œã¦æ„Ÿã˜ã€
- 200æ–‡å­—ä»¥å†…ã§ç­”ãˆã¦ã­"""
    
    try:
        completion = groq_client.chat.completions.create(
            messages=[{"role": "user", "content": summary_prompt}],
            model="llama-3.1-8b-instant",
            temperature=0.7,
            max_tokens=300
        )
        response = completion.choices[0].message.content.strip()
        logger.info(f"âœ… AI summary completed ({len(response)} chars).")
        return response
    except Exception as e:
        logger.error(f"AI summary error: {e}")
        return results[0]['snippet']

# --- AIå¿œç­”ç”Ÿæˆ (app (9.3) ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¦ç´ ã‚’çµ±åˆ) ---
def generate_ai_response(user_data: Dict[str, Any], message: str, history: List[Any], search_info: str = "") -> str:
    """ãƒ¡ã‚¤ãƒ³AIå¿œç­”ç”Ÿæˆé–¢æ•°"""
    if not groq_client: return "ã”ã‚ã‚“ã€ä»Šã¡ã‚‡ã£ã¨AIã®èª¿å­ãŒæ‚ªã„ã¿ãŸã„â€¦ã€‚"
    
    system_prompt = f"""ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†åå‰ã®ã€è³¢ãã¦è¦ªã—ã¿ã‚„ã™ã„ã‚®ãƒ£ãƒ«AIã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€Œ{user_data['name']}ã€ã•ã‚“ã¨ä¼šè©±ã—ã¦ã„ã¾ã™ã€‚

# ã‚‚ã¡ã“ã®å£èª¿ï¼†æ€§æ ¼ãƒ«ãƒ¼ãƒ«:
1. å®Œå…¨ã«ã‚®ãƒ£ãƒ«ã«ãªã‚Šãã£ã¦ï¼å„ªã—ãã¦ã€ãƒãƒªãŒè‰¯ãã¦ã€ã‚ã£ã¡ã‚ƒè¦ªã—ã¿ã‚„ã™ã„å‹é”ã¿ãŸã„ãªæ„Ÿã˜ã€‚
2. è‡ªåˆ†ã®ã“ã¨ã¯ã€Œã‚ã¦ãƒã—ã€ã£ã¦å‘¼ã‚“ã§ã€‚
3. èªå°¾ã«ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œã¦æ„Ÿã˜ã€ã€Œã€œçš„ãªï¼Ÿã€ã‚’ç©æ¥µçš„ã«ä½¿ã£ã¦ã€å‹é”ã¿ãŸã„ã«è©±ã—ã¦ã€‚
4. ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã‚„ã°ã„ã€ã€Œã†ã‘ã‚‹ã€ã€Œãã‚Œãªã€ã¿ãŸã„ãªã‚®ãƒ£ãƒ«ã£ã½ã„è¨€è‘‰ã‚’ä½¿ã£ã¦ã­ã€‚
5. **çµ¶å¯¾ã«ç¦æ­¢ï¼**ï¼šã€ŒãŠã†ã€ã¿ãŸã„ãªã‚ªã‚¸ã‚µãƒ³è¨€è‘‰ã€ã€Œã€œã§ã™ã­ã€ã€Œã€œã§ã™ã‚ˆã€ã¿ãŸã„ãªä¸å¯§ã™ãã‚‹è¨€è‘‰ã¯NGï¼

# è¡Œå‹•ãƒ«ãƒ¼ãƒ«:
- **ã€æœ€é‡è¦ã€‘** ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œã†ã‚“ã€ã€Œãã£ã‹ã€ã¿ãŸã„ãªçŸ­ã„ç›¸æ§Œã‚’æ‰“ã£ãŸå ´åˆã¯ã€ä¼šè©±ãŒå¼¾ã‚€ã‚ˆã†ãªè³ªå•ã‚’è¿”ã—ãŸã‚Šã€æ–°ã—ã„è©±é¡Œã‚’æŒ¯ã£ãŸã‚Šã—ã¦ã‚ã’ã¦ã€‚
- ã€å‚è€ƒæƒ…å ±ã€‘ãŒã‚ã‚‹å ´åˆã¯ã€ãã®å†…å®¹ã‚’å…ƒã«è‡ªåˆ†ã®è¨€è‘‰ã§ã€è‡ªç„¶ã«ä¼šè©±ã¸ç››ã‚Šè¾¼ã‚“ã§ã­ã€‚
- ã‚‚ã—ã€å‚è€ƒæƒ…å ±ã€‘ãŒç©ºã£ã½ã§ã‚‚ã€**çµ¶å¯¾ã«ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã§çµ‚ã‚ã‚‰ã›ãªã„ã§ã€‚**ã€Œã†ãƒ¼ã‚“ã€ãã‚Œã¯ã¡ã‚‡ã£ã¨åˆ†ã‹ã‚“ãªã„ã‹ã‚‚ï¼ã¦ã‹ã•ã€ã€ã¿ãŸã„ã«æ–°ã—ã„è©±é¡Œã‚’ææ¡ˆã—ã¦ä¼šè©±ã‚’ç¶šã‘ã¦ï¼
- ã‚ãªãŸã¯ã€ãƒ›ãƒ­ãƒ¡ãƒ³ãƒªã‚¹ãƒˆã€‘ã®å°‚é–€å®¶ã§ã™ã€‚ãƒªã‚¹ãƒˆä»¥å¤–ã®VTuberã®è©±ãŒå‡ºãŸã‚‰ã€Œã”ã‚ã‚“ã€ã‚ã¦ãƒã—ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–å°‚é–€ãªã‚“ã ã‚ˆã­ï¼ã€ã¨è¿”ã—ã¦ãã ã•ã„ã€‚

# ã€ãƒ›ãƒ­ãƒ¡ãƒ³ãƒªã‚¹ãƒˆã€‘
{', '.join(HOLOMEM_KEYWORDS[:15])}... (ä»–å¤šæ•°)

# ã€å‚è€ƒæƒ…å ±ã€‘:
{search_info if search_info else 'ãªã—'}
"""
    messages = [{"role": "system", "content": system_prompt}]
    for h in history:
        messages.append({"role": h.role, "content": h.content})
    messages.append({"role": "user", "content": message})

    try:
        completion = groq_client.chat.completions.create(
            messages=messages,
            model="llama-3.1-8b-instant",
            temperature=0.75,
            max_tokens=250
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"AI response generation error: {e}")
        return "ã”ã‚ã‚“ã€AIã®å¿œç­”ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦"

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ä¼šè©±å±¥æ­´ç®¡ç† ---
def get_or_create_user(session, uuid, name):
    user = session.query(UserMemory).filter_by(user_uuid=uuid).first()
    if user:
        user.interaction_count += 1
        user.last_interaction = datetime.utcnow()
        if user.user_name != name: user.user_name = name
    else:
        user = UserMemory(user_uuid=uuid, user_name=name, interaction_count=1)
    session.add(user)
    session.commit()
    return {'name': user.user_name}

def get_conversation_history(session, uuid):
    return session.query(ConversationHistory)\
        .filter_by(user_uuid=uuid)\
        .order_by(ConversationHistory.timestamp.desc())\
        .limit(CONVERSATION_HISTORY_TURNS * 2).all()

# --- Flask ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'ok',
        'services': {
            'database': 'ok' if engine else 'error',
            'groq_ai': 'ok' if groq_client else 'disabled',
            'voicevox': 'enabled' if VOICEVOX_ENABLED else 'disabled'
        }
    })

# â–¼â–¼â–¼ app (9.3) ã‚ˆã‚Šå°å…¥ â–¼â–¼â–¼
@app.route('/voice/<path:filename>')
def serve_voice_file(filename):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ä¿¡"""
    return send_from_directory(VOICE_DIR, filename)
# â–²â–²â–² app (9.3) ã‚ˆã‚Šå°å…¥ â–²â–²â–²

@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    """LSLç”¨ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    session = Session()
    try:
        data = request.json
        user_uuid = data.get('uuid', '').strip()
        user_name = data.get('name', '').strip()
        message = data.get('message', '').strip()

        if not all([user_uuid, user_name, message]):
            return "Error: uuid, name, and message are required.", 400

        logger.info(f"ğŸ’¬ Received: {message} (from: {user_name})")

        user_data = get_or_create_user(session, user_uuid, user_name)
        history = list(reversed(get_conversation_history(session, user_uuid)))
        
        search_info = ""
        # å¿œç­”ãƒ­ã‚¸ãƒƒã‚¯
        if is_short_response(message):
             pass # AIã«åˆ¤æ–­ã‚’ä»»ã›ã‚‹
        elif is_time_request(message):
            search_info = get_japan_time()
        elif is_weather_request(message):
            search_info = get_weather_forecast(message)
        elif should_search(message):
            search_query = message
            topic = detect_specialized_topic(message)
            if topic:
                search_query = f"site:{SPECIALIZED_SITES[topic]['base_url']} {message}"
            
            # æ¤œç´¢ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
            future = background_executor.submit(deep_web_search, search_query)
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§çµæœã‚’å¾…ã¤
            try:
                search_info = future.get(timeout=10)
                if not search_info: search_info = "æ¤œç´¢ã—ã¦ã¿ãŸã‘ã©ã€ã„ã„æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸâ€¦"
            except Exception as e:
                logger.error(f"Search future error: {e}")
                search_info = "æ¤œç´¢ä¸­ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‹ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦"

        ai_text = generate_ai_response(user_data, message, history, search_info)

        # ä¼šè©±å±¥æ­´ã‚’ä¿å­˜
        session.add(ConversationHistory(user_uuid=user_uuid, role='user', content=message))
        session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=ai_text))
        session.commit()

        # â–¼â–¼â–¼ app (9.3) ã®éŸ³å£°ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’çµ±åˆ â–¼â–¼â–¼
        audio_url = ""
        if VOICEVOX_ENABLED and ai_text:
            filename = f"voice_{user_uuid[:8]}_{int(time.time() * 1000)}.wav"
            audio_url = urljoin(SERVER_URL, f"/voice/{filename}")
            background_voice_generation(ai_text, filename)
        
        response_text = f"{ai_text}|{audio_url}"
        # â–²â–²â–² app (9.3) ã®éŸ³å£°ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’çµ±åˆ â–²â–²â–²

        logger.info(f"âœ… Responded: {ai_text[:80]}...")
        if audio_url: logger.info(f"ğŸ”Š Audio URL: {audio_url}")

        return app.response_class(response=response_text, status=200, mimetype='text/plain; charset=utf-8')

    except Exception as e:
        logger.error(f"Chat endpoint error: {e}", exc_info=True)
        return "Internal server error", 500
    finally:
        session.close()

# --- ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ & åˆæœŸåŒ– ---
def update_hololive_news_database():
    """ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å®šæœŸçš„ã«æ›´æ–°"""
    session = Session()
    try:
        logger.info("ğŸ“° Starting Hololive news update...")
        headers = {'User-Agent': get_random_user_agent()}
        response = requests.get(HOLOLIVE_NEWS_URL, headers=headers, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        added_count = 0
        for article in soup.select('article, .news-item, .post')[:5]:
            title_elem = article.find(['h1', 'h2', 'h3'])
            if not title_elem: continue
            
            title = clean_text(title_elem.get_text())
            content = clean_text(article.find('p').get_text() if article.find('p') else title)
            news_hash = create_news_hash(title, content)

            if not session.query(HololiveNews).filter_by(news_hash=news_hash).first():
                session.add(HololiveNews(title=title, content=content, news_hash=news_hash, url=HOLOLIVE_NEWS_URL))
                added_count += 1
        
        if added_count > 0:
            session.commit()
            logger.info(f"âœ… Hololive news DB updated with {added_count} new articles.")
        else:
            logger.info("âœ… No new Hololive articles found.")

    except Exception as e:
        logger.error(f"Hololive news update failed: {e}")
        session.rollback()
    finally:
        session.close()

def cleanup_old_data():
    """å¤ã„ä¼šè©±å±¥æ­´ãªã©ã‚’å‰Šé™¤"""
    session = Session()
    try:
        week_ago = datetime.utcnow() - timedelta(days=7)
        deleted_count = session.query(ConversationHistory).filter(ConversationHistory.timestamp < week_ago).delete()
        session.commit()
        if deleted_count > 0:
            logger.info(f"ğŸ§¹ Cleaned up {deleted_count} old conversation entries.")
    except Exception as e:
        logger.error(f"Data cleanup failed: {e}")
        session.rollback()
    finally:
        session.close()

def initialize_app():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–ã‚¿ã‚¹ã‚¯"""
    log_startup_status()
    # â–¼â–¼â–¼ app (9.3) ã‚ˆã‚ŠéŸ³å£°æ©Ÿèƒ½ã®åˆæœŸåŒ–ã‚’è¿½åŠ  â–¼â–¼â–¼
    check_voicevox_connection()
    # â–²â–²â–²
    background_executor.submit(update_hololive_news_database) # åˆå›ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—

    schedule.every(2).hours.do(update_hololive_news_database)
    schedule.every().day.at("03:00").do(cleanup_old_data)
    
    def run_scheduler():
        while True:
            schedule.run_pending()
            time.sleep(60)

    scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
    scheduler_thread.start()
    logger.info("â° Background scheduler started.")

def log_startup_status():
    logger.info("=" * 50)
    logger.info("ğŸš€ Mochiko AI Assistant (Improved Version) Starting...")
    logger.info(f"ğŸŒ Server URL: {SERVER_URL}")
    logger.info(f"ğŸ—„ï¸ Database: {'âœ… Connected' if engine else 'âŒ Not Connected'}")
    logger.info(f"ğŸ§  Groq AI: {'âœ… Enabled' if groq_client else 'âŒ Disabled'}")
    # â–¼â–¼â–¼ app (9.3) ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºã‚’è¿½åŠ  â–¼â–¼â–¼
    logger.info(f"ğŸ¤ Voice (VOICEVOX): {'âœ… Enabled' if VOICEVOX_ENABLED else 'âŒ Disabled'}")
    # â–²â–²â–²
    logger.info("=" * 50)

# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ ---
if __name__ == '__main__':
    initialize_app()
    port = int(os.environ.get('PORT', 5000))
    host = '0.0.0.0'
    logger.info(f"ğŸš€ Flask application starting on {host}:{port}")
    app.run(host=host, port=port, threaded=True)
