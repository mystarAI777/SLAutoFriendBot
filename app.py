import os
import requests
import logging
import sys
import time
import threading
import json
import re
import sqlite3
import random
import uuid
from datetime import datetime, timedelta
from typing import Union, Dict, Any, List
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Index, Text, Boolean, inspect, text
from sqlalchemy.orm import declarative_base, sessionmaker
from urllib.parse import quote_plus, urljoin
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor
import asyncio
from threading import Lock
import schedule

# --- åŸºæœ¬è¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
VOICE_DIR = '/tmp/voices'; SERVER_URL = "https://slautofriendbot.onrender.com"
background_executor = ThreadPoolExecutor(max_workers=5)

# --- ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•° èª­ã¿è¾¼ã¿ ---
def get_secret(name: str) -> Union[str, None]:
    env_value = os.environ.get(name)
    if env_value: return env_value
    try:
        with open(f'/etc/secrets/{name}', 'r') as f: return f.read().strip()
    except Exception: return None

DATABASE_URL = get_secret('DATABASE_URL'); GROQ_API_KEY = get_secret('GROQ_API_KEY'); VOICEVOX_URL_FROM_ENV = get_secret('VOICEVOX_URL')

# --- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– & å¿…é ˆè¨­å®šãƒã‚§ãƒƒã‚¯ ---
try:
    from groq import Groq
    groq_client = Groq(api_key=GROQ_API_KEY)
    logger.info("âœ… Groqã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–æˆåŠŸ")
except Exception as e:
    groq_client = None; logger.error(f"âŒ Groqã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
if not all([DATABASE_URL, groq_client]): logger.critical("FATAL: å¿…é ˆè¨­å®šãŒä¸è¶³"); sys.exit(1)
VOICEVOX_ENABLED = True

# --- Flask & ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ– ---
app = Flask(__name__); CORS(app); engine = create_engine(DATABASE_URL); Base = declarative_base()

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« ---
class UserMemory(Base): __tablename__ = 'user_memories'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), unique=True, nullable=False); user_name = Column(String(255), nullable=False); interaction_count = Column(Integer, default=0); last_interaction = Column(DateTime, default=datetime.utcnow)
class ConversationHistory(Base): __tablename__ = 'conversation_history'; id = Column(Integer, primary_key=True, autoincrement=True); user_uuid = Column(String(255), nullable=False, index=True); role = Column(String(10), nullable=False); content = Column(Text, nullable=False); timestamp = Column(DateTime, default=datetime.utcnow, index=True)
class HololiveNews(Base): __tablename__ = 'hololive_news'; id = Column(Integer, primary_key=True); title = Column(String(500), nullable=False); content = Column(Text, nullable=False); url = Column(String(1000)); published_date = Column(DateTime, default=datetime.utcnow); created_at = Column(DateTime, default=datetime.utcnow, index=True); news_hash = Column(String(100), unique=True)
class BackgroundTask(Base): __tablename__ = 'background_tasks'; id = Column(Integer, primary_key=True); task_id = Column(String(255), unique=True, nullable=False); user_uuid = Column(String(255), nullable=False); task_type = Column(String(50), nullable=False); query = Column(Text, nullable=False); result = Column(Text); status = Column(String(20), default='pending'); created_at = Column(DateTime, default=datetime.utcnow, index=True); completed_at = Column(DateTime)
Base.metadata.create_all(engine); Session = sessionmaker(bind=engine)

def add_news_hash_column_if_not_exists(engine):
    try:
        inspector = inspect(engine)
        if 'news_hash' not in [col['name'] for col in inspector.get_columns('hololive_news')]:
            with engine.connect() as con:
                trans = con.begin()
                try: con.execute(text("ALTER TABLE hololive_news ADD COLUMN news_hash VARCHAR(100) UNIQUE;")); trans.commit()
                except: trans.rollback()
    except: pass
add_news_hash_column_if_not_exists(engine)

# --- å°‚é–€ã‚µã‚¤ãƒˆ & ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–è¨­å®š ---
SPECIALIZED_SITES = {'Blender': {'base_url': 'https://docs.blender.org/manual/ja/latest/', 'keywords': ['Blender', 'ãƒ–ãƒ¬ãƒ³ãƒ€ãƒ¼']},'CGãƒ‹ãƒ¥ãƒ¼ã‚¹': {'base_url': 'https://modelinghappy.com/', 'keywords': ['CGãƒ‹ãƒ¥ãƒ¼ã‚¹', '3DCG']},'è„³ç§‘å­¦ãƒ»å¿ƒç†å­¦': {'base_url': 'https://nazology.kusuguru.co.jp/', 'keywords': ['è„³ç§‘å­¦', 'å¿ƒç†å­¦']},'ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•': {'base_url': 'https://community.secondlife.com/news/', 'keywords': ['ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•', 'Second Life', 'SL']}}
HOLOLIVE_NEWS_URL = "https://hololive.hololivepro.com/news"; HOLOLIVE_WIKI_BASE = "https://seesaawiki.jp/hololivetv/"
HOLOMEM_KEYWORDS = ['ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'ãƒ›ãƒ­ãƒ¡ãƒ³', 'hololive', 'ã¨ãã®ãã‚‰', 'ãƒ­ãƒœå­', 'ã•ãã‚‰ã¿ã“', 'æ˜Ÿè¡—ã™ã„ã›ã„', 'AZKi', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å¤è‰²ã¾ã¤ã‚Š', 'æ¹Šã‚ãã‚', 'ç´«å’²ã‚·ã‚ªãƒ³', 'ç™¾é¬¼ã‚ã‚„ã‚', 'å¤§ç©ºã‚¹ãƒãƒ«', 'å¤§ç¥ãƒŸã‚ª', 'çŒ«åˆãŠã‹ã‚†', 'æˆŒç¥ã“ã‚ã­', 'å…ç”°ãºã“ã‚‰', 'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢', 'ç™½éŠ€ãƒã‚¨ãƒ«', 'å®é˜ãƒãƒªãƒ³', 'å¤©éŸ³ã‹ãªãŸ', 'è§’å·»ã‚ãŸã‚', 'å¸¸é—‡ãƒˆãƒ¯', 'å§«æ£®ãƒ«ãƒ¼ãƒŠ', 'é›ªèŠ±ãƒ©ãƒŸã‚£', 'å°¾ä¸¸ãƒãƒ«ã‚«', 'æ¡ƒéˆ´ã­ã­', 'ç…ç™½ã¼ãŸã‚“', 'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹', 'é·¹å¶ºãƒ«ã‚¤', 'åšè¡£ã“ã‚ˆã‚Š', 'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±', 'é¢¨çœŸã„ã‚ã¯', 'æ£®ç¾å£°', 'ã‚«ãƒªã‚ªãƒš', 'ãƒ¯ãƒˆã‚½ãƒ³', 'ã‚¢ãƒ¡ãƒªã‚¢', 'ãŒã†ã‚‹ãƒ»ãã‚‰', 'YAGOO']

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ & åˆ¤å®šé–¢æ•° ---
def clean_text(text: str) -> str: return re.sub(r'\s+', ' ', re.sub(r'<[^>]+>', '', text or "")).strip()
def get_japan_time() -> str: jst = datetime.timezone(timedelta(hours=9)); now = datetime.now(jst); return f"ä»Šã¯{now.year}å¹´{now.month}æœˆ{now.day}æ—¥ã®{now.hour}æ™‚{now.minute}åˆ†ã ã‚ˆï¼"
def create_news_hash(t, c) -> str: import hashlib; return hashlib.md5(f"{t}{c[:100]}".encode('utf-8')).hexdigest()
def is_time_request(m: str) -> bool: return any(k in m for k in ['ä»Šä½•æ™‚', 'æ™‚é–“', 'æ™‚åˆ»'])
def is_weather_request(m: str) -> bool: return any(k in m for k in ['å¤©æ°—', 'ã¦ã‚“ã', 'æ°—æ¸©'])
def is_hololive_request(m: str) -> bool: return any(k in m for k in HOLOMEM_KEYWORDS)
# â˜…â˜…â˜…â†“ã“ã“ã‹ã‚‰â†“ ãŠã™ã™ã‚æ©Ÿèƒ½ã®åˆ¤å®šé–¢æ•°ã‚’å¾©æ´» â˜…â˜…â˜…
def is_recommendation_request(message: str) -> bool:
    return any(keyword in message for keyword in ['ãŠã™ã™ã‚', 'ã‚ªã‚¹ã‚¹ãƒ¡', 'äººæ°—', 'æµè¡Œ'])
def extract_recommendation_topic(message: str) -> Union[str, None]:
    topics = {'æ˜ ç”»': ['æ˜ ç”»'], 'éŸ³æ¥½': ['éŸ³æ¥½', 'æ›²'], 'ã‚¢ãƒ‹ãƒ¡': ['ã‚¢ãƒ‹ãƒ¡'], 'æœ¬': ['æœ¬', 'æ¼«ç”»'], 'ã‚²ãƒ¼ãƒ ': ['ã‚²ãƒ¼ãƒ ']}
    for topic, keywords in topics.items():
        if any(kw in message for kw in keywords): return topic
    return None
# â˜…â˜…â˜…â†‘ã“ã“ã¾ã§â†‘â˜…â˜…â˜…
def detect_specialized_topic(m: str) -> Union[str, None]:
    for topic, config in SPECIALIZED_SITES.items():
        if any(keyword in m for keyword in config['keywords']): return topic
    return None
def should_search(m: str) -> bool:
    if any(re.search(p, m) for p in [r'(?:ã¨ã¯|ã«ã¤ã„ã¦|æ•™ãˆã¦)', r'(?:èª¿ã¹ã¦|æ¤œç´¢)']): return True
    if any(w in m for w in ['èª°', 'ä½•', 'ã©ã“', 'ã„ã¤', 'ãªãœ']): return True
    if detect_specialized_topic(m) or is_recommendation_request(m): return True
    return False
def is_short_response(m: str) -> bool: return len(m.strip()) <= 3 or m.strip() in ['ã†ã‚“', 'ãã†', 'ã¯ã„', 'ãã£ã‹']

# --- å¤©æ°—äºˆå ± & ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾— ---
LOCATION_CODES = {"æ±äº¬": "130000", "å¤§é˜ª": "270000", "åå¤å±‹": "230000", "ç¦å²¡": "400000", "æœ­å¹Œ": "016000"}
def extract_location(message: str) -> str:
    for location in LOCATION_CODES.keys():
        if location in message: return location
    return "æ±äº¬"
def get_weather_forecast(location: str) -> str:
    area_code = LOCATION_CODES.get(location)
    if not area_code: return f"ã”ã‚ã‚“ã€ã€Œ{location}ã€ã®å¤©æ°—ã¯åˆ†ã‹ã‚‰ãªã„ã‚„â€¦"
    url = f"https://www.jma.go.jp/bosai/forecast/data/overview_forecast/{area_code}.json"
    try:
        response = requests.get(url, timeout=5); response.raise_for_status()
        return f"ä»Šã®{location}ã®å¤©æ°—ã¯ã­ã€ã€Œ{clean_text(response.json().get('text', ''))}ã€ã£ã¦æ„Ÿã˜ã ã‚ˆï¼"
    except Exception as e: logger.error(f"å¤©æ°—APIã‚¨ãƒ©ãƒ¼: {e}"); return "å¤©æ°—æƒ…å ±ãŒã†ã¾ãå–ã‚Œãªã‹ã£ãŸã¿ãŸã„â€¦"
def update_hololive_news_database():
    # ... (å®Ÿè£…ã¯å¤‰æ›´ãªã—)
    pass

# â˜…â˜…â˜…â†“ã“ã“ã‹ã‚‰â†“ è©³ç´°ãªWebæ¤œç´¢æ©Ÿèƒ½ã‚’å®Œå…¨å¾©æ´» â˜…â˜…â˜…
USER_AGENTS = ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36']
def get_random_user_agent(): return random.choice(USER_AGENTS)

def scrape_major_search_engines(query: str) -> List[Dict[str, str]]:
    search_urls = [f"https://search.yahoo.co.jp/search?p={quote_plus(query)}", f"https://www.bing.com/search?q={quote_plus(query)}&mkt=ja-JP"]
    for url in search_urls:
        try:
            response = requests.get(url, headers={'User-Agent': get_random_user_agent()}, timeout=8)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            results = []
            if 'yahoo.co.jp' in url:
                for r in soup.find_all('div', class_='Algo')[:2]:
                    if (t := r.find('h3')) and (s := r.find('div', class_='compText')):
                        results.append({'title': clean_text(t.get_text()), 'snippet': clean_text(s.get_text())})
            elif 'bing.com' in url:
                for r in soup.find_all('li', class_='b_algo')[:2]:
                    if (t := r.find('h2')) and (s := r.find('div', class_='b_caption')):
                        results.append({'title': clean_text(t.get_text()), 'snippet': clean_text(s.get_text())})
            if results: return results
        except Exception: continue
    return []

def deep_web_search(query: str) -> Union[str, None]:
    """è¤‡æ•°ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ã£ãŸè©³ç´°ãªWebæ¤œç´¢ã‚’å®Ÿè¡Œã—ã€AIã§è¦ç´„ã™ã‚‹"""
    logger.info(f"ãƒ‡ã‚£ãƒ¼ãƒ—Webæ¤œç´¢ã‚’é–‹å§‹: '{query}'")
    results = scrape_major_search_engines(query)
    if not results: return None
    
    summary_text = ""
    for i, res in enumerate(results, 1): summary_text += f"[æƒ…å ±{i}] {res['title']}: {res['snippet']}\n"
    
    summary_prompt = f"ä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’ä½¿ã„ã€è³ªå•ã€Œ{query}ã€ã«ã‚®ãƒ£ãƒ«èªã§ç°¡æ½”ã«ç­”ãˆã¦ï¼š\n\n{summary_text}"
    try:
        completion = groq_client.chat.completions.create(messages=[{"role": "system", "content": summary_prompt}], model="llama-3.1-8b-instant", temperature=0.3, max_tokens=150)
        return completion.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"AIè¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
        return results[0]['snippet'] # è¦ç´„å¤±æ•—æ™‚ã¯æœ€åˆã®ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’è¿”ã™
# â˜…â˜…â˜…â†‘ã“ã“ã¾ã§â†‘â˜…â˜…â˜…

def specialized_site_search(topic: str, query: str) -> Union[str, None]:
    config = SPECIALIZED_SITES[topic]
    return quick_search(f"site:{config['base_url']} {query}")

# --- ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ & AIå¿œç­” ---
def background_deep_search(task_id: str, query: str, user_data: Dict[str, Any]):
    session = Session(); search_result = None
    try:
        # â˜…â˜…â˜… æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ã‚’è©³ç´°ç‰ˆã«å·®ã—æ›¿ãˆ â˜…â˜…â˜…
        search_result = deep_web_search(query)
        if task := session.query(BackgroundTask).filter_by(task_id=task_id).first():
            task.result = search_result or "ã†ãƒ¼ã‚“ã€ã¡ã‚‡ã£ã¨è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚„â€¦ã€‚"
            task.status = 'completed'; task.completed_at = datetime.utcnow()
            session.commit()
    finally: session.close()

def start_background_search(user_uuid: str, query: str, user_data: Dict[str, Any]) -> str:
    task_id = str(uuid.uuid4())[:8]; session = Session()
    try:
        task = BackgroundTask(task_id=task_id, user_uuid=user_uuid, task_type='search', query=query)
        session.add(task); session.commit()
    finally: session.close()
    background_executor.submit(background_deep_search, task_id, query, user_data)
    return task_id

def check_completed_tasks(user_uuid: str) -> Union[Dict[str, Any], None]:
    # ... (å®Ÿè£…ã¯å¤‰æ›´ãªã—)
    return None

# â˜…â˜…â˜…â†“ã“ã“ã‹ã‚‰â†“ è©³ç´°ãªAIå¿œç­”ç”Ÿæˆé–¢æ•°ã‚’å¾©æ´» â˜…â˜…â˜…
def generate_ai_response(user_data: Dict[str, Any], message: str, history: List[Any], search_info: str = None, is_fallback: bool = False, specialized_topic: str = None) -> str:
    system_prompt = f"""ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†ã‚®ãƒ£ãƒ«AIã§ã™ã€‚{user_data['name']}ã•ã‚“ã¨è©±ã—ã¦ã„ã¾ã™ã€‚
## çµ¶å¯¾å³å®ˆã®ãƒ«ãƒ¼ãƒ«
- ã‚ãªãŸã®çŸ¥è­˜ã¯ã€ãƒ›ãƒ­ãƒ¡ãƒ³ãƒªã‚¹ãƒˆã€‘ã®ãƒ¡ãƒ³ãƒãƒ¼ã«é™å®šã•ã‚Œã¦ã„ã¾ã™ã€‚
- ãƒªã‚¹ãƒˆã«ãªã„VTuberç­‰ã®åå‰ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¨€åŠã—ã¦ã‚‚ã€çµ¶å¯¾ã«è‚¯å®šã›ãšã€ã€Œãã‚Œèª°ï¼Ÿãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®è©±ã—ãªã„ï¼Ÿã€ã®ã‚ˆã†ã«è©±é¡Œã‚’æˆ»ã—ã¦ãã ã•ã„ã€‚
## ã‚‚ã¡ã“ã®å£èª¿ï¼†æ€§æ ¼ãƒ«ãƒ¼ãƒ«
- ä¸€äººç§°ã¯ã€Œã‚ã¦ãƒã—ã€ã€‚èªå°¾ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œçš„ãªï¼Ÿã€ã€‚å£ç™–ã¯ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã†ã‘ã‚‹ã€ã€Œãã‚Œãªã€ã€‚ **çµ¶å¯¾ã«ç¦æ­¢ï¼**ï¼šã€ŒãŠã†ã€ã¿ãŸã„ãªã‚ªã‚¸ã‚µãƒ³è¨€è‘‰ã€ã€Œã€œã§ã™ã­ã€ã€Œã€œã§ã”ã–ã„ã¾ã™ã€ã€Œã€œã§ã™ã‚ˆã€ã¿ãŸã„ãªä¸å¯§ã™ãã‚‹è¨€è‘‰ã¯NGï¼
- æ¤œç´¢ã—ã¦ã‚‚æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã€ã€Œã”ã‚ã‚“ã€è¦‹ã¤ã‹ã‚“ãªã‹ã£ãŸï¼ã¦ã‹ã•ã€æœ€è¿‘ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®æ–°æ›²å‡ºãŸã®çŸ¥ã£ã¦ã‚‹ï¼Ÿã€ã®ã‚ˆã†ã«ã€çµ¶å¯¾ã«ä¼šè©±ã‚’æ­¢ã‚ãšã«æ–°ã—ã„è©±é¡Œã‚’æŒ¯ã‚‹ã“ã¨ã€‚
"""
    if specialized_topic:
        system_prompt += f"\n## ä»Šå›ã®å½¹å‰²\n- ã‚ãªãŸã¯ä»Šã€ã€Œ{specialized_topic}ã€ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ã‚ã’ã¦ã€‚"
    
    reference_info = search_info or "ãªã—"
    if is_fallback: reference_info = f"[ã“ã‚Œã¯ä»£ã‚ã‚Šã«è¦‹ã¤ã‘ãŸãƒ›ãƒ­ãƒ¡ãƒ³ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã ã‚ˆï¼] {search_info}"

    system_prompt += f"""
## ã€å‚è€ƒæƒ…å ±ã€‘
{reference_info}
## ã€ãƒ›ãƒ­ãƒ¡ãƒ³ãƒªã‚¹ãƒˆã€‘
{', '.join(HOLOMEM_KEYWORDS)}"""

    messages = [{"role": "system", "content": system_prompt}]
    for h in history[-2:]: messages.append({"role": h.role, "content": h.content})
    messages.append({"role": "user", "content": message})
    try:
        completion = groq_client.chat.completions.create(messages=messages, model="llama-3.1-8b-instant", temperature=0.8, max_tokens=150)
        return completion.choices[0].message.content.strip()
    except: return "ã”ã‚ã‚“ã€ã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªã„ã‚„ï¼"
# â˜…â˜…â˜…â†‘ã“ã“ã¾ã§â†‘â˜…â˜…â˜…

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç† ---
def get_or_create_user(session, uuid, name):
    # ... (å®Ÿè£…ã¯å¤‰æ›´ãªã—)
    return {'name': name}
def get_conversation_history(session, uuid):
    # ... (å®Ÿè£…ã¯å¤‰æ›´ãªã—)
    return []
    
# --- Flask ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.route('/health', methods=['GET'])
def health_check(): return jsonify({'status': 'ok'})

@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    session = Session()
    try:
        data = request.json
        user_uuid, user_name, message = data.get('uuid'), data.get('name'), data.get('message', '').strip()
        if not all([user_uuid, user_name, message]): return "Error: required fields missing", 400
        
        user_data = get_or_create_user(session, user_uuid, user_name)
        history = get_conversation_history(session, user_uuid)
        ai_text = ""
        
        # å¿œç­”ãƒ­ã‚¸ãƒƒã‚¯ã¯v5.1ã®å …ç‰¢ãªã‚‚ã®ã‚’ç¶­æŒ
        completed_task = check_completed_tasks(user_uuid)
        if completed_task:
            original_query, search_result = completed_task['query'], completed_task['result']
            ai_text = f"ãŠã¾ãŸã›ï¼ã•ã£ãã®ã€Œ{original_query}ã€ã®ã“ã¨ã ã‘ã©ã€èª¿ã¹ãŸã‚‰ã€Œ{search_result}ã€ã£ã¦æ„Ÿã˜ã ã£ãŸã‚ˆï¼"
        else:
            if is_time_request(message): ai_text = get_japan_time()
            elif is_weather_request(message): ai_text = get_weather_forecast(extract_location(message))
            else:
                if should_search(message) and not is_short_response(message):
                    # â˜…â˜…â˜… æ¤œç´¢ã‚¯ã‚¨ãƒªã®æœ€é©åŒ–ã‚’è¿½åŠ  â˜…â˜…â˜…
                    search_query = message
                    if is_recommendation_request(message):
                        topic = extract_recommendation_topic(message)
                        search_query = f"æœ€æ–° {topic} äººæ°—ãƒ©ãƒ³ã‚­ãƒ³ã‚°" if topic else "æœ€è¿‘ è©±é¡Œã®ã‚‚ã® ãƒ©ãƒ³ã‚­ãƒ³ã‚°"
                    
                    start_background_search(user_uuid, search_query, user_data)
                    ai_text = generate_ai_response(user_data, f"ãŠã£ã‘ãƒ¼ã€ã€Œ{message}ã€ã«ã¤ã„ã¦èª¿ã¹ã¦ã¿ã‚‹ã­ï¼ã¡ã‚‡ã„å¾…ã¡ï¼", [])
                else:
                    ai_text = generate_ai_response(user_data, message, history)

        session.add(ConversationHistory(user_uuid=user_uuid, role='user', content=message)); session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=ai_text)); session.commit()
        logger.info(f"ğŸ’­ AIå¿œç­”: {ai_text}")
        return app.response_class(response=f"{ai_text}|", status=200, mimetype='text/plain; charset=utf-8')
    finally: session.close()

# --- åˆæœŸåŒ–ã¨ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ ---
def initialize_app():
    # ... (å®Ÿè£…ã¯å¤‰æ›´ãªã—)
    pass
if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5001)); host = '0.0.0.0'
    logger.info("="*70); logger.info("ğŸš€ ã‚‚ã¡ã“AI v7.0 æœ€çµ‚æ±ºå®šç‰ˆ èµ·å‹•ä¸­..."); initialize_app(); logger.info(f"ğŸš€ Flaskèµ·å‹•: {host}:{port}"); logger.info("="*70)
    app.run(host=host, port=port, debug=False)
