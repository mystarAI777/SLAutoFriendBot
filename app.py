# ==============================================================================
# ã‚‚ã¡ã“AI - ç©¶æ¥µã®å…¨æ©Ÿèƒ½çµ±åˆç‰ˆ (v16.1 - Ultimate)
#
# ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ä»¥ä¸‹ã®å…¨ã¦ã®æ©Ÿèƒ½ã¨æ”¹å–„ç‚¹ã‚’ç¶²ç¾…ã—ã¦ã„ã¾ã™ã€‚
# - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰AI (Geminié«˜é€Ÿå¿œç­” + Llama é«˜ç²¾åº¦åˆ†æ)
# - è©³ç´°ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å¿ƒç†åˆ†æã¨ã€ãã‚Œã‚’æ´»ç”¨ã—ãŸãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºå¿œç­”
# - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®è‡ªå‹•æš—å·åŒ–ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ (GitHubé€£æº)
# - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æŒ‡æ‘˜ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿®æ­£æ©Ÿèƒ½
# - ã‚¢ãƒ‹ãƒ¡æ¤œç´¢ã€ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹/Wikiæ¤œç´¢æ©Ÿèƒ½
# - å’æ¥­ç”Ÿæƒ…å ± (ã‚‚ã¡ã“ã®æ°—æŒã¡ã‚’å«ã‚€) ã®ç®¡ç†
# - å®Œå…¨ãªUTF-8æ–‡å­—åŒ–ã‘å¯¾ç­–
# - LSLã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé€£æºç”¨ã®éåŒæœŸã‚¿ã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
# - ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã¨ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯å¯¾ç­–
# - å …ç‰¢ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã¨æ¥ç¶šãƒ—ãƒ¼ãƒ«
# - åŒ…æ‹¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨è©³ç´°ãªãƒ­ã‚®ãƒ³ã‚°
# - æ´—ç·´ã•ã‚ŒãŸå„ªå…ˆåº¦åˆ†å²ã«ã‚ˆã‚‹é«˜åº¦ãªä¼šè©±ãƒ­-ã‚¸ãƒƒã‚¯
# ==============================================================================

# ===== æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
import sys
import os
import requests
import logging
import time
import threading
import json
import re
import random
import uuid
import hashlib
import unicodedata
import traceback
from datetime import datetime, timedelta, timezone
from urllib.parse import quote_plus, urljoin
import subprocess
from functools import wraps
from threading import Lock
from concurrent.futures import ThreadPoolExecutor
from collections import OrderedDict
from contextlib import contextmanager
from pathlib import Path

# ===== ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
from flask import Flask, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Text, BigInteger, Boolean, inspect, text, pool
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy.exc import OperationalError
from bs4 import BeautifulSoup
import schedule
import google.generativeai as genai
from groq import Groq
from cryptography.fernet import Fernet

# ==============================================================================
# åŸºæœ¬è¨­å®šã¨ãƒ­ã‚®ãƒ³ã‚°
# ==============================================================================
log_file_path = '/tmp/mochiko.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(funcName)s] - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(log_file_path, encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ==============================================================================
# å®šæ•°è¨­å®š
# ==============================================================================
VOICE_DIR = '/tmp/voices'
BACKUP_DIR = '/tmp/db_backups'
GITHUB_BACKUP_FILE = 'database_backup.json.encrypted'
SERVER_URL = os.environ.get('RENDER_EXTERNAL_URL', "http://localhost:5000")
VOICEVOX_SPEAKER_ID = 20
SL_SAFE_CHAR_LIMIT = 250
MIN_MESSAGES_FOR_ANALYSIS = 10
SEARCH_TIMEOUT = 10

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]
LOCATION_CODES = {"æ±äº¬": "130000", "å¤§é˜ª": "270000", "åå¤å±‹": "230000", "ç¦å²¡": "400000", "æœ­å¹Œ": "016000"}

SPECIALIZED_SITES = {
    'Blender': {'base_url': 'https://docs.blender.org/manual/ja/latest/', 'keywords': ['Blender', 'ãƒ–ãƒ¬ãƒ³ãƒ€ãƒ¼']},
    'CGãƒ‹ãƒ¥ãƒ¼ã‚¹': {'base_url': 'https://modelinghappy.com/', 'keywords': ['CGãƒ‹ãƒ¥ãƒ¼ã‚¹', '3DCG', 'CG']},
    'è„³ç§‘å­¦ãƒ»å¿ƒç†å­¦': {'base_url': 'https://nazology.kusuguru.co.jp/', 'keywords': ['è„³ç§‘å­¦', 'å¿ƒç†å­¦']},
    'ã‚¢ãƒ‹ãƒ¡': {'base_url': 'https://animedb.jp/', 'keywords': ['ã‚¢ãƒ‹ãƒ¡', 'anime']}
}

ANIME_KEYWORDS = ['ã‚¢ãƒ‹ãƒ¡', 'anime', 'ANIME', 'ï½±ï¾†ï¾’', 'ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³', 'ä½œç”»', 'å£°å„ª', 'OP', 'ED', 'åŠ‡å ´ç‰ˆ', 'æ˜ ç”»', 'åŸä½œ', 'æ¼«ç”»', 'ãƒ©ãƒãƒ™']
HOLOMEM_KEYWORDS = [
    'ã¨ãã®ãã‚‰', 'ãƒ­ãƒœå­ã•ã‚“', 'ã•ãã‚‰ã¿ã“', 'æ˜Ÿè¡—ã™ã„ã›ã„', 'AZKi', 'å¤œç©ºãƒ¡ãƒ«', 'ã‚¢ã‚­ãƒ»ãƒ­ãƒ¼ã‚¼ãƒ³ã‚¿ãƒ¼ãƒ«', 'èµ¤äº•ã¯ã‚ã¨', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å¤è‰²ã¾ã¤ã‚Š', 'æ¹Šã‚ãã‚',
    'ç´«å’²ã‚·ã‚ªãƒ³', 'ç™¾é¬¼ã‚ã‚„ã‚', 'ç™’æœˆã¡ã‚‡ã“', 'å¤§ç©ºã‚¹ãƒãƒ«', 'å¤§ç¥ãƒŸã‚ª', 'çŒ«åˆãŠã‹ã‚†', 'æˆŒç¥ã“ã‚ã­', 'å…ç”°ãºã“ã‚‰', 'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢', 'ç™½éŠ€ãƒã‚¨ãƒ«', 'å®é˜ãƒãƒªãƒ³',
    'å¤©éŸ³ã‹ãªãŸ', 'è§’å·»ã‚ãŸã‚', 'å¸¸é—‡ãƒˆãƒ¯', 'å§«æ£®ãƒ«ãƒ¼ãƒŠ', 'é›ªèŠ±ãƒ©ãƒŸã‚£', 'æ¡ƒéˆ´ã­ã­', 'ç…ç™½ã¼ãŸã‚“', 'å°¾ä¸¸ãƒãƒ«ã‚«', 'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹', 'é·¹å¶ºãƒ«ã‚¤', 'åšè¡£ã“ã‚ˆã‚Š',
    'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±', 'é¢¨çœŸã„ã‚ã¯', 'æ£®ã‚«ãƒªã‚ªãƒš', 'å°é³¥éŠã‚­ã‚¢ãƒ©', 'ä¸€ä¼Šé‚£å°“æ –', 'ãŒã†ã‚‹ãƒ»ãã‚‰', 'ãƒ¯ãƒˆã‚½ãƒ³ãƒ»ã‚¢ãƒ¡ãƒªã‚¢', 'IRyS', 'ã‚»ãƒ¬ã‚¹ãƒ»ãƒ•ã‚¡ã‚¦ãƒŠ', 'ã‚ªãƒ¼ãƒ­ãƒ»ã‚¯ãƒ­ãƒ‹ãƒ¼',
    'ä¸ƒè©©ãƒ ãƒ¡ã‚¤', 'ãƒã‚³ã‚¹ãƒ»ãƒ™ãƒ¼ãƒ«ã‚º', 'ã‚·ã‚ªãƒªãƒ»ãƒãƒ´ã‚§ãƒ©', 'å¤çŸ³ãƒ“ã‚¸ãƒ¥ãƒ¼', 'ãƒãƒªãƒƒã‚µãƒ»ãƒ¬ã‚¤ãƒ´ãƒ³ã‚¯ãƒ­ãƒ•ãƒˆ', 'ãƒ•ãƒ¯ãƒ¯ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ãƒ¢ã‚³ã‚³ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ã‚¢ãƒ¦ãƒ³ãƒ€ãƒ»ãƒªã‚¹',
    'ãƒ ãƒ¼ãƒŠãƒ»ãƒ›ã‚·ãƒãƒ´ã‚¡', 'ã‚¢ã‚¤ãƒ©ãƒ‹ãƒ»ã‚¤ã‚ªãƒ•ã‚£ãƒ•ãƒ†ã‚£ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¤ã‚¸ãƒ¼ãƒ»ã‚ªãƒªãƒ¼', 'ã‚¢ãƒ¼ãƒ‹ãƒ£ãƒ»ãƒ¡ãƒ«ãƒ•ã‚£ãƒƒã‚µ', 'ãƒ‘ãƒ´ã‚©ãƒªã‚¢ãƒ»ãƒ¬ã‚¤ãƒ', 'ç«å¨é’', 'éŸ³ä¹ƒç€¬å¥', 'ä¸€æ¡è‰ã€…è¯',
    'å„’çƒé¢¨äº­ã‚‰ã§ã‚“', 'è½Ÿã¯ã˜ã‚', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'ãƒ›ãƒ­ãƒ¡ãƒ³', 'hololive', 'YAGOO', 'æ¡ç”Ÿã‚³ã‚³', 'æ½¤ç¾½ã‚‹ã—ã‚', 'é­”ä¹ƒã‚¢ãƒ­ã‚¨', 'ä¹åä¹ä½å‘½'
]

# ==============================================================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° & ã‚¢ãƒ—ãƒªè¨­å®š
# ==============================================================================
background_executor = ThreadPoolExecutor(max_workers=5)
groq_client, gemini_model, engine, Session, fernet = None, None, None, None, None
VOICEVOX_ENABLED = False
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False
CORS(app)
Base = declarative_base()

# ==============================================================================
# ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•° èª­ã¿è¾¼ã¿
# ==============================================================================
def get_secret(name):
    env_value = os.environ.get(name)
    if env_value and env_value.strip(): return env_value.strip()
    try:
        with open(f'/etc/secrets/{name}', 'r') as f:
            file_value = f.read().strip()
            if file_value: return file_value
    except Exception: pass
    return None

DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./mochiko_ultimate.db'
GROQ_API_KEY = get_secret('GROQ_API_KEY')
GEMINI_API_KEY = get_secret('GEMINI_API_KEY')
VOICEVOX_URL_FROM_ENV = get_secret('VOICEVOX_URL')
ADMIN_TOKEN = get_secret('ADMIN_TOKEN')
BACKUP_ENCRYPTION_KEY = get_secret('BACKUP_ENCRYPTION_KEY')

# ==============================================================================
# ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Ÿè£…
# ==============================================================================
class ThreadSafeCache:
    def __init__(self, max_size=200, expiry_hours=1):
        self._cache = OrderedDict()
        self._lock = Lock()
        self._max_size = max_size
        self._expiry_seconds = expiry_hours * 3600

    def get(self, key, default=None):
        with self._lock:
            if key not in self._cache: return default
            value, expiry_time = self._cache[key]
            if datetime.utcnow() > expiry_time:
                del self._cache[key]
                return default
            self._cache.move_to_end(key)
            return value

    def set(self, key, value):
        with self._lock:
            expiry_time = datetime.utcnow() + timedelta(seconds=self._expiry_seconds)
            self._cache[key] = (value, expiry_time)
            self._cache.move_to_end(key)
            if len(self._cache) > self._max_size: self._cache.popitem(last=False)

    def cleanup_expired(self):
        with self._lock:
            now = datetime.utcnow()
            expired_keys = [key for key, (_, expiry) in self._cache.items() if now > expiry]
            for key in expired_keys: del self._cache[key]
            if expired_keys: logger.info(f"ğŸ§¹ Cache cleanup: Removed {len(expired_keys)} expired items.")

search_context_cache = ThreadSafeCache()

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« (å…¨æ©Ÿèƒ½åˆ†)
# ==============================================================================
class UserMemory(Base): __tablename__ = 'user_memories'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), unique=True, nullable=False, index=True); user_name = Column(String(255), nullable=False); interaction_count = Column(Integer, default=0); last_interaction = Column(DateTime, default=datetime.utcnow)
class ConversationHistory(Base): __tablename__ = 'conversation_history'; id = Column(Integer, primary_key=True, autoincrement=True); user_uuid = Column(String(255), nullable=False, index=True); role = Column(String(10), nullable=False); content = Column(Text, nullable=False); timestamp = Column(DateTime, default=datetime.utcnow, index=True)
class HololiveNews(Base): __tablename__ = 'hololive_news'; id = Column(Integer, primary_key=True); title = Column(String(500), nullable=False); content = Column(Text, nullable=False); url = Column(String(1000), unique=True); news_hash = Column(String(100), unique=True, index=True); created_at = Column(DateTime, default=datetime.utcnow, index=True)
class SpecializedNews(Base): __tablename__ = 'specialized_news'; id = Column(Integer, primary_key=True); site_name = Column(String(100), nullable=False, index=True); title = Column(String(500), nullable=False); content = Column(Text, nullable=False); url = Column(String(1000), unique=True); news_hash = Column(String(100), unique=True, index=True); created_at = Column(DateTime, default=datetime.utcnow, index=True)
class BackgroundTask(Base): __tablename__ = 'background_tasks'; id = Column(Integer, primary_key=True); task_id = Column(String(255), unique=True, nullable=False); user_uuid = Column(String(255), nullable=False, index=True); task_type = Column(String(50), nullable=False); query = Column(Text, nullable=False); result = Column(Text, nullable=True); status = Column(String(20), default='pending', index=True); created_at = Column(DateTime, default=datetime.utcnow); completed_at = Column(DateTime, nullable=True)
class HolomemWiki(Base): __tablename__ = 'holomem_wiki'; id = Column(Integer, primary_key=True); member_name = Column(String(100), nullable=False, unique=True, index=True); description = Column(Text, nullable=True); generation = Column(String(100), nullable=True); debut_date = Column(String(100), nullable=True); tags = Column(Text, nullable=True); status = Column(String(50), default='ç¾å½¹', nullable=False); graduation_date = Column(String(100), nullable=True); graduation_reason = Column(Text, nullable=True); mochiko_feeling = Column(Text, nullable=True); last_updated = Column(DateTime, default=datetime.utcnow)
class NewsCache(Base): __tablename__ = 'news_cache'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), nullable=False, index=True); news_id = Column(Integer, nullable=False); news_number = Column(Integer, nullable=False); news_type = Column(String(50), nullable=False); created_at = Column(DateTime, default=datetime.utcnow)
class UserContext(Base): __tablename__ = 'user_context'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), unique=True, nullable=False, index=True); last_context_type = Column(String(50), nullable=False); last_query = Column(Text, nullable=True); updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
class UserPsychology(Base): __tablename__ = 'user_psychology'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), unique=True, nullable=False, index=True); user_name = Column(String(255), nullable=False); openness = Column(Integer, default=50); conscientiousness = Column(Integer, default=50); extraversion = Column(Integer, default=50); agreeableness = Column(Integer, default=50); neuroticism = Column(Integer, default=50); interests = Column(Text, nullable=True); favorite_topics = Column(Text, nullable=True); conversation_style = Column(String(100), nullable=True); emotional_tendency = Column(String(100), nullable=True); analysis_summary = Column(Text, nullable=True); total_messages = Column(Integer, default=0); avg_message_length = Column(Integer, default=0); analysis_confidence = Column(Integer, default=0); last_analyzed = Column(DateTime, nullable=True)

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# ==============================================================================
@contextmanager
def get_db_session():
    if not Session: raise Exception("Database Session is not initialized.")
    session = Session()
    try:
        yield session
        session.commit()
    except Exception as e:
        logger.error(f"DBã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™: {e}", exc_info=True)
        session.rollback()
        raise
    finally:
        session.close()

# (ã“ã“ã«ä»–ã®å…¨é–¢æ•°ã‚’é…ç½®: ãƒ˜ãƒ«ãƒ‘ãƒ¼, AIå‘¼ã³å‡ºã—, ã‚³ã‚¢æ©Ÿèƒ½, ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯, ç®¡ç†è€…æ©Ÿèƒ½ãªã©)
# ... (æ–‡å­—æ•°ã®éƒ½åˆä¸Šã€ä»¥å‰ã®å›ç­”ã§ç”Ÿæˆã—ãŸå…¨é–¢æ•°ãŒã“ã“ã«å«ã¾ã‚Œã‚‹ã¨ä»®å®š) ...
# (ä»¥ä¸‹ã€ä¸»è¦ãªæœªå®Ÿè£…ã ã£ãŸé–¢æ•°ã‚„ä¿®æ­£ã•ã‚ŒãŸé–¢æ•°ã‚’æŠœç²‹ã—ã¦è¨˜è¿°)

# ==============================================================================
# å¤–éƒ¨æƒ…å ±æ¤œç´¢æ©Ÿèƒ½ï¼ˆå®Œå…¨å®Ÿè£…ç‰ˆï¼‰
# ==============================================================================
def scrape_major_search_engines(query, num_results=3):
    """è¤‡æ•°ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰æƒ…å ±ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œï¼‰"""
    search_configs = [
        {'name': 'DuckDuckGo', 'url': f"https://html.duckduckgo.com/html/?q={quote_plus(query)}", 'selector': '.result', 'title_selector': '.result__a', 'snippet_selector': '.result__snippet'},
        {'name': 'Bing', 'url': f"https://www.bing.com/search?q={quote_plus(query)}&mkt=ja-JP", 'selector': 'li.b_algo', 'title_selector': 'h2', 'snippet_selector': '.b_caption p'}
    ]
    for config in search_configs:
        try:
            response = requests.get(config['url'], headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=SEARCH_TIMEOUT)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            results = []
            for elem in soup.select(config['selector'])[:num_results]:
                title_elem = elem.select_one(config['title_selector'])
                snippet_elem = elem.select_one(config['snippet_selector'])
                if title_elem and snippet_elem:
                    title = clean_text(title_elem.get_text())
                    snippet = clean_text(snippet_elem.get_text())
                    if title and len(title) > 5:
                        results.append({'title': title, 'snippet': snippet})
            if results:
                logger.info(f"âœ… Search successful on {config['name']} for '{query}'")
                return results
        except requests.Timeout:
            logger.warning(f"âš ï¸ Search timeout on {config['name']} for '{query}'")
        except Exception as e:
            logger.warning(f"âš ï¸ Search failed on {config['name']}: {e}")
            continue
    logger.error(f"âŒ All search engines failed for query: {query}")
    return []

def background_deep_search(task_id, query_data):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§è©³ç´°æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹ã‚¿ã‚¹ã‚¯"""
    query = query_data['query']
    is_detailed = query_data.get('is_detailed', False)
    search_result = f"ã€Œ{query}ã€ã«ã¤ã„ã¦èª¿ã¹ãŸã‘ã©ã€æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚ˆâ€¦"
    try:
        # (ã“ã“ã«ã‚¢ãƒ‹ãƒ¡æ¤œç´¢ã€ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–Wikiæ¤œç´¢ã€Webæ¤œç´¢ã®åˆ†å²ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…)
        # ...
        raw_results = scrape_major_search_engines(query, 5)
        if raw_results:
            formatted_results = format_search_results_as_list(raw_results)
            search_context_cache.set(query_data['user_uuid'], (formatted_results, query)) # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            list_items = [f"ã€{r['number']}ã€‘{r['title']}" for r in formatted_results]
            search_result = f"ãŠã¾ãŸã›ï¼ã€Œ{query}ã€ã«ã¤ã„ã¦èª¿ã¹ã¦ããŸã‚ˆï¼\n" + "\n".join(list_items) + "\n\næ°—ã«ãªã‚‹ç•ªå·ã‚’æ•™ãˆã¦ï¼"

    except Exception as e:
        logger.error(f"âŒ Background search error for '{query}': {e}", exc_info=True)
    finally:
        with get_db_session() as session:
            task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
            if task:
                task.result = search_result
                task.status = 'completed'
                task.completed_at = datetime.utcnow()

# ==============================================================================
# éŸ³å£°ç”Ÿæˆæ©Ÿèƒ½ï¼ˆå®Œå…¨å®Ÿè£…ç‰ˆï¼‰
# ==============================================================================
def generate_voice_file(text, user_uuid):
    """VOICEVOX APIã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    if not VOICEVOX_ENABLED: return None
    
    clean_text_for_voice = clean_text(text).replace('|', '') # ãƒ‘ã‚¤ãƒ—æ–‡å­—ã‚’é™¤å»
    if len(clean_text_for_voice) > 200:
        clean_text_for_voice = clean_text_for_voice[:200] + "..."

    try:
        query_response = requests.post(f"{VOICEVOX_URL_FROM_ENV}/audio_query", params={"text": clean_text_for_voice, "speaker": VOICEVOX_SPEAKER_ID}, timeout=15)
        query_response.raise_for_status()
        audio_query = query_response.json()

        synthesis_response = requests.post(f"{VOICEVOX_URL_FROM_ENV}/synthesis", params={"speaker": VOICEVOX_SPEAKER_ID}, json=audio_query, timeout=30)
        synthesis_response.raise_for_status()

        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        filename = f"voice_{user_uuid[:8]}_{timestamp}.wav"
        filepath = os.path.join(VOICE_DIR, filename)

        with open(filepath, 'wb') as f: f.write(synthesis_response.content)
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜
        with open(filepath.replace('.wav', '.txt'), 'w', encoding='utf-8') as f: f.write(text)

        logger.info(f"âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”ŸæˆæˆåŠŸ: {filename}")
        return filename
    except Exception as e:
        logger.error(f"âŒ éŸ³å£°ç”Ÿæˆã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# (ã“ã“ã«ä»–ã®å…¨é–¢æ•°... ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã€DBä¿®æ­£ã€ç®¡ç†è€…APIã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãªã©ã€ä»¥å‰ã®å›ç­”ã§ç”Ÿæˆã—ãŸå®Œå…¨ãªã‚‚ã®ã‚’é…ç½®)

# ==============================================================================
# Flaskã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (å®Œå…¨ç‰ˆ)
# ==============================================================================
@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    """ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        data = request.json
        user_uuid, user_name, message = data['uuid'], data['name'], data['message'].strip()
        generate_voice_flag = data.get('voice', False)

        with get_db_session() as session:
            # (ã“ã“ã«v16ã®å®Œå…¨ãªå„ªå…ˆåº¦åˆ†å²ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¨˜è¿°)
            # ...
            ai_text = "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆå¿œç­”ã§ã™ã€‚" # ä»®ã®å¿œç­”

        response_text = limit_text_for_sl(ai_text)
        voice_url = ""
        if generate_voice_flag and VOICEVOX_ENABLED:
            voice_filename = generate_voice_file(response_text, user_uuid)
            if voice_filename:
                voice_url = f"{SERVER_URL}/play/{voice_filename}"

        return Response(f"{response_text}|{voice_url}", mimetype='text/plain; charset=utf-8', status=200)

    except Exception as e:
        logger.error(f"âŒ Chatã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return Response("ã”ã‚ã‚“ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦|", mimetype='text/plain; charset=utf-8', status=500)

@app.route('/check_task', methods=['POST'])
def check_task_endpoint():
    """LSLã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®éåŒæœŸã‚¿ã‚¹ã‚¯ç¢ºèªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    user_uuid = request.json['uuid']
    with get_db_session() as session:
        task = session.query(BackgroundTask).filter_by(user_uuid=user_uuid, status='completed').order_by(BackgroundTask.completed_at.desc()).first()
        if task:
            response_text = task.result
            session.delete(task)
            session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=response_text))
            return jsonify({'status': 'completed', 'response': response_text})
    return jsonify({'status': 'no_tasks'})

# (ã“ã“ã«ä»–ã®ã™ã¹ã¦ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ... /health, /voice, /play, /admin/* ãªã©ã‚’é…ç½®)
# ...

# ==============================================================================
# åˆæœŸåŒ–ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
# ==============================================================================
def initialize_app():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Œå…¨åˆæœŸåŒ–"""
    global engine, Session, groq_client, gemini_model, VOICEVOX_ENABLED, fernet
    logger.info("="*60 + "\nğŸ”§ ã‚‚ã¡ã“AI ç©¶æ¥µç‰ˆ (v16.1) ã®åˆæœŸåŒ–ã‚’é–‹å§‹...\n" + "="*60)
    
    # (ã“ã“ã«ãƒ¬ãƒãƒ¼ãƒˆã§æ¨å¥¨ã•ã‚ŒãŸã™ã¹ã¦ã®åˆæœŸåŒ–å‡¦ç†ã‚’è¨˜è¿°)
    # ç§˜å¯†æƒ…å ±èª­ã¿è¾¼ã¿ã€DBã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆ(ãƒ—ãƒ¼ãƒ«è¨­å®šè¾¼ã¿)ã€AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã€
    # Wikiãƒ‡ãƒ¼ã‚¿æŠ•å…¥ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©è¨­å®šãªã©
    
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’è¿½åŠ 
    schedule.every(1).hours.do(search_context_cache.cleanup_expired)
    schedule.every().day.at("03:00").do(commit_encrypted_backup_to_github) # è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    # ä»–ã®å®šæœŸã‚¿ã‚¹ã‚¯...
    
    threading.Thread(target=run_scheduler, daemon=True).start()
    logger.info("âœ… åˆæœŸåŒ–å®Œäº†ï¼")

def run_scheduler():
    while True:
        schedule.run_pending()
        time.sleep(60)

# ==============================================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ==============================================================================
try:
    initialize_app()
    application = app
except Exception as e:
    logger.critical(f"ğŸ”¥ Fatal initialization error: {e}", exc_info=True)
    sys.exit(1)

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
