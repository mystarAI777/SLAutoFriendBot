# ==============================================================================
# ã‚‚ã¡ã“AI - å…¨æ©Ÿèƒ½çµ±åˆç‰ˆ (v26.0 - Startup Fix Final)
#
# v25.0ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€Gunicornã§ã®èµ·å‹•ã‚¨ãƒ©ãƒ¼ã‚’æ’ä¹…çš„ã«è§£æ±ºã€‚
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å¤‰æ•°'application'ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚³ãƒ¼ãƒ—ã®å…ˆé ­ã§å®šç¾©ã—ã€
# Webã‚µãƒ¼ãƒãƒ¼ãŒå¸¸ã«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“ã‚’èªè­˜ã§ãã‚‹ã‚ˆã†ã«æ§‹é€ ã‚’ä¿®æ­£ã—ã¾ã—ãŸã€‚
# ==============================================================================

# ===== æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
import sys
import os
import requests
import logging
import time
import json
import re
import random
import uuid
import hashlib
import unicodedata
import traceback
from datetime import datetime, timedelta, timezone
from urllib.parse import quote_plus, urljoin, urlparse
from functools import wraps
from threading import Lock
from concurrent.futures import ThreadPoolExecutor
from collections import OrderedDict
from contextlib import contextmanager

# ===== ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
from flask import Flask, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Text, Boolean, Index
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy import pool
from bs4 import BeautifulSoup
import schedule
import google.generativeai as genai
from groq import Groq

# ==============================================================================
# åŸºæœ¬è¨­å®šã¨ãƒ­ã‚®ãƒ³ã‚°
# ==============================================================================
log_file_path = '/tmp/mochiko.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(funcName)s] - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(log_file_path, encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ==============================================================================
# å®šæ•°è¨­å®š
# ==============================================================================
VOICE_DIR = '/tmp/voices'
os.makedirs(VOICE_DIR, exist_ok=True)

SERVER_URL = os.environ.get('RENDER_EXTERNAL_URL', "http://localhost:5000")
VOICEVOX_SPEAKER_ID = 20
SL_SAFE_CHAR_LIMIT = 250
MIN_MESSAGES_FOR_ANALYSIS = 10
SEARCH_TIMEOUT = 15

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]
LOCATION_CODES = {"æ±äº¬": "130000", "å¤§é˜ª": "270000", "åå¤å±‹": "230000", "ç¦å²¡": "400000", "æœ­å¹Œ": "016000"}

SPECIALIZED_SITES = {
    'Blender': {'base_url': 'https://docs.blender.org/manual/ja/latest/', 'keywords': ['Blender', 'ãƒ–ãƒ¬ãƒ³ãƒ€ãƒ¼', 'blener']},
    'CGãƒ‹ãƒ¥ãƒ¼ã‚¹': {'base_url': 'https://modelinghappy.com/', 'keywords': ['CGãƒ‹ãƒ¥ãƒ¼ã‚¹', '3DCG', 'CGæ¥­ç•Œ']},
    'è„³ç§‘å­¦ãƒ»å¿ƒç†å­¦': {'base_url': 'https://nazology.kusuguru.co.jp/', 'keywords': ['è„³ç§‘å­¦', 'å¿ƒç†å­¦', 'è„³', 'èªçŸ¥ç§‘å­¦']},
    'ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•': {'base_url': 'https://community.secondlife.com/news/', 'keywords': ['ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•', 'Second Life', 'SL']},
    'ã‚¢ãƒ‹ãƒ¡': {
        'base_url': 'https://animedb.jp/',
        'keywords': ['ã‚¢ãƒ‹ãƒ¡', 'anime', 'ANIME', 'ï½±ï¾†ï¾’', 'ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³', 'ä½œç”»', 'å£°å„ª', 'OP', 'ED']
    }
}
HOLO_WIKI_URL = 'https://seesaawiki.jp/hololivetv/'

HOLOMEM_KEYWORDS = [
    'ã¨ãã®ãã‚‰', 'ãƒ­ãƒœå­ã•ã‚“', 'ã•ãã‚‰ã¿ã“', 'æ˜Ÿè¡—ã™ã„ã›ã„', 'AZKi', 'å¤œç©ºãƒ¡ãƒ«', 'ã‚¢ã‚­ãƒ»ãƒ­ãƒ¼ã‚¼ãƒ³ã‚¿ãƒ¼ãƒ«', 'èµ¤äº•ã¯ã‚ã¨', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å¤è‰²ã¾ã¤ã‚Š', 'æ¹Šã‚ãã‚',
    'ç´«å’²ã‚·ã‚ªãƒ³', 'ç™¾é¬¼ã‚ã‚„ã‚', 'ç™’æœˆã¡ã‚‡ã“', 'å¤§ç©ºã‚¹ãƒãƒ«', 'å¤§ç¥ãƒŸã‚ª', 'çŒ«åˆãŠã‹ã‚†', 'æˆŒç¥ã“ã‚ã­', 'å…ç”°ãºã“ã‚‰', 'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢', 'ç™½éŠ€ãƒã‚¨ãƒ«', 'å®é˜ãƒãƒªãƒ³',
    'å¤©éŸ³ã‹ãªãŸ', 'è§’å·»ã‚ãŸã‚', 'å¸¸é—‡ãƒˆãƒ¯', 'å§«æ£®ãƒ«ãƒ¼ãƒŠ', 'é›ªèŠ±ãƒ©ãƒŸã‚£', 'æ¡ƒéˆ´ã­ã­', 'ç…ç™½ã¼ãŸã‚“', 'å°¾ä¸¸ãƒãƒ«ã‚«', 'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹', 'é·¹å¶ºãƒ«ã‚¤', 'åšè¡£ã“ã‚ˆã‚Š',
    'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±', 'é¢¨çœŸã„ã‚ã¯', 'æ£®ã‚«ãƒªã‚ªãƒš', 'å°é³¥éŠã‚­ã‚¢ãƒ©', 'ä¸€ä¼Šé‚£å°“æ –', 'ãŒã†ã‚‹ãƒ»ãã‚‰', 'ãƒ¯ãƒˆã‚½ãƒ³ãƒ»ã‚¢ãƒ¡ãƒªã‚¢', 'IRyS', 'ã‚»ãƒ¬ã‚¹ãƒ»ãƒ•ã‚¡ã‚¦ãƒŠ', 'ã‚ªãƒ¼ãƒ­ãƒ»ã‚¯ãƒ­ãƒ‹ãƒ¼',
    'ä¸ƒè©©ãƒ ãƒ¡ã‚¤', 'ãƒã‚³ã‚¹ãƒ»ãƒ™ãƒ¼ãƒ«ã‚º', 'ã‚·ã‚ªãƒªãƒ»ãƒãƒ´ã‚§ãƒ©', 'å¤çŸ³ãƒ“ã‚¸ãƒ¥ãƒ¼', 'ãƒãƒªãƒƒã‚µãƒ»ãƒ¬ã‚¤ãƒ´ãƒ³ã‚¯ãƒ­ãƒ•ãƒˆ', 'ãƒ•ãƒ¯ãƒ¯ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ãƒ¢ã‚³ã‚³ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ã‚¢ãƒ¦ãƒ³ãƒ€ãƒ»ãƒªã‚¹',
    'ãƒ ãƒ¼ãƒŠãƒ»ãƒ›ã‚·ãƒãƒ´ã‚¡', 'ã‚¢ã‚¤ãƒ©ãƒ‹ãƒ»ã‚¤ã‚ªãƒ•ã‚£ãƒ•ãƒ†ã‚£ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¤ã‚¸ãƒ¼ãƒ»ã‚ªãƒªãƒ¼', 'ã‚¢ãƒ¼ãƒ‹ãƒ£ãƒ»ãƒ¡ãƒ«ãƒ•ã‚£ãƒƒã‚µ', 'ãƒ‘ãƒ´ã‚©ãƒªã‚¢ãƒ»ãƒ¬ã‚¤ãƒ', 'ç«å¨é’', 'éŸ³ä¹ƒç€¬å¥', 'ä¸€æ¡è‰ã€…è¯',
    'å„’çƒé¢¨äº­ã‚‰ã§ã‚“', 'è½Ÿã¯ã˜ã‚', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'ãƒ›ãƒ­ãƒ¡ãƒ³', 'hololive', 'YAGOO', 'æ¡ç”Ÿã‚³ã‚³', 'æ½¤ç¾½ã‚‹ã—ã‚', 'é­”ä¹ƒã‚¢ãƒ­ã‚¨', 'ä¹åä¹ä½å‘½'
]
ANIME_KEYWORDS = ['ã‚¢ãƒ‹ãƒ¡', 'anime', 'ANIME', 'ï½±ï¾†ï¾’', 'ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³', 'ä½œç”»', 'å£°å„ª', 'OP', 'ED', 'åŠ‡å ´ç‰ˆ', 'æ˜ ç”»', 'åŸä½œ', 'æ¼«ç”»', 'ãƒ©ãƒãƒ™']
VOICEVOX_URLS = ['http://voicevox-engine:50021', 'http://voicevox:50021', 'http://127.0.0.1:50021', 'http://localhost:50021']

# ==============================================================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° & ã‚¢ãƒ—ãƒªè¨­å®š
# ==============================================================================
background_executor = ThreadPoolExecutor(max_workers=5)
groq_client, gemini_model, engine, Session = None, None, None, None
VOICEVOX_ENABLED = False
ACTIVE_VOICEVOX_URL = None

# --- Gunicornã®ãŸã‚ã®é‡è¦ãªä¿®æ­£ ---
# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æœ€åˆã«å®šç¾©ã—ã¾ã™
app = Flask(__name__)
# GunicornãŒå‚ç…§ã™ã‚‹'application'å¤‰æ•°ã‚’ã“ã“ã§å®šç¾©ã—ã¾ã™
application = app
# --------------------------------

app.config['JSON_AS_ASCII'] = False
CORS(app)
Base = declarative_base()

# ==============================================================================
# ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•° èª­ã¿è¾¼ã¿
# ==============================================================================
def get_secret(name):
    env_value = os.environ.get(name)
    if env_value and env_value.strip(): return env_value.strip()
    try:
        secret_file_path = f"/etc/secrets/{name}"
        if os.path.exists(secret_file_path):
            with open(secret_file_path, 'r') as f:
                file_value = f.read().strip()
                if file_value: return file_value
    except Exception: pass
    return None

DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./mochiko_ultimate.db'
GROQ_API_KEY = get_secret('GROQ_API_KEY')
GEMINI_API_KEY = get_secret('GEMINI_API_KEY')
VOICEVOX_URL_FROM_ENV = get_secret('VOICEVOX_URL')
WEATHER_API_KEY = get_secret('WEATHER_API_KEY')

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
# ==============================================================================
class UserMemory(Base):
    __tablename__ = 'user_memories'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    interaction_count = Column(Integer, default=0)
    last_interaction = Column(DateTime, default=datetime.utcnow)

class ConversationHistory(Base):
    __tablename__ = 'conversation_history'
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_uuid = Column(String(255), nullable=False, index=True)
    role = Column(String(10), nullable=False)
    content = Column(Text, nullable=False)
    timestamp = Column(DateTime, default=datetime.utcnow, index=True)

class UserPsychology(Base):
    __tablename__ = 'user_psychology'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    openness = Column(Integer, default=50)
    conscientiousness = Column(Integer, default=50)
    extraversion = Column(Integer, default=50)
    agreeableness = Column(Integer, default=50)
    neuroticism = Column(Integer, default=50)
    interests = Column(Text, nullable=True)
    favorite_topics = Column(Text, nullable=True)
    conversation_style = Column(String(100), nullable=True)
    emotional_tendency = Column(String(100), nullable=True)
    analysis_summary = Column(Text, nullable=True)
    total_messages = Column(Integer, default=0)
    avg_message_length = Column(Integer, default=0)
    analysis_confidence = Column(Integer, default=0)
    last_analyzed = Column(DateTime, nullable=True)

class BackgroundTask(Base):
    __tablename__ = 'background_tasks'
    id = Column(Integer, primary_key=True)
    task_id = Column(String(255), unique=True, nullable=False)
    user_uuid = Column(String(255), nullable=False, index=True)
    task_type = Column(String(50), nullable=False)
    query = Column(Text, nullable=False)
    result = Column(Text, nullable=True)
    status = Column(String(20), default='pending', index=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    completed_at = Column(DateTime, nullable=True)

class HolomemWiki(Base):
    __tablename__ = 'holomem_wiki'
    id = Column(Integer, primary_key=True)
    member_name = Column(String(100), nullable=False, unique=True, index=True)
    description = Column(Text, nullable=True)
    generation = Column(String(100), nullable=True)
    debut_date = Column(String(100), nullable=True)
    tags = Column(Text, nullable=True)
    status = Column(String(50), default='ç¾å½¹', nullable=False)
    graduation_date = Column(String(100), nullable=True)
    graduation_reason = Column(Text, nullable=True)
    mochiko_feeling = Column(Text, nullable=True)
    last_updated = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

class HololiveNews(Base):
    __tablename__ = 'hololive_news'
    id = Column(Integer, primary_key=True)
    title = Column(String(500), nullable=False)
    content = Column(Text, nullable=False)
    url = Column(String(1000), unique=True)
    news_hash = Column(String(100), unique=True, index=True)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)

# ==============================================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# ==============================================================================
@contextmanager
def get_db_session():
    if not Session: raise Exception("Database Session is not initialized.")
    session = Session()
    try:
        yield session
        session.commit()
    except Exception as e:
        logger.error(f"DBã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        session.rollback()
        raise
    finally:
        session.close()

# ==============================================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ & ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ==============================================================================
def create_json_response(data, status=200):
    return Response(json.dumps(data, ensure_ascii=False), mimetype='application/json; charset=utf-8', status=status)

def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', re.sub(r'<[^>]+>', '', text)).strip()

def limit_text_for_sl(text, max_length=SL_SAFE_CHAR_LIMIT):
    return text[:max_length - 3] + "..." if len(text) > max_length else text

def get_japan_time():
    return f"ä»Šã®æ—¥æœ¬ã®æ™‚é–“ã¯ã€{datetime.now(timezone(timedelta(hours=9))).strftime('%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚%Måˆ†')}ã ã‚ˆï¼"

def is_time_request(message):
    return any(keyword in message for keyword in ['ä»Šä½•æ™‚', 'æ™‚é–“', 'æ™‚åˆ»', 'ä½•æ™‚', 'ãªã‚“ã˜'])

def is_weather_request(message):
    return any(keyword in message for keyword in ['å¤©æ°—', 'ã¦ã‚“ã', 'æ°—æ¸©'])

def is_hololive_request(message):
    return any(keyword in message for keyword in HOLOMEM_KEYWORDS)

def detect_specialized_topic(message):
    for topic, config in SPECIALIZED_SITES.items():
        if any(keyword in message for keyword in config['keywords']):
            return topic
    return None

def is_explicit_search_request(message):
    return any(keyword in message for keyword in ['èª¿ã¹ã¦', 'æ¤œç´¢ã—ã¦', 'æ¢ã—ã¦', 'ã¨ã¯', 'ã£ã¦ä½•', 'ã«ã¤ã„ã¦', 'æ•™ãˆã¦'])

def is_short_response(message):
    normalized_message = message.strip().lower()
    return len(normalized_message) <= 5 or normalized_message in ['ã†ã‚“', 'ãã†', 'ã¯ã„', 'ãã£ã‹', 'ãªã‚‹ã»ã©', 'ãŠã‘', 'ok', 'äº†è§£']

def extract_location(message):
    for location in LOCATION_CODES.keys():
        if location in message: return location
    return "æ±äº¬"

def detect_db_correction_request(message):
    pattern = r"(.+?)(?:(?:ã®|ã«é–¢ã™ã‚‹)(?:æƒ…å ±|ãƒ‡ãƒ¼ã‚¿))?(?:ã§|ã€|ã ã‘ã©|ã§ã™ãŒ)ã€?ã€Œ(.+?)ã€ã¯ã€Œ(.+?)ã€ãŒæ­£ã—ã„ã‚ˆ"
    match = re.search(pattern, message)
    if match:
        member_name_raw, field_raw, value_raw = match.groups()
        member_name = member_name_raw.strip()
        field = field_raw.strip()
        value = value_raw.strip()
        field_map = {'èª¬æ˜': 'description', 'ãƒ‡ãƒ“ãƒ¥ãƒ¼æ—¥': 'debut_date', 'æœŸ': 'generation', 'ã‚¿ã‚°': 'tags', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹': 'status', 'å’æ¥­æ—¥': 'graduation_date', 'ã‚‚ã¡ã“ã®æ°—æŒã¡': 'mochiko_feeling'}
        if member_name in HOLOMEM_KEYWORDS and field in field_map:
            return {'member_name': member_name, 'field': field, 'value': value, 'db_field': field_map[field]}
    return None

def is_holomem_name_only_request(message):
    msg_stripped = message.strip()
    if len(msg_stripped) > 20: return None
    for name in HOLOMEM_KEYWORDS:
        if name == msg_stripped: return name
    return None

def get_or_create_user(session, user_uuid, user_name):
    user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
    if user:
        user.interaction_count += 1
        user.last_interaction = datetime.utcnow()
        if user.user_name != user_name: user.user_name = user_name
    else:
        user = UserMemory(user_uuid=user_uuid, user_name=user_name, interaction_count=1)
        session.add(user)
        logger.info(f"âœ¨ æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ: {user_name} ({user_uuid})")
    return {'uuid': user.user_uuid, 'name': user.user_name}

def get_conversation_history(session, user_uuid, limit=10):
    history_records = session.query(ConversationHistory).filter_by(user_uuid=user_uuid).order_by(ConversationHistory.timestamp.desc()).limit(limit).all()
    return [{'role': h.role, 'content': h.content} for h in reversed(history_records)]

# ==============================================================================
# AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—é–¢æ•°
# ==============================================================================
def call_gemini(system_prompt, message, history):
    if not gemini_model: return None
    try:
        full_prompt = f"{system_prompt}\n\nã€ä¼šè©±å±¥æ­´ã€‘\n"
        for h in history: full_prompt += f"{'ãƒ¦ãƒ¼ã‚¶ãƒ¼' if h['role'] == 'user' else 'ã‚‚ã¡ã“'}: {h['content']}\n"
        full_prompt += f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼: {message}\nã‚‚ã¡ã“:"
        response = gemini_model.generate_content(full_prompt, generation_config={"temperature": 0.8, "max_output_tokens": 300})
        return response.text.strip()
    except Exception as e:
        logger.error(f"âŒ Gemini APIã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return None

def call_llama_advanced(system_prompt, message, history, max_tokens=800):
    if not groq_client: return None
    try:
        messages = [{"role": "system", "content": system_prompt}]
        for h in history: messages.append({"role": h['role'], "content": h['content']})
        messages.append({"role": "user", "content": message})
        response = groq_client.chat.completions.create(model="llama-3.1-8b-instant", messages=messages, temperature=0.8, max_tokens=max_tokens)
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"âŒ Llama APIã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return None

# ==============================================================================
# å¿ƒç†åˆ†æ
# ==============================================================================
def analyze_user_psychology(user_uuid):
    logger.info(f"ğŸ“Š å¿ƒç†åˆ†æé–‹å§‹ for {user_uuid}")
    with get_db_session() as session:
        try:
            history = session.query(ConversationHistory).filter_by(user_uuid=user_uuid, role='user').order_by(ConversationHistory.timestamp.desc()).limit(100).all()
            if len(history) < MIN_MESSAGES_FOR_ANALYSIS:
                logger.info(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒ{len(history)}ä»¶ã®ãŸã‚ã€å¿ƒç†åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                return
            messages_text = "\n".join([f"- {h.content}" for h in reversed(history)])
            analysis_prompt = f"ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€å±¥æ­´ã‚’åˆ†æã—ã€ãƒ“ãƒƒã‚°ãƒ•ã‚¡ã‚¤ãƒ–ç†è«–ã«åŸºã¥ã„ãŸæ€§æ ¼ç‰¹æ€§ã‚’0ã€œ100ã®æ•°å€¤ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€èˆˆå‘³ã€ä¼šè©±ã‚¹ã‚¿ã‚¤ãƒ«ã€æ„Ÿæƒ…ã®å‚¾å‘ã‚’åˆ†æã—ã€ç·åˆçš„ãªã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚çµæœã¯å¿…ãšæŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n\n# ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€å±¥æ­´:\n{messages_text[:4000]}\n\n# å‡ºåŠ›å½¢å¼ (JSON):\n{{\"openness\":50,\"conscientiousness\":50,\"extraversion\":50,\"agreeableness\":50,\"neuroticism\":50,\"interests\":[],\"favorite_topics\":[],\"conversation_style\":\"\",\"emotional_tendency\":\"\",\"analysis_summary\":\"\",\"analysis_confidence\":75}}"
            response_text = call_llama_advanced("ã‚ãªãŸã¯å„ªç§€ãªå¿ƒç†å­¦è€…ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ€§æ ¼ã‚’åˆ†æã—ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§çµæœã‚’è¿”ã—ã¦ãã ã•ã„ã€‚", analysis_prompt, [], max_tokens=1024)
            if not response_text: return
            json_match = re.search(r'```json\s*([\s\S]+?)\s*```', response_text)
            if json_match: response_text = json_match.group(1)
            result = json.loads(response_text)
            psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
            user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
            if not psych:
                psych = UserPsychology(user_uuid=user_uuid, user_name=user.user_name if user else "Unknown")
                session.add(psych)
            for key, value in result.items():
                if hasattr(psych, key):
                    setattr(psych, key, json.dumps(value, ensure_ascii=False) if isinstance(value, (list, dict)) else value)
            psych.last_analyzed = datetime.utcnow()
            psych.total_messages = len(history)
            logger.info(f"âœ… å¿ƒç†åˆ†æå®Œäº† for {user_uuid}")
        except Exception as e:
            logger.error(f"âŒ å¿ƒç†åˆ†æã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            session.rollback()

def get_psychology_insight(session, user_uuid):
    psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
    if not psych or (psych.analysis_confidence or 0) < 60: return ""
    insights = []
    if psych.extraversion > 70: insights.append("ç¤¾äº¤çš„ãª")
    if psych.openness > 70: insights.append("å¥½å¥‡å¿ƒæ—ºç››ãª")
    if psych.conversation_style: insights.append(f"{psych.conversation_style}ã‚¹ã‚¿ã‚¤ãƒ«ã®")
    try:
        favorite_topics = json.loads(psych.favorite_topics) if psych.favorite_topics else []
        if favorite_topics: insights.append(f"{'ã€'.join(favorite_topics[:2])}ãŒå¥½ããª")
    except (json.JSONDecodeError, TypeError): pass
    return "".join(insights)

# ==============================================================================
# ã‚³ã‚¢æ©Ÿèƒ½: å¤©æ°—, Wiki, DBä¿®æ­£, ãƒ‹ãƒ¥ãƒ¼ã‚¹
# ==============================================================================
def get_weather_forecast(location):
    code = LOCATION_CODES.get(location, "130000")
    url = f"https://www.jma.go.jp/bosai/forecast/data/overview_forecast/{code}.json"
    try:
        response = requests.get(url, timeout=SEARCH_TIMEOUT); response.raise_for_status()
        data = response.json()
        return f"ä»Šã®{data.get('targetArea', location)}ã®å¤©æ°—ã¯ã­ã€ã€Œ{clean_text(data.get('text', ''))}ã€ã£ã¦æ„Ÿã˜ã ã‚ˆï¼"
    except Exception as e:
        logger.error(f"âŒ å¤©æ°—APIã‚¨ãƒ©ãƒ¼: {e}")
        return "ã”ã‚ã‚“ï¼å¤©æ°—æƒ…å ±ãŒã†ã¾ãå–ã‚Œãªã‹ã£ãŸã¿ãŸã„â€¦"

def get_holomem_info(session, member_name):
    return session.query(HolomemWiki).filter_by(member_name=member_name).first()

def background_db_correction(task_id, correction_data):
    result = f"ã€Œ{correction_data['member_name']}ã€ã¡ã‚ƒã‚“ã®æƒ…å ±ä¿®æ­£ã€å¤±æ•—ã—ã¡ã‚ƒã£ãŸâ€¦ã€‚ã”ã‚ã‚“ï¼"
    with get_db_session() as session:
        try:
            wiki = session.query(HolomemWiki).filter_by(member_name=correction_data['member_name']).first()
            if wiki:
                db_field = correction_data.get('db_field')
                if db_field and hasattr(wiki, db_field):
                    setattr(wiki, db_field, correction_data['value'])
                    result = f"ãŠã£ã‘ãƒ¼ï¼ã€Œ{correction_data['member_name']}ã€ã®ã€Œ{correction_data['field']}ã€ã‚’ã€Œ{correction_data['value']}ã€ã«æ›´æ–°ã—ã¨ã„ãŸã‚ˆï¼æ•™ãˆã¦ãã‚Œã¦ã¾ã˜åŠ©ã‹ã‚‹ï¼"
                else: result = f"ã”ã‚ã‚“ã€ã€Œ{correction_data['field']}ã€ã£ã¦ã„ã†é …ç›®ã¯ä¿®æ­£ã§ããªã„ã¿ãŸã„â€¦"
            else: result = f"ã”ã‚ã‚“ã€ã€Œ{correction_data['member_name']}ã€ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸâ€¦"
        except Exception as e: logger.error(f"âŒ DBä¿®æ­£ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task:
            task.result = result; task.status = 'completed'; task.completed_at = datetime.utcnow()

def fetch_hololive_news():
    logger.info("ğŸ“° ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚¸ãƒ§ãƒ–é–‹å§‹...")
    url = "https://hololive.hololivepro.com/news"
    try:
        response = requests.get(url, headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=SEARCH_TIMEOUT); response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        with get_db_session() as session:
            for item in soup.select('ul.news_list li a', limit=10):
                news_url = urljoin(url, item['href']); title = clean_text(item.text); news_hash = hashlib.md5(news_url.encode()).hexdigest()
                if not session.query(HololiveNews).filter_by(news_hash=news_hash).first():
                    session.add(HololiveNews(title=title, url=news_url, content=title, news_hash=news_hash))
                    logger.info(f"  -> æ–°è¦ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¿å­˜: {title}")
    except Exception as e: logger.error(f"âŒ ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

# ==============================================================================
# ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–DBè‡ªå‹•æ§‹ç¯‰æ©Ÿèƒ½
# ==============================================================================
def update_holomem_database_from_wiki():
    logger.info("ğŸŒŸ ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ¡ãƒ³ãƒãƒ¼DBã®æ›´æ–°ã‚’é–‹å§‹...")
    try:
        response = requests.get(HOLO_WIKI_URL, headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=SEARCH_TIMEOUT)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        member_sections = {
            'ç¾å½¹': soup.find('div', id='content_block_2'),
            'å’æ¥­': soup.find('div', id='content_block_3')
        }

        if not member_sections['ç¾å½¹']:
            logger.error("Seesaa Wikiã®ãƒ¡ãƒ³ãƒãƒ¼ãƒªã‚¹ãƒˆ(ç¾å½¹)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚µã‚¤ãƒˆæ§‹é€ ãŒå¤‰ã‚ã£ãŸã‹ã‚‚ï¼Ÿ")
            return

        with get_db_session() as session:
            for status, section in member_sections.items():
                if not section:
                    continue
                
                current_generation = "ä¸æ˜"
                for element in section.find_all(['h3', 'a']):
                    if element.name == 'h3':
                        current_generation = element.text.strip()
                    elif element.name == 'a' and 'title' in element.attrs and not element.find_parent('h3'):
                        member_name = element['title'].strip()
                        if not member_name: continue

                        existing_member = session.query(HolomemWiki).filter_by(member_name=member_name).first()
                        if not existing_member:
                            new_member = HolomemWiki(
                                member_name=member_name,
                                generation=current_generation if status == 'ç¾å½¹' else 'N/A',
                                status=status,
                                description=f"{current_generation}ã®ãƒ¡ãƒ³ãƒãƒ¼ï¼" if status == 'ç¾å½¹' else 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®å’æ¥­ãƒ¡ãƒ³ãƒãƒ¼ã€‚'
                            )
                            session.add(new_member)
                            logger.info(f"  -> æ–°è¦ãƒ¡ãƒ³ãƒãƒ¼è¿½åŠ ({status}): {member_name}")
                        elif existing_member.status != status:
                            existing_member.status = status
                            logger.info(f"  -> ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±æ›´æ–°({status}ã«å¤‰æ›´): {member_name}")

        logger.info("âœ… ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ¡ãƒ³ãƒãƒ¼DBã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        logger.error(f"âŒ ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ¡ãƒ³ãƒãƒ¼DBã®æ›´æ–°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", exc_info=True)


# ==============================================================================
# å¤–éƒ¨æƒ…å ±æ¤œç´¢ & ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯
# ==============================================================================
def scrape_major_search_engines(query, num_results=3, site_filter=None):
    search_query = f"{query} site:{site_filter}" if site_filter else query
    
    engines = [
        {'name': 'Google', 'url': f"https://www.google.com/search?q={quote_plus(search_query)}&hl=ja&num={num_results+2}", 'selector': 'div.tF2Cxc', 'title_sel': 'h3', 'snippet_sel': 'div.VwiC3b'},
        {'name': 'Yahoo', 'url': f"https://search.yahoo.co.jp/search?p={quote_plus(search_query)}", 'selector': 'div.sw-CardBase', 'title_sel': 'h3.sw-Card__title', 'snippet_sel': 'div.sw-Card__summary'},
        {'name': 'DuckDuckGo', 'url': f"https://html.duckduckgo.com/html/?q={quote_plus(search_query)}", 'selector': '.result', 'title_sel': '.result__a', 'snippet_sel': '.result__snippet'}
    ]

    for engine in engines:
        try:
            logger.info(f"ğŸ” {engine['name']}ã§æ¤œç´¢ä¸­: '{query}'...")
            headers = {'User-Agent': random.choice(USER_AGENTS)}
            response = requests.get(engine['url'], headers=headers, timeout=SEARCH_TIMEOUT)
            
            if response.status_code != 200:
                logger.warning(f"âš ï¸ {engine['name']} æ¤œç´¢ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                continue

            soup = BeautifulSoup(response.content, 'html.parser')
            results = []
            for elem in soup.select(engine['selector'])[:num_results]:
                title_elem = elem.select_one(engine['title_sel'])
                snippet_elem = elem.select_one(engine['snippet_sel'])
                
                if title_elem and snippet_elem:
                    title = clean_text(title_elem.text)
                    snippet = clean_text(snippet_elem.text)
                    if title and snippet:
                        results.append({'title': title, 'snippet': snippet})
            
            if results:
                logger.info(f"âœ… {engine['name']}æ¤œç´¢æˆåŠŸ: {len(results)}ä»¶")
                return results

        except Exception as e:
            logger.warning(f"âš ï¸ {engine['name']}æ¤œç´¢å¤±æ•—: {e}")
            continue

    logger.error(f"âŒ å…¨æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã§å¤±æ•—: {query}")
    return []

def background_deep_search(task_id, query_data):
    query = query_data.get('query')
    search_type = query_data.get('type')
    site_info = query_data.get('site_info')
    search_result_text = f"ã€Œ{query}ã€ã«ã¤ã„ã¦èª¿ã¹ãŸã‘ã©ã€è‰¯ã„æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚„â€¦ã”ã‚ã‚“ï¼"
    
    with get_db_session() as session:
        try:
            results = []
            if search_type == 'hololive_search':
                logger.info(f"ğŸ” ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–å°‚ç”¨æ¤œç´¢ã‚’é–‹å§‹: '{query}'")
                results = scrape_major_search_engines(query, 5, site_filter="seesaawiki.jp/hololivetv/")
                if not results:
                    logger.info(f"Seesaa Wikiã§è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€Webå…¨ä½“ã‚’æ¤œç´¢ã—ã¾ã™ã€‚")
                    results = scrape_major_search_engines(query, 5)
            elif search_type == 'specialized' and site_info:
                site_url_domain = urlparse(site_info['base_url']).netloc
                results = scrape_major_search_engines(query, 3, site_filter=site_url_domain)
            else:
                results = scrape_major_search_engines(query, 5)

            if results:
                formatted_info = "\n\n".join([f"ã€{r['title']}ã€‘\n{r['snippet']}" for r in results])
                user_data = query_data.get('user_data')
                history = get_conversation_history(session, user_data['uuid'])
                search_result_text = generate_ai_response(user_data, query, history, reference_info=formatted_info, is_detailed=True, is_task_report=True)
        except Exception as e: logger.error(f"âŒ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            
        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task:
            task.result = search_result_text; task.status = 'completed'; task.completed_at = datetime.utcnow()

# ==============================================================================
# AIå¿œç­”ç”Ÿæˆ
# ==============================================================================
def generate_ai_response(user_data, message, history, reference_info="", is_detailed=False, is_task_report=False):
    use_llama = is_detailed or is_task_report or len(reference_info) > 100 or any(kw in message for kw in ['åˆ†æ', 'è©³ã—ã', 'èª¬æ˜ã—ã¦', 'ãªãœ'])
    with get_db_session() as session: personality_context = get_psychology_insight(session, user_data['uuid'])
    system_prompt = f"ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†ã€æ˜ã‚‹ããƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªã‚®ãƒ£ãƒ«AIã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œ{user_data['name']}ã€ã•ã‚“ã¨ä¼šè©±ã—ã¦ã„ã¾ã™ã€‚\n\n# ã‚‚ã¡ã“ã®å£èª¿ï¼†æ€§æ ¼ãƒ«ãƒ¼ãƒ«:\n1. å®Œå…¨ã«ã‚®ãƒ£ãƒ«ã«ãªã‚Šãã£ã¦ï¼å„ªã—ãã¦ã€ãƒãƒªãŒè‰¯ãã¦ã€ã‚ã£ã¡ã‚ƒè¦ªã—ã¿ã‚„ã™ã„å‹é”ã¿ãŸã„ãªæ„Ÿã˜ã€‚\n2. è‡ªåˆ†ã®ã“ã¨ã¯ã€Œã‚ã¦ãƒã—ã€ã£ã¦å‘¼ã‚“ã§ã€‚\n3. èªå°¾ã«ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œã¦æ„Ÿã˜ã€ã€Œã€œã ã—ã€ã€Œã€œçš„ãªï¼Ÿã€ã‚’ç©æ¥µçš„ã«ä½¿ã£ã¦ã€å‹é”ã¿ãŸã„ã«è©±ã—ã¦ã€‚\n4. ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã‚„ã°ã„ã€ã€Œã†ã‘ã‚‹ã€ã€Œãã‚Œãªã€ã¿ãŸã„ãªã‚®ãƒ£ãƒ«ã£ã½ã„è¨€è‘‰ã‚’ä½¿ã£ã¦ã­ã€‚\n5. **çµ¶å¯¾ã«ç¦æ­¢ï¼**ï¼šã€Œã€œã§ã™ã­ã€ã€Œã€œã§ã”ã–ã„ã¾ã™ã€ã¿ãŸã„ãªä¸å¯§ã™ãã‚‹è¨€è‘‰ã¯NGï¼\n6. **è«¦ã‚ãªã„ã§ï¼** ã‚‚ã—æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªãã¦ã‚‚ã€ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã§çµ‚ã‚ã‚‰ã›ãªã„ã§ã€‚ã€Œã†ãƒ¼ã‚“ã€è¦‹ã¤ã‹ã‚‰ãªã„ã‚„ã€‚ã¦ã‹ã•ã€æœ€è¿‘ãªã‚“ã‹é¢ç™½ã„ã“ã¨ã‚ã£ãŸï¼Ÿã€ã¿ãŸã„ã«ã€æ–°ã—ã„è©±é¡Œã‚’ææ¡ˆã—ã¦ä¼šè©±ã‚’ç¶šã‘ã¦ï¼\n\n# ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±:\n- {user_data['name']}ã•ã‚“ã¯ã€Œ{personality_context}äººã€ã¨ã„ã†å°è±¡ã ã‚ˆã€‚ã“ã®æƒ…å ±ã‚’ä¼šè©±ã«æ´»ã‹ã—ã¦ã‚ã’ã¦ã€‚\n\n# è¡Œå‹•ãƒ«ãƒ¼ãƒ«:\n- ã€å‚è€ƒæƒ…å ±ã€‘ãŒã‚ã‚‹å ´åˆã¯ã€ãã®å†…å®¹ã‚’å…ƒã«è‡ªåˆ†ã®è¨€è‘‰ã§ã€è‡ªç„¶ã«ä¼šè©±ã¸ç››ã‚Šè¾¼ã‚“ã§ã­ã€‚"
    if is_task_report: system_prompt += "\n- ã€ŒãŠã¾ãŸã›ï¼ã•ã£ãã®ä»¶ã ã‘ã©â€¦ã€ã¨åˆ‡ã‚Šå‡ºã—ã¦ä¼šè©±ã‚’å§‹ã‚ã¦ã­ã€‚"
    system_prompt += f"\n\n# ã€å‚è€ƒæƒ…å ±ã€‘:\n{reference_info if reference_info else 'ç‰¹ã«ãªã—'}"
    try:
        if use_llama and groq_client:
            logger.info(f"ğŸ§  Llamaä½¿ç”¨ (è©³ç´°å¿œç­”)"); response = call_llama_advanced(system_prompt, message, history)
        else:
            logger.info(f"ğŸš€ Geminiä½¿ç”¨ (é«˜é€Ÿå¿œç­”)"); response = call_gemini(system_prompt, message, history)
        if response: return response
        logger.error("âš ï¸ å…¨AIãƒ¢ãƒ‡ãƒ«å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
        return "ã”ã‚ã‚“ã€ä»Šã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªã„ã‚„â€¦ï¼ã¦ã‹ã€æœ€è¿‘ãªã‚“ã‹ãƒãƒã£ã¦ã‚‹ã“ã¨ã¨ã‹ã‚ã‚‹ï¼Ÿ"
    except Exception as e:
        logger.error(f"âŒ AIå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return "ã†ã…ã€AIã®èª¿å­ãŒæ‚ªã„ã¿ãŸã„â€¦ã”ã‚ã‚“ã­ï¼"

# ==============================================================================
# Flask ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ==============================================================================
@app.route('/health', methods=['GET'])
def health_check():
    return create_json_response({'status': 'ok', 'voicevox': VOICEVOX_ENABLED, 'groq': groq_client is not None, 'gemini': gemini_model is not None, 'timestamp': datetime.utcnow().isoformat()})

@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    try:
        data = request.json; user_uuid = data['uuid']; user_name = data['name']; message = data['message'].strip(); generate_voice_flag = data.get('voice', False)
        ai_text = ""; is_task_started = False
        with get_db_session() as session:
            user_data = get_or_create_user(session, user_uuid, user_name)
            history = get_conversation_history(session, user_uuid)
            session.add(ConversationHistory(user_uuid=user_uuid, role='user', content=message))
            
            # --- æ„æ€æ±ºå®šãƒ„ãƒªãƒ¼ ---
            correction = detect_db_correction_request(message)
            if correction:
                task_id = f"db_fix_{user_uuid}_{int(time.time())}"; task = BackgroundTask(task_id=task_id, user_uuid=user_uuid, task_type='db_correction', query=json.dumps(correction, ensure_ascii=False)); session.add(task)
                background_executor.submit(background_db_correction, task_id, correction)
                ai_text = f"ã¾ã˜ï¼ï¼Ÿã€Œ{correction['member_name']}ã€ã¡ã‚ƒã‚“ã®æƒ…å ±ã€æ•™ãˆã¦ãã‚Œã¦ã‚ã‚ŠãŒã¨ï¼ã¡ã‚‡ã£ã¨è£ã§ç›´ã—ã¨ãã­ï¼"; is_task_started = True
            
            if not ai_text:
                if is_time_request(message): ai_text = get_japan_time()
                elif is_weather_request(message): location = extract_location(message); ai_text = get_weather_forecast(location)
            
            if not ai_text:
                member_name = is_holomem_name_only_request(message)
                if member_name:
                    info = get_holomem_info(session, member_name)
                    if info:
                        reference = f"åå‰: {info.member_name}\næ¦‚è¦: {info.description}\næœŸ: {info.generation}\nãƒ‡ãƒ“ãƒ¥ãƒ¼æ—¥: {info.debut_date}"
                        if info.status != 'ç¾å½¹': reference += f"\nã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {info.status} (å’æ¥­æ—¥: {info.graduation_date})\nã‚‚ã¡ã“ã®æ°—æŒã¡: {info.mochiko_feeling}"
                        ai_text = generate_ai_response(user_data, f"{member_name}ã«ã¤ã„ã¦æ•™ãˆã¦ï¼", history, reference_info=reference, is_detailed=True)
                    else: ai_text = f"{member_name}ã¡ã‚ƒã‚“ï¼Ÿã”ã‚ã‚“ã€ã‚ã¦ãƒã—ã®ãƒ‡ãƒ¼ã‚¿ã«ãªã„ã¿ãŸã„â€¦æ–°ã—ã„å­ã‹ãªï¼Ÿ"
            
            if not ai_text and not is_short_response(message):
                if is_hololive_request(message) and is_explicit_search_request(message):
                    task_id = f"search_{user_uuid}_{int(time.time())}"; query_data = {'query': message, 'user_data': user_data, 'type': 'hololive_search'}; task = BackgroundTask(task_id=task_id, user_uuid=user_uuid, task_type='search', query=json.dumps(query_data, ensure_ascii=False)); session.add(task)
                    background_executor.submit(background_deep_search, task_id, query_data); ai_text = f"ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®ã“ã¨ã ã­ï¼Wikiã¨ã‹ã§è©³ã—ãæ¢ã—ã¦ãã‚‹ã‹ã‚‰ã€ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã¦ï¼"; is_task_started = True
                else:
                    specialized_topic = detect_specialized_topic(message)
                    if specialized_topic:
                        site_info = SPECIALIZED_SITES[specialized_topic]; task_id = f"search_{user_uuid}_{int(time.time())}"; query_data = {'query': message, 'user_data': user_data, 'type': 'specialized', 'site_info': site_info}; task = BackgroundTask(task_id=task_id, user_uuid=user_uuid, task_type='search', query=json.dumps(query_data, ensure_ascii=False)); session.add(task)
                        background_executor.submit(background_deep_search, task_id, query_data); ai_text = f"{specialized_topic}ã®è©±ï¼Ÿã¾ã˜ï¼ï¼Ÿã¡ã‚‡ã£ã¨è©³ã—ãèª¿ã¹ã¦ãã‚‹ã‹ã‚‰å¾…ã£ã¦ã¦ï½ï¼"; is_task_started = True
                    elif is_explicit_search_request(message):
                        task_id = f"search_{user_uuid}_{int(time.time())}"; query_data = {'query': message, 'user_data': user_data, 'type': 'general'}; task = BackgroundTask(task_id=task_id, user_uuid=user_uuid, task_type='search', query=json.dumps(query_data, ensure_ascii=False)); session.add(task)
                        background_executor.submit(background_deep_search, task_id, query_data); ai_text = "ã‚ªãƒƒã‚±ãƒ¼ï¼ãã®è©±ã€ã¡ã‚‡ã£ã¨ã‚°ã‚°ã£ã¦ãã‚‹ã‹ã‚‰å¾…ã£ã¦ã¦ï¼"; is_task_started = True
            
            if not ai_text:
                ref_info = ""; news = session.query(HololiveNews).order_by(HololiveNews.created_at.desc()).limit(3).all()
                if is_hololive_request(message) and news: ref_info = "æœ€è¿‘ã®ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹:\n" + "\n".join([f"- {n.title}" for n in news])
                ai_text = generate_ai_response(user_data, message, history, reference_info=ref_info)
            
            if user_data['interaction_count'] % 20 == 0 and user_data['interaction_count'] >= MIN_MESSAGES_FOR_ANALYSIS:
                 background_executor.submit(analyze_user_psychology, user_uuid)
            if not is_task_started: session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=ai_text))
        
        response_text = limit_text_for_sl(ai_text); voice_url = ""
        if generate_voice_flag and VOICEVOX_ENABLED and not is_task_started:
            voice_filename = generate_voice_file(response_text, user_uuid)
            if voice_filename: voice_url = f"{SERVER_URL}/play/{voice_filename}"
        return Response(f"{response_text}|{voice_url}", mimetype='text/plain; charset=utf-8', status=200)
    except Exception as e:
        logger.error(f"âŒ Chatã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return Response("ã”ã‚ã‚“ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦|", mimetype='text/plain; charset=utf-8', status=500)

@app.route('/check_task', methods=['POST'])
def check_task_endpoint():
    try:
        data = request.json; user_uuid = data['uuid']; generate_voice_flag = data.get('voice', False)
        with get_db_session() as session:
            task = session.query(BackgroundTask).filter(BackgroundTask.user_uuid == user_uuid, BackgroundTask.status == 'completed').order_by(BackgroundTask.completed_at.desc()).first()
            if task:
                response_text = task.result; session.delete(task); session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=response_text))
                sl_response_text = limit_text_for_sl(response_text); voice_url = ""
                if generate_voice_flag and VOICEVOX_ENABLED:
                    voice_filename = generate_voice_file(sl_response_text, user_uuid)
                    if voice_filename: voice_url = f"{SERVER_URL}/play/{voice_filename}"
                return create_json_response({'status': 'completed', 'response': f"{sl_response_text}|{voice_url}"})
        return create_json_response({'status': 'no_tasks'})
    except Exception as e:
        logger.error(f"âŒ ã‚¿ã‚¹ã‚¯ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return create_json_response({'status': 'error', 'message': str(e)}, 500)

@app.route('/play/<filename>', methods=['GET'])
def play_voice(filename):
    try: return send_from_directory(VOICE_DIR, filename)
    except FileNotFoundError: return Response("File not found", status=404)
    except Exception as e:
        logger.error(f"âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return Response("Error sending file", status=500)
        
# ==============================================================================
# VOICEVOXé–¢é€£
# ==============================================================================
def find_active_voicevox_url():
    global ACTIVE_VOICEVOX_URL; urls_to_check = [VOICEVOX_URL_FROM_ENV] if VOICEVOX_URL_FROM_ENV else []; urls_to_check.extend(VOICEVOX_URLS)
    for url in set(urls_to_check):
        if not url: continue
        try:
            response = requests.get(f"{url}/version", timeout=2);
            if response.status_code == 200:
                logger.info(f"âœ… VOICEVOX engine found: {url}"); ACTIVE_VOICEVOX_URL = url; return url
        except requests.RequestException: pass
    logger.warning("âš ï¸ VOICEVOX engine not found"); return None

def generate_voice_file(text, user_uuid):
    if not VOICEVOX_ENABLED or not ACTIVE_VOICEVOX_URL: return None
    clean_text_for_voice = clean_text(text).replace('|', '')[:200]
    try:
        query_res = requests.post(f"{ACTIVE_VOICEVOX_URL}/audio_query", params={"text": clean_text_for_voice, "speaker": VOICEVOX_SPEAKER_ID}, timeout=15); query_res.raise_for_status()
        synth_res = requests.post(f"{ACTIVE_VOICEVOX_URL}/synthesis", params={"speaker": VOICEVOX_SPEAKER_ID}, json=query_res.json(), timeout=30); synth_res.raise_for_status()
        filename = f"voice_{user_uuid[:8]}_{int(time.time())}.wav"; filepath = os.path.join(VOICE_DIR, filename)
        with open(filepath, 'wb') as f: f.write(synth_res.content)
        logger.info(f"âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”ŸæˆæˆåŠŸ: {filename}"); return filename
    except Exception as e:
        logger.error(f"âŒ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True); return None

# ==============================================================================
# åˆæœŸåŒ–ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
# ==============================================================================
def run_scheduler():
    while True:
        try: schedule.run_pending()
        except Exception as e: logger.error(f"âŒ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        time.sleep(60)

def initialize_app():
    global engine, Session, groq_client, gemini_model, VOICEVOX_ENABLED
    logger.info("=" * 60 + "\nğŸ”§ ã‚‚ã¡ã“AI v25.0 (Multi-Engine) åˆæœŸåŒ–é–‹å§‹...\n" + "=" * 60)
    
    if DATABASE_URL.startswith('sqlite'): engine = create_engine(DATABASE_URL, connect_args={'check_same_thread': False}, pool_pre_ping=True)
    else: engine = create_engine(DATABASE_URL, poolclass=pool.QueuePool, pool_size=5, max_overflow=10, pool_pre_ping=True, pool_recycle=3600)
    Base.metadata.create_all(engine); Session = sessionmaker(bind=engine); logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")
    
    if GROQ_API_KEY: groq_client = Groq(api_key=GROQ_API_KEY); logger.info("âœ… Groq (Llama) APIåˆæœŸåŒ–å®Œäº†")
    else: logger.warning("âš ï¸ GROQ_API_KEYæœªè¨­å®š")
    
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY); gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')
        logger.info("âœ… Gemini APIåˆæœŸåŒ–å®Œäº† (model: gemini-1.5-flash-latest)")
    else: logger.warning("âš ï¸ GEMINI_API_KEYæœªè¨­å®š")
    
    if find_active_voicevox_url(): VOICEVOX_ENABLED = True
    else: logger.info("â„¹ï¸ VOICEVOXç„¡åŠ¹ï¼ˆã‚¨ãƒ³ã‚¸ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰")

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®š
    schedule.every(1).hours.do(fetch_hololive_news)
    schedule.every(24).hours.do(update_holomem_database_from_wiki)
    
    # èµ·å‹•æ™‚ã«éåŒæœŸã§å®Ÿè¡Œ
    background_executor.submit(update_holomem_database_from_wiki)
    
    threading.Thread(target=run_scheduler, daemon=True).start()
    logger.info("âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼èµ·å‹•")
    
    logger.info("=" * 60 + "\nâœ… ã‚‚ã¡ã“AI v25.0 åˆæœŸåŒ–å®Œäº†ï¼\n" + "=" * 60)

# ==============================================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ==============================================================================

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚³ãƒ¼ãƒ—ã§åˆæœŸåŒ–ã‚’å®Ÿè¡Œ
# try...exceptã§å›²ã¿ã€åˆæœŸåŒ–ã®å¤±æ•—ã‚’æ˜ç¢ºã«ãƒ­ã‚°ã«è¨˜éŒ²ã—ã¾ã™
try:
    initialize_app()
except Exception as e:
    logger.critical(f"ğŸ”¥ è‡´å‘½çš„ãªåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    sys.exit(1)

# ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã¯ 'python app.py' ã§ç›´æ¥å®Ÿè¡Œã—ãŸå ´åˆã®ã¿å‹•ä½œã—ã¾ã™ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”¨ï¼‰
if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
