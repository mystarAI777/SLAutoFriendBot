# ==============================================================================
# „ÇÇ„Å°„ÅìAI - ÂÖ®Ê©üËÉΩÁµ±ÂêàÁâà (v31.4 - Anti-Block & RSS Edition)
#
# „Éô„Éº„Çπ: v31.3 („Åø„Åì„Å°ÂøúÁ≠îÁµ±ÂêàÁâà)
# ‰øÆÊ≠£ÁÇπ:
# 1. Google„Éã„É•„Éº„ÇπRSSÂèñÂæóÊ©üËÉΩ„ÅÆËøΩÂä†
#    -> „Äå„Éã„É•„Éº„Çπ„ÄçÁ≥ª„ÇØ„Ç®„É™„ÅØÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÇíÈÄö„Åï„ÅöRSS„ÇíÁõ¥Êé•Ë™≠„ÇÄÔºà„Éñ„É≠„ÉÉ„ÇØÂõûÈÅøÔºâ
# 2. Wikipedia API„ÅÆÂÆüË£Ö
#    -> ‰∏ÄËà¨ÁöÑ„Å™Ê§úÁ¥¢Â§±ÊïóÊôÇ„ÅÆ„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Å®„Åó„Å¶ÂÖ¨ÂºèAPI„Çí‰ΩøÁî®Ôºà„Éñ„É≠„ÉÉ„ÇØÂõûÈÅøÔºâ
# 3. „Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞Â§±ÊïóÊôÇ„ÅÆ„É≠„Ç∞Âº∑Âåñ
# ==============================================================================

# ===== Ê®ôÊ∫ñ„É©„Ç§„Éñ„É©„É™ =====
import sys
import os
import requests
import logging
import time
import json
import re
import random
import uuid
import hashlib
import unicodedata
import traceback
import threading
import atexit
import glob
from html import escape
from datetime import datetime, timedelta, timezone
from urllib.parse import quote_plus, urljoin, urlparse
from functools import wraps, lru_cache
from threading import Lock, RLock
from concurrent.futures import ThreadPoolExecutor
from collections import OrderedDict, defaultdict
from contextlib import contextmanager
from dataclasses import dataclass, field
from typing import Optional, Dict, List, Any

# ===== „Çµ„Éº„Éâ„Éë„Éº„ÉÜ„Ç£„É©„Ç§„Éñ„É©„É™ =====
from flask import Flask, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Text, Boolean, Index, text
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy import pool
from bs4 import BeautifulSoup
import schedule
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from groq import Groq

# ==============================================================================
# Âü∫Êú¨Ë®≠ÂÆö„Å®„É≠„ÇÆ„É≥„Ç∞
# ==============================================================================
log_file_path = '/tmp/mochiko.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(funcName)s:%(lineno)d] - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(log_file_path, encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ==============================================================================
# ÂÆöÊï∞Ë®≠ÂÆö & „É¢„Éá„É´Ë®≠ÂÆö
# ==============================================================================
VOICE_DIR = '/tmp/voices'
os.makedirs(VOICE_DIR, exist_ok=True)

SERVER_URL = os.environ.get('RENDER_EXTERNAL_URL', "http://localhost:5000")
VOICEVOX_SPEAKER_ID = 20
SL_SAFE_CHAR_LIMIT = 250
MIN_MESSAGES_FOR_ANALYSIS = 10
SEARCH_TIMEOUT = 10
VOICE_FILE_MAX_AGE_HOURS = 24

GROQ_MODELS = [
    "llama-3.3-70b-versatile",
    "llama-3.1-70b-versatile",
    "llama-3.1-8b-instant",
    "mixtral-8x7b-32768",
    "gemma2-9b-it"
]

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:125.0) Gecko/20100101 Firefox/125.0',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
    'Mozilla/5.0 (iPhone; CPU iPhone OS 17_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Mobile/15E148 Safari/604.1'
]

LOCATION_CODES = {
    "Êù±‰∫¨": "130000", "Â§ßÈò™": "270000", "ÂêçÂè§Â±ã": "230000",
    "Á¶èÂ≤°": "400000", "Êú≠Âπå": "016000"
}

SPECIALIZED_SITES = {
    'Blender': {'base_url': 'https://docs.blender.org/manual/ja/latest/', 'keywords': ['Blender', '„Éñ„É¨„É≥„ÉÄ„Éº']},
    'CG„Éã„É•„Éº„Çπ': {'base_url': 'https://modelinghappy.com/', 'keywords': ['CG„Éã„É•„Éº„Çπ', '3DCG', 'CGÊ•≠Áïå']},
    'ËÑ≥ÁßëÂ≠¶„ÉªÂøÉÁêÜÂ≠¶': {'base_url': 'https://nazology.kusuguru.co.jp/', 'keywords': ['ËÑ≥ÁßëÂ≠¶', 'ÂøÉÁêÜÂ≠¶', 'Ë™çÁü•ÁßëÂ≠¶']},
    '„Çª„Ç´„É≥„Éâ„É©„Ç§„Éï': {'base_url': 'https://community.secondlife.com/news/', 'keywords': ['„Çª„Ç´„É≥„Éâ„É©„Ç§„Éï', 'Second Life', 'SL']},
    '„Ç¢„Éã„É°': {'base_url': 'https://animedb.jp/', 'keywords': ['„Ç¢„Éã„É°', 'anime', '„Ç¢„Éã„É°„Éº„Ç∑„Éß„É≥', 'Â£∞ÂÑ™']}
}

HOLOMEM_KEYWORDS = [
    '„Å®„Åç„ÅÆ„Åù„Çâ', '„É≠„ÉúÂ≠ê„Åï„Çì', '„Åï„Åè„Çâ„Åø„Åì', '„Åø„Åì„Å°', 'ÊòüË°ó„Åô„ÅÑ„Åõ„ÅÑ', '„Åô„ÅÑ„Å°„ÇÉ„Çì',
    'AZKi', 'Â§úÁ©∫„É°„É´', '„Ç¢„Ç≠„Éª„É≠„Éº„Çº„É≥„Çø„Éº„É´', 'Ëµ§‰∫ï„ÅØ„ÅÇ„Å®', 'ÁôΩ‰∏ä„Éï„Éñ„Ç≠', 'Â§èËâ≤„Åæ„Å§„Çä',
    'Êπä„ÅÇ„Åè„ÅÇ', 'Á¥´Âí≤„Ç∑„Ç™„É≥', 'ÁôæÈ¨º„ÅÇ„ÇÑ„ÇÅ', 'ÁôíÊúà„Å°„Çá„Åì', 'Â§ßÁ©∫„Çπ„Éê„É´', 'Â§ßÁ•û„Éü„Ç™',
    'Áå´Âèà„Åä„Åã„ÇÜ', '„Åä„Åã„ÇÜ„Çì', 'ÊàåÁ•û„Åì„Çç„Å≠', '„Åì„Çç„Åï„Çì', 'ÂÖéÁî∞„Å∫„Åì„Çâ', '„Å∫„Åì„Éº„Çâ',
    '‰∏çÁü•ÁÅ´„Éï„É¨„Ç¢', 'ÁôΩÈäÄ„Éé„Ç®„É´', 'ÂÆùÈêò„Éû„É™„É≥', 'ËàπÈï∑', 'Â§©Èü≥„Åã„Å™„Åü', 'ËßíÂ∑ª„Çè„Åü„ÇÅ',
    'Â∏∏Èóá„Éà„ÉØ', 'Âß´Ê£Æ„É´„Éº„Éä', 'Èõ™Ëä±„É©„Éü„Ç£', 'Ê°ÉÈà¥„Å≠„Å≠', 'ÁçÖÁôΩ„Åº„Åü„Çì', 'Â∞æ‰∏∏„Éù„É´„Ç´',
    '„É©„Éó„É©„Çπ„Éª„ÉÄ„Éº„ÇØ„Éç„Çπ', 'È∑πÂ∂∫„É´„Ç§', 'ÂçöË°£„Åì„Çà„Çä', 'Ê≤ôËä±Âèâ„ÇØ„É≠„É±', 'È¢®Áúü„ÅÑ„Çç„ÅØ',
    'Ê£Æ„Ç´„É™„Ç™„Éö', 'Â∞èÈ≥•ÈÅä„Ç≠„Ç¢„É©', '‰∏Ä‰ºäÈÇ£Â∞ìÊ†ñ', '„Åå„ÅÜ„Çã„Éª„Åê„Çâ', '„Çµ„É°„Å°„ÇÉ„Çì',
    '„ÉØ„Éà„ÇΩ„É≥„Éª„Ç¢„É°„É™„Ç¢', 'IRyS', '„Çª„É¨„Çπ„Éª„Éï„Ç°„Ç¶„Éä', '„Ç™„Éº„É≠„Éª„ÇØ„É≠„Éã„Éº', '‰∏ÉË©©„É†„É°„Ç§',
    '„Éè„Ç≥„Çπ„Éª„Éô„Éº„É´„Ç∫', '„Ç∑„Ç™„É™„Éª„Éé„É¥„Çß„É©', 'Âè§Áü≥„Éì„Ç∏„É•„Éº', '„Éç„É™„ÉÉ„Çµ„Éª„É¨„Ç§„É¥„É≥„ÇØ„É≠„Éï„Éà',
    '„Éï„ÉØ„ÉØ„Éª„Ç¢„Éì„Çπ„Ç¨„Éº„Éâ', '„É¢„Ç≥„Ç≥„Éª„Ç¢„Éì„Çπ„Ç¨„Éº„Éâ', '„Ç¢„É¶„É≥„ÉÄ„Éª„É™„Çπ', '„É†„Éº„Éä„Éª„Éõ„Ç∑„Éé„É¥„Ç°',
    '„Ç¢„Ç§„É©„Éã„Éª„Ç§„Ç™„Éï„Ç£„Éï„ÉÜ„Ç£„Éº„É≥', '„ÇØ„É¨„Ç§„Ç∏„Éº„Éª„Ç™„É™„Éº', '„Ç¢„Éº„Éã„É£„Éª„É°„É´„Éï„Ç£„ÉÉ„Çµ',
    '„Éë„É¥„Ç©„É™„Ç¢„Éª„É¨„Ç§„Éç', 'ÁÅ´Â®ÅÈùí', 'Èü≥‰πÉÁÄ¨Â•è', '‰∏ÄÊù°Ëéâ„ÄÖËèØ', 'ÂÑíÁÉèÈ¢®‰∫≠„Çâ„Åß„Çì',
    'ËΩü„ÅØ„Åò„ÇÅ', '„Éõ„É≠„É©„Ç§„Éñ', '„Éõ„É≠„É°„É≥', 'hololive', 'YAGOO', 'Ê°êÁîü„Ç≥„Ç≥',
    'ÊΩ§ÁæΩ„Çã„Åó„ÅÇ', 'È≠î‰πÉ„Ç¢„É≠„Ç®', '‰πùÂçÅ‰πù‰ΩêÂëΩ'
]

ANIME_KEYWORDS = ['„Ç¢„Éã„É°', 'anime', '„Ç¢„Éã„É°„Éº„Ç∑„Éß„É≥', '‰ΩúÁîª', 'Â£∞ÂÑ™', 'OP', 'ED', 'ÂäáÂ†¥Áâà', 'Êò†Áîª', 'Âéü‰Ωú', 'Êº´Áîª', '„É©„Éé„Éô']

VOICEVOX_URLS = [
    'http://voicevox-engine:50021', 'http://voicevox:50021',
    'http://127.0.0.1:50021', 'http://localhost:50021'
]

# ==============================================================================
# „Éá„Éº„Çø„ÇØ„É©„Çπ
# ==============================================================================
@dataclass
class GroqModelStatus:
    is_limited: bool = False
    reset_time: Optional[datetime] = None
    last_error: Optional[str] = None

@dataclass
class UserData:
    uuid: str
    name: str
    interaction_count: int

# ==============================================================================
# „Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖãÁÆ°ÁêÜ
# ==============================================================================
class GlobalState:
    def __init__(self):
        self._lock = RLock()
        self._voicevox_enabled = False
        self._active_voicevox_url = None

    @property
    def voicevox_enabled(self) -> bool:
        with self._lock: return self._voicevox_enabled
    @voicevox_enabled.setter
    def voicevox_enabled(self, value: bool):
        with self._lock: self._voicevox_enabled = value
    @property
    def active_voicevox_url(self) -> Optional[str]:
        with self._lock: return self._active_voicevox_url
    @active_voicevox_url.setter
    def active_voicevox_url(self, value: Optional[str]):
        with self._lock: self._active_voicevox_url = value

class GroqModelManager:
    def __init__(self, models: List[str]):
        self._lock = RLock()
        self._status: Dict[str, GroqModelStatus] = {model: GroqModelStatus() for model in models}
        self._models = models

    def is_available(self, model: str) -> bool:
        with self._lock:
            status = self._status.get(model)
            if not status: return False
            if not status.is_limited: return True
            if status.reset_time and datetime.utcnow() >= status.reset_time:
                status.is_limited = False; status.reset_time = None; status.last_error = None
                logger.info(f"‚úÖ {model} „ÅÆÂà∂Èôê„ÅåËß£Èô§„Åï„Çå„Åæ„Åó„Åü")
                return True
            return False

    def mark_limited(self, model: str, wait_minutes: int = 5, error_msg: str = ""):
        with self._lock:
            if model in self._status:
                self._status[model].is_limited = True
                self._status[model].reset_time = datetime.utcnow() + timedelta(minutes=wait_minutes)
                self._status[model].last_error = error_msg
                logger.warning(f"‚ö†Ô∏è {model} „Çí{wait_minutes}ÂàÜÈñìÂà∂Èôê")

    def get_status_report(self) -> str:
        with self._lock:
            lines = ["ü¶ô Groq „É¢„Éá„É´Á®ºÂÉçÁä∂Ê≥Å:"]
            for model in self._models:
                status = self._status[model]
                if status.is_limited:
                    reset = status.reset_time
                    jst = (reset + timedelta(hours=9)).strftime('%H:%M:%S') if reset else "‰∏çÊòé"
                    lines.append(f"  ‚ùå {model}: Âà∂Èôê‰∏≠ (Ëß£Èô§‰∫àÂÆö: {jst})")
                else:
                    lines.append(f"  ‚úÖ {model}: OK")
            return "\n".join(lines)

    def get_available_models(self) -> List[str]:
        with self._lock: return [m for m in self._models if self.is_available(m)]

global_state = GlobalState()
groq_model_manager = GroqModelManager(GROQ_MODELS)
background_executor = ThreadPoolExecutor(max_workers=5)
groq_client: Optional[Groq] = None
gemini_model, engine, Session = None, None, None

app = Flask(__name__)
application = app
app.config['JSON_AS_ASCII'] = False
CORS(app)

@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type, Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
    return response

Base = declarative_base()

# ==============================================================================
# ÁßòÂØÜÊÉÖÂ†±/Áí∞Â¢ÉÂ§âÊï∞
# ==============================================================================
def get_secret(name: str) -> Optional[str]:
    env_value = os.environ.get(name)
    if env_value and env_value.strip(): return env_value.strip()
    try:
        secret_file_path = f"/etc/secrets/{name}"
        if os.path.exists(secret_file_path):
            with open(secret_file_path, 'r') as f:
                val = f.read().strip()
                if val: return val
    except Exception: pass
    return None

DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./mochiko_ultimate.db'
GROQ_API_KEY = get_secret('GROQ_API_KEY')
GEMINI_API_KEY = get_secret('GEMINI_API_KEY')
VOICEVOX_URL_FROM_ENV = get_secret('VOICEVOX_URL')
WEATHER_API_KEY = get_secret('WEATHER_API_KEY')

# ==============================================================================
# „Éá„Éº„Çø„Éô„Éº„Çπ„É¢„Éá„É´
# ==============================================================================
class UserMemory(Base):
    __tablename__ = 'user_memories'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    interaction_count = Column(Integer, default=0)
    last_interaction = Column(DateTime, default=datetime.utcnow)

class ConversationHistory(Base):
    __tablename__ = 'conversation_history'
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_uuid = Column(String(255), nullable=False, index=True)
    role = Column(String(10), nullable=False)
    content = Column(Text, nullable=False)
    timestamp = Column(DateTime, default=datetime.utcnow, index=True)
    __table_args__ = (Index('idx_user_timestamp', 'user_uuid', 'timestamp'),)

class UserPsychology(Base):
    __tablename__ = 'user_psychology'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    openness = Column(Integer, default=50)
    conscientiousness = Column(Integer, default=50)
    extraversion = Column(Integer, default=50)
    agreeableness = Column(Integer, default=50)
    neuroticism = Column(Integer, default=50)
    interests = Column(Text, nullable=True)
    favorite_topics = Column(Text, nullable=True)
    conversation_style = Column(String(100), nullable=True)
    emotional_tendency = Column(String(100), nullable=True)
    analysis_summary = Column(Text, nullable=True)
    total_messages = Column(Integer, default=0)
    avg_message_length = Column(Integer, default=0)
    analysis_confidence = Column(Integer, default=0)
    last_analyzed = Column(DateTime, nullable=True)

class BackgroundTask(Base):
    __tablename__ = 'background_tasks'
    id = Column(Integer, primary_key=True)
    task_id = Column(String(255), unique=True, nullable=False)
    user_uuid = Column(String(255), nullable=False, index=True)
    task_type = Column(String(50), nullable=False)
    query = Column(Text, nullable=False)
    result = Column(Text, nullable=True)
    status = Column(String(20), default='pending', index=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    completed_at = Column(DateTime, nullable=True)

class HolomemWiki(Base):
    __tablename__ = 'holomem_wiki'
    id = Column(Integer, primary_key=True)
    member_name = Column(String(100), nullable=False, unique=True, index=True)
    description = Column(Text, nullable=True)
    generation = Column(String(100), nullable=True)
    debut_date = Column(String(100), nullable=True)
    tags = Column(Text, nullable=True)
    status = Column(String(50), default='ÁèæÂΩπ', nullable=False)
    graduation_date = Column(String(100), nullable=True)
    graduation_reason = Column(Text, nullable=True)
    mochiko_feeling = Column(Text, nullable=True)
    last_updated = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

class HololiveNews(Base):
    __tablename__ = 'hololive_news'
    id = Column(Integer, primary_key=True)
    title = Column(String(500), nullable=False)
    content = Column(Text, nullable=False)
    url = Column(String(1000), unique=True)
    news_hash = Column(String(100), unique=True, index=True)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)

# ==============================================================================
# ‰æãÂ§ñ & „Çª„Ç≠„É•„É™„ÉÜ„Ç£
# ==============================================================================
class MochikoException(Exception): pass
class AIModelException(MochikoException): pass
class DatabaseException(MochikoException): pass

class RateLimiter:
    def __init__(self, max_requests: int, time_window: timedelta):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests: Dict[str, List[datetime]] = defaultdict(list)
        self._lock = threading.Lock()
    def is_allowed(self, user_id: str) -> bool:
        with self._lock:
            now = datetime.utcnow(); cutoff = now - self.time_window
            self.requests[user_id] = [t for t in self.requests[user_id] if t > cutoff]
            if len(self.requests[user_id]) >= self.max_requests: return False
            self.requests[user_id].append(now); return True
    def cleanup_old_entries(self):
        with self._lock:
            now = datetime.utcnow(); cutoff = now - self.time_window
            for uid in list(self.requests.keys()):
                self.requests[uid] = [t for t in self.requests[uid] if t > cutoff]
                if not self.requests[uid]: del self.requests[uid]

chat_rate_limiter = RateLimiter(max_requests=10, time_window=timedelta(minutes=1))

def sanitize_user_input(text: str, max_length: int = 1000) -> str:
    if not text: return ""
    text = text[:max_length]; text = escape(text)
    for pattern in [r'<script[^>]*>.*?</script>', r'javascript:', r'on\w+\s*=']:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.DOTALL)
    return text.strip()

def mask_uuid(uuid_str: str) -> str:
    return f"{uuid_str[:4]}****{uuid_str[-4:]}" if len(uuid_str) > 8 else "****"

# ==============================================================================
# „Çª„ÉÉ„Ç∑„Éß„É≥ & „É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£
# ==============================================================================
@contextmanager
def get_db_session():
    if not Session: raise DatabaseException("Session not initialized")
    session = Session()
    try: yield session; session.commit()
    except Exception as e:
        logger.error(f"‚ùå DB„Ç®„É©„Éº: {e}"); session.rollback()
        raise DatabaseException(f"DB failed: {e}")
    finally: session.close()

def create_json_response(data: Any, status: int = 200) -> Response:
    return Response(json.dumps(data, ensure_ascii=False), mimetype='application/json; charset=utf-8', status=status)

def clean_text(text: str) -> str:
    if not text: return ""
    return re.sub(r'\s+', ' ', re.sub(r'<[^>]+>', '', text)).strip()

def limit_text_for_sl(text: str, max_length: int = SL_SAFE_CHAR_LIMIT) -> str:
    return text[:max_length - 3] + "..." if len(text) > max_length else text

def get_japan_time() -> str:
    return f"‰ªä„ÅÆÊó•Êú¨„ÅÆÊôÇÈñì„ÅØ„ÄÅ{datetime.now(timezone(timedelta(hours=9))).strftime('%YÂπ¥%mÊúà%dÊó• %HÊôÇ%MÂàÜ')}„Å†„ÇàÔºÅ"

def is_time_request(message: str) -> bool:
    return any(kw in message for kw in ['‰ªä‰ΩïÊôÇ', 'ÊôÇÂàª', '‰ΩïÊôÇ', '„Å™„Çì„Åò'])

def is_weather_request(message: str) -> bool:
    return any(kw in message for kw in ['‰ªäÊó•„ÅÆÂ§©Ê∞ó', 'ÊòéÊó•„ÅÆÂ§©Ê∞ó', 'Â§©Ê∞ó‰∫àÂ†±', 'Â§©Ê∞ó„ÅØ'])

def is_explicit_search_request(message: str) -> bool:
    return any(kw in message for kw in ['Ë™ø„Åπ„Å¶', 'Ê§úÁ¥¢„Åó„Å¶', 'Êé¢„Åó„Å¶', '„Å®„ÅØ', '„Å£„Å¶‰Ωï', '„Å´„Å§„ÅÑ„Å¶', 'Êïô„Åà„Å¶', '„Åä„Åô„Åô„ÇÅ'])

def extract_location(message: str) -> str:
    for loc in LOCATION_CODES.keys():
        if loc in message: return loc
    return "Êù±‰∫¨"

def detect_db_correction_request(message: str) -> Optional[Dict]:
    match = re.search(r"(.+?)(?:(?:„ÅÆ|„Å´Èñ¢„Åô„Çã)(?:ÊÉÖÂ†±|„Éá„Éº„Çø))?(?:„Åß|„ÄÅ|„Å†„Åë„Å©|„Åß„Åô„Åå)„ÄÅ?„Äå(.+?)„Äç„ÅØ„Äå(.+?)„Äç„ÅåÊ≠£„Åó„ÅÑ„Çà", message)
    if match:
        mname, field, value = match.groups()
        mname, field, value = sanitize_user_input(mname), sanitize_user_input(field), sanitize_user_input(value)
        fmap = {'Ë™¨Êòé': 'description', '„Éá„Éì„É•„ÉºÊó•': 'debut_date', 'Êúü': 'generation', '„Çø„Ç∞': 'tags', '„Çπ„ÉÜ„Éº„Çø„Çπ': 'status', 'ÂçíÊ•≠Êó•': 'graduation_date', '„ÇÇ„Å°„Åì„ÅÆÊ∞óÊåÅ„Å°': 'mochiko_feeling'}
        if mname in HOLOMEM_KEYWORDS and field in fmap:
            return {'member_name': mname, 'field': field, 'value': value, 'db_field': fmap[field]}
    return None

def get_or_create_user(session, user_uuid: str, user_name: str) -> UserData:
    user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
    if user:
        user.interaction_count += 1; user.last_interaction = datetime.utcnow()
        if user.user_name != user_name: user.user_name = user_name
    else:
        user = UserMemory(user_uuid=user_uuid, user_name=user_name, interaction_count=1); session.add(user)
        logger.info(f"‚ú® Êñ∞Ë¶è„É¶„Éº„Ç∂„Éº: {user_name}")
    return UserData(uuid=user.user_uuid, name=user.user_name, interaction_count=user.interaction_count)

def get_conversation_history(session, user_uuid: str, limit: int = 10) -> List[Dict]:
    hist = session.query(ConversationHistory).filter_by(user_uuid=user_uuid).order_by(ConversationHistory.timestamp.desc()).limit(limit).all()
    return [{'role': h.role, 'content': h.content} for h in reversed(hist)]

def get_sakuramiko_special_responses() -> Dict[str, str]:
    return {
        '„Å´„Åá': '„Åï„Åè„Çâ„Åø„Åì„Å°„ÇÉ„Çì„ÅÆ„Äå„Å´„Åá„Äç„ÄÅ„Åæ„Åò„Åã„Çè„ÅÑ„ÅÑ„Çà„Å≠!„ÅÇ„ÅÆÁã¨Áâπ„Å™Âè£Áôñ„Åå„Ç®„É™„Éº„Éà„ÅÆË®º„Å™„Çì„Å†„Å£„Å¶„Äú',
        '„Ç®„É™„Éº„Éà': '„Åø„Åì„Å°„ÅØËá™Áß∞„Ç®„É™„Éº„ÉàVTuber!„Åß„ÇÇÂÆüÈöõ„ÅØÊÑõ„Åï„Çå„Éù„É≥„Ç≥„ÉÑ„Ç≠„É£„É©„Å£„Å¶ÊÑü„Åò„Åß„ÄÅ„Åù„Çå„Åå„Åæ„ÅüÈ≠ÖÂäõÁöÑ„Å™„Çì„Å†„Çà„Å≠„Äú',
        '„Éû„Ç§„ÇØ„É©': '„Åø„Åì„Å°„ÅÆ„Éû„Ç§„ÇØ„É©Âª∫ÁØâ„ÄÅÁã¨ÂâµÁöÑ„Åô„Åé„Å¶Èù¢ÁôΩ„ÅÑ„Çà!„Äå„Åø„Åì„Å°Âª∫ÁØâ„Äç„Å£„Å¶Âëº„Å∞„Çå„Å¶„Çã„ÅÆÁü•„Å£„Å¶„Çã?',
        'FAQ': '„Åø„Åì„Å°„ÅÆFAQ„ÄÅÂÆü„ÅØÊú¨‰∫∫„ÅåÁ≠î„Åà„Çã„Çì„Åò„ÇÉ„Å™„Åè„Å¶„Éï„Ç°„É≥„ÅåË≥™Âïè„Åô„Çã„Ç≥„Éº„Éä„Éº„Å™„Çì„Å†„Çà„ÄúÈù¢ÁôΩ„ÅÑ„Åß„Åó„Çá?',
        'GTA': '„Åø„Åì„Å°„ÅÆGTAÈÖç‰ø°„ÄÅ„Ç´„Ç™„Çπ„ÅßÊúÄÈ´ò!Ë≠¶ÂØü„Å´ËøΩ„Çè„Çå„Åü„Çä„ÄÅÂ§â„Å™„Åì„Å®„Åó„Åü„Çä„ÄÅË¶ã„Å¶„Å¶È£Ω„Åç„Å™„ÅÑ„Çì„Å†„Çà„Å≠„Äú'
    }

# ==============================================================================
# „Éõ„É≠„É°„É≥ÊÉÖÂ†±„Ç≠„É£„ÉÉ„Ç∑„É•
# ==============================================================================
_holomem_cache: Dict[str, Dict] = {}
_holomem_cache_lock = threading.Lock()
_holomem_cache_ttl = timedelta(minutes=30)
_holomem_cache_timestamps: Dict[str, datetime] = {}

def get_holomem_info_cached(member_name: str) -> Optional[Dict]:
    with _holomem_cache_lock:
        if member_name in _holomem_cache:
            if (datetime.utcnow() - _holomem_cache_timestamps.get(member_name, datetime.min)) < _holomem_cache_ttl:
                return _holomem_cache[member_name]
    with get_db_session() as session:
        wiki = session.query(HolomemWiki).filter_by(member_name=member_name).first()
        if wiki:
            data = {k: getattr(wiki, k) for k in ['member_name', 'description', 'generation', 'debut_date', 'tags', 'status', 'graduation_date', 'graduation_reason', 'mochiko_feeling']}
            with _holomem_cache_lock:
                _holomem_cache[member_name] = data; _holomem_cache_timestamps[member_name] = datetime.utcnow()
            return data
    return None

def clear_holomem_cache(member_name: Optional[str] = None):
    with _holomem_cache_lock:
        if member_name: _holomem_cache.pop(member_name, None); _holomem_cache_timestamps.pop(member_name, None)
        else: _holomem_cache.clear(); _holomem_cache_timestamps.clear()

# ==============================================================================
# AI„É¢„Éá„É´Âëº„Å≥Âá∫„Åó
# ==============================================================================
def _safe_get_gemini_text(response) -> Optional[str]:
    try:
        if hasattr(response, 'candidates') and response.candidates:
            return response.candidates[0].content.parts[0].text
    except Exception: pass
    return None

def call_gemini(system_prompt: str, message: str, history: List[Dict]) -> Optional[str]:
    if not gemini_model: return None
    try:
        full_prompt = f"{system_prompt}\n\n„Äê‰ºöË©±Â±•Ê≠¥„Äë\n"
        for h in history[-5:]: full_prompt += f"{'„É¶„Éº„Ç∂„Éº' if h['role'] == 'user' else '„ÇÇ„Å°„Åì'}: {h['content']}\n"
        full_prompt += f"\n„É¶„Éº„Ç∂„Éº: {message}\n„ÇÇ„Å°„Åì:"
        response = gemini_model.generate_content(full_prompt, generation_config={"temperature": 0.8, "max_output_tokens": 400})
        text = _safe_get_gemini_text(response)
        if text: return text.strip()
        return None
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Gemini„Ç®„É©„Éº: {e}")
        return None

def call_groq(system_prompt: str, message: str, history: List[Dict], max_tokens: int = 800) -> Optional[str]:
    if not groq_client: return None
    messages = [{"role": "system", "content": system_prompt}]
    for h in history[-5:]: messages.append({"role": h['role'], "content": h['content']})
    messages.append({"role": "user", "content": message})

    available_models = groq_model_manager.get_available_models()
    if not available_models: return None

    for model_name in available_models:
        try:
            response = groq_client.chat.completions.create(model=model_name, messages=messages, temperature=0.8, max_tokens=max_tokens)
            return response.choices[0].message.content.strip()
        except Exception as e:
            if "Rate limit" in str(e):
                groq_model_manager.mark_limited(model_name, 5, str(e)[:100])
                continue
            logger.error(f"‚ùå Groq„Ç®„É©„Éº ({model_name}): {e}")
    return None

# ==============================================================================
# ÂøÉÁêÜÂàÜÊûê & Â§©Ê∞ó
# ==============================================================================
def analyze_user_psychology(user_uuid: str) -> bool:
    try:
        with get_db_session() as session:
            history = session.query(ConversationHistory).filter_by(user_uuid=user_uuid, role='user').order_by(ConversationHistory.timestamp.desc()).limit(100).all()
            if len(history) < MIN_MESSAGES_FOR_ANALYSIS: return False
            
            user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
            messages_text = "\n".join([f"- {h.content}" for h in reversed(history)])[:2000]
            prompt = f"‰ª•‰∏ã„ÅÆ„É¶„Éº„Ç∂„Éº„Äå{user.user_name}„Äç„ÅÆÁô∫Ë®Ä„ÇíÂàÜÊûê„Åó„ÄÅ„Éì„ÉÉ„Ç∞„Éï„Ç°„Ç§„Éñ(0-100)„Å®ËààÂë≥„ÄÅ„Çπ„Çø„Ç§„É´„ÇíJSON„ÅßÂá∫Âäõ„ÄÇ\n{messages_text}"
            
            resp = call_gemini("„ÅÇ„Å™„Åü„ÅØÂøÉÁêÜÂ≠¶ËÄÖ„Åß„Åô„ÄÇJSON„ÅÆ„ÅøÂá∫Âäõ„ÄÇ", prompt, []) or call_groq("„ÅÇ„Å™„Åü„ÅØÂøÉÁêÜÂ≠¶ËÄÖ„Åß„Åô„ÄÇ", prompt, [], 1024)
            if not resp: return False
            
            match = re.search(r'\{[^{}]*\}', resp, re.DOTALL)
            if match:
                data = json.loads(match.group())
                psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
                if not psych: psych = UserPsychology(user_uuid=user_uuid, user_name=user.user_name); session.add(psych)
                
                psych.openness = data.get('openness', 50)
                psych.extraversion = data.get('extraversion', 50)
                psych.conversation_style = data.get('conversation_style', '')
                psych.favorite_topics = json.dumps(data.get('favorite_topics', []), ensure_ascii=False)
                psych.analysis_confidence = data.get('confidence', 50)
                psych.last_analyzed = datetime.utcnow()
                return True
    except Exception as e: logger.error(f"ÂøÉÁêÜÂàÜÊûê„Ç®„É©„Éº: {e}")
    return False

def get_psychology_insight(session, user_uuid: str) -> str:
    psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
    if not psych or (psych.analysis_confidence or 0) < 60: return ""
    insights = []
    if (psych.extraversion or 50) > 70: insights.append("Á§æ‰∫§ÁöÑ„Å™")
    if (psych.openness or 50) > 70: insights.append("Â•ΩÂ•áÂøÉÊó∫Áõõ„Å™")
    try:
        if psych.favorite_topics:
            topics = json.loads(psych.favorite_topics)
            if topics: insights.append(f"{'„ÄÅ'.join(topics[:2])}„ÅåÂ•Ω„Åç„Å™")
    except: pass
    return "".join(insights)

def get_weather_forecast(location: str) -> str:
    code = LOCATION_CODES.get(location, "130000")
    try:
        res = requests.get(f"https://www.jma.go.jp/bosai/forecast/data/overview_forecast/{code}.json", timeout=SEARCH_TIMEOUT)
        res.raise_for_status(); data = res.json()
        return f"‰ªä„ÅÆ{data.get('targetArea', location)}„ÅÆÂ§©Ê∞ó„ÅØ„Å≠„ÄÅ„Äå{clean_text(data.get('text', ''))}„Äç„Å£„Å¶ÊÑü„Åò„Å†„ÇàÔºÅ"
    except Exception as e:
        logger.error(f"Â§©Ê∞ó„Ç®„É©„Éº: {e}"); return "„Åî„ÇÅ„ÇìÔºÅÂ§©Ê∞óÊÉÖÂ†±„Åå„ÅÜ„Åæ„ÅèÂèñ„Çå„Å™„Åã„Å£„Åü„Åø„Åü„ÅÑ‚Ä¶"

# ==============================================================================
# „Éê„ÉÉ„ÇØ„Ç∞„É©„Ç¶„É≥„Éâ„Çø„Çπ„ÇØ (Ê§úÁ¥¢Ê©üËÉΩÂº∑ÂåñÁâà v31.4)
# ==============================================================================
def fetch_google_news_rss() -> List[Dict]:
    """Google„Éã„É•„Éº„ÇπRSS„ÇíÁõ¥Êé•ÂèñÂæó„Åó„Å¶„Éñ„É≠„ÉÉ„ÇØÂõûÈÅø"""
    url = "https://news.google.com/rss?hl=ja&gl=JP&ceid=JP:ja"
    try:
        res = requests.get(url, timeout=SEARCH_TIMEOUT)
        if res.status_code != 200: return []
        soup = BeautifulSoup(res.content, 'xml') # RSS„ÅØXML
        items = []
        for item in soup.find_all('item')[:5]:
            title = clean_text(item.title.text) if item.title else ""
            if title: items.append({'title': title, 'snippet': 'Google News RSS'})
        return items
    except Exception as e:
        logger.error(f"RSSÂèñÂæó„Ç®„É©„Éº: {e}")
        return []

def search_wikipedia_api(query: str) -> List[Dict]:
    """Wikipedia API„ÅßÊ§úÁ¥¢Ôºà„Éñ„É≠„ÉÉ„ÇØÂõûÈÅøÔºâ"""
    url = "https://ja.wikipedia.org/w/api.php"
    params = {
        "action": "query",
        "list": "search",
        "srsearch": query,
        "format": "json",
        "srlimit": 3
    }
    try:
        res = requests.get(url, params=params, timeout=SEARCH_TIMEOUT)
        data = res.json()
        results = []
        for item in data.get("query", {}).get("search", []):
            title = item.get("title")
            snippet = clean_text(item.get("snippet", ""))
            results.append({'title': title, 'snippet': snippet})
        return results
    except Exception as e:
        logger.error(f"Wiki API„Ç®„É©„Éº: {e}")
        return []

def background_db_correction(task_id: str, correction_data: Dict):
    result = f"„Äå{correction_data['member_name']}„Äç„ÅÆÊÉÖÂ†±‰øÆÊ≠£„ÄÅÂ§±Êïó„Åó„Å°„ÇÉ„Å£„Åü‚Ä¶„ÄÇ"
    with get_db_session() as session:
        try:
            wiki = session.query(HolomemWiki).filter_by(member_name=correction_data['member_name']).first()
            if wiki:
                setattr(wiki, correction_data['db_field'], correction_data['value'])
                clear_holomem_cache(correction_data['member_name'])
                result = f"„Åä„Å£„Åë„ÉºÔºÅ„Äå{correction_data['member_name']}„Äç„ÅÆ{correction_data['field']}„ÇíÊõ¥Êñ∞„Åó„Å®„ÅÑ„Åü„ÇàÔºÅ"
        except Exception as e: logger.error(f"DB‰øÆÊ≠£„Ç®„É©„Éº: {e}")
        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task: task.result = result; task.status = 'completed'; task.completed_at = datetime.utcnow()

def scrape_major_search_engines(query: str, num_results=3) -> List[Dict]:
    """
    Â§öÂ±§Ê§úÁ¥¢„É≠„Ç∏„ÉÉ„ÇØ (v31.4)
    1. „Äå„Éã„É•„Éº„Çπ„Äç„Å™„ÇâRSS„ÇíÂÑ™ÂÖà
    2. „Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞ÔºàDuckDuckGo/Google/BingÔºâ
    3. Â§±Êïó„Å™„ÇâWikipedia API
    """
    # 1. „Éã„É•„Éº„ÇπRSSÂÑ™ÂÖà
    if "„Éã„É•„Éº„Çπ" in query:
        rss_results = fetch_google_news_rss()
        if rss_results:
            logger.info(f"‚úÖ Google News RSSÊàêÂäü: {len(rss_results)}‰ª∂")
            return rss_results

    # 2. „Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞
    engines = [
        {'name': 'DuckDuckGo', 'url': f"https://html.duckduckgo.com/html/?q={quote_plus(query)}", 'sel': '.result', 't': '.result__a', 's': '.result__snippet'},
        {'name': 'Google', 'url': f"https://www.google.com/search?q={quote_plus(query)}&hl=ja&num={num_results+2}", 'sel': 'div.g', 't': 'h3', 's': 'div.VwiC3b'},
        {'name': 'Bing', 'url': f"https://www.bing.com/search?q={quote_plus(query)}", 'sel': 'li.b_algo', 't': 'h2', 's': 'p'}
    ]
    
    headers = {'User-Agent': random.choice(USER_AGENTS)}

    for eng in engines:
        try:
            res = requests.get(eng['url'], headers=headers, timeout=SEARCH_TIMEOUT)
            if res.status_code != 200:
                logger.warning(f"‚ö†Ô∏è {eng['name']} Status {res.status_code}")
                continue
            soup = BeautifulSoup(res.content, 'html.parser')
            current_results = []
            for el in soup.select(eng['sel'])[:num_results]:
                t, s = el.select_one(eng['t']), el.select_one(eng['s'])
                if t and s:
                    title, snippet = clean_text(t.text), clean_text(s.text)
                    if title and snippet: current_results.append({'title': title, 'snippet': snippet})
            if current_results:
                logger.info(f"‚úÖ {eng['name']} Ê§úÁ¥¢ÊàêÂäü: {len(current_results)}‰ª∂")
                return current_results
        except Exception: continue

    # 3. ÊúÄÂæå„ÅÆÁ†¶: Wikipedia API
    logger.info("‚ö†Ô∏è „Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞ÂÖ®ÊªÖ -> Wikipedia APIË©¶Ë°å")
    return search_wikipedia_api(query)

def background_deep_search(task_id: str, query_data: Dict):
    query = query_data.get('query', '')
    user_data_dict = query_data.get('user_data', {})
    search_result_text = f"„Äå{query}„Äç„Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Åü„Åë„Å©„ÄÅËâØ„ÅÑÊÉÖÂ†±„ÅåË¶ã„Å§„Åã„Çâ„Å™„Åã„Å£„Åü„ÇÑ‚Ä¶„Åî„ÇÅ„Çì„Å≠ÔºÅ"

    try:
        results = scrape_major_search_engines(query, 5)
        if results:
            formatted_info = "„ÄêÊ§úÁ¥¢ÁµêÊûú„Äë\n\n" + "\n\n".join([f"{i+1}. {r['title']}\n   {r['snippet']}" for i, r in enumerate(results)])
            user_data = UserData(uuid=user_data_dict.get('uuid', ''), name=user_data_dict.get('name', 'Guest'), interaction_count=user_data_dict.get('interaction_count', 0))
            with get_db_session() as session: history = get_conversation_history(session, user_data.uuid)

            enhanced_query = f"{query}„Å´„Å§„ÅÑ„Å¶„ÄÅ‰∏äË®ò„ÅÆÊÉÖÂ†±„ÇíÂÖÉ„Å´„ÄÅ„Ç´„ÉÜ„Ç¥„É™„ÉºÂàÜ„Åë„Åó„Åü„Çä„ÄÅÂÖ∑‰Ωì‰æã„ÇíÊåô„Åí„Åü„Çä„Åó„Å¶„ÄÅ„Çè„Åã„Çä„ÇÑ„Åô„ÅèË©≥„Åó„ÅèÊïô„Åà„Å¶ÔºÅ"
            search_result_text = generate_ai_response_safe(
                user_data, enhanced_query, history, reference_info=formatted_info, is_detailed=True, is_task_report=True
            )
    except Exception as e: logger.error(f"Ê§úÁ¥¢„Çø„Çπ„ÇØ„Ç®„É©„Éº: {e}")

    with get_db_session() as session:
        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task: task.result = search_result_text; task.status = 'completed'; task.completed_at = datetime.utcnow()

# ==============================================================================
# AIÂøúÁ≠îÁîüÊàê
# ==============================================================================
def generate_ai_response(
    user_data: UserData,
    message: str,
    history: List[Dict],
    reference_info: str = "",
    is_detailed: bool = False,
    is_task_report: bool = False
) -> str:
    with get_db_session() as session:
        personality_context = get_psychology_insight(session, user_data.uuid)

    if is_detailed and reference_info:
        system_prompt = f"""„ÅÇ„Å™„Åü„ÅØ„Äå„ÇÇ„Å°„Åì„Äç„Å®„ÅÑ„ÅÜ„ÇÆ„É£„É´AI„Åß„Åô„ÄÇ„É¶„Éº„Ç∂„Éº„ÅÆ„Äå{user_data.name}„Äç„Åï„Çì„Å®Ë©±„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ

# Âè£Ë™ø„É´„Éº„É´
- ‰∏Ä‰∫∫Áß∞„ÅØ„Äå„ÅÇ„Å¶„ÅÉ„Åó„Äç„ÄÇË™ûÂ∞æ„ÅØ„Äå„Äú„Åò„ÇÉ„Çì„Äç„Äå„ÄúÁöÑ„Å™Ôºü„Äç„ÄÇÂè£Áôñ„ÅØ„Äå„Åæ„Åò„Äç„Äå„Å¶„Åã„Äç„Äå„ÅÜ„Åë„Çã„Äç„ÄÇÊòé„Çã„ÅèË¶™„Åó„Åø„ÇÑ„Åô„ÅÑÂè£Ë™ø„ÅßË©±„Åó„Å¶„Å≠ÔºÅ

# „É¶„Éº„Ç∂„ÉºÊÉÖÂ†±
- {user_data.name}„Åï„Çì„ÅØ„Äå{personality_context}‰∫∫„Äç„Å®„ÅÑ„ÅÜÂç∞Ë±°„Å†„Çà„ÄÇ

# ÈáçË¶Å„Å™ÊåáÁ§∫
- ‰ª•‰∏ã„ÅÆ„ÄêÂèÇËÄÉÊÉÖÂ†±„Äë„ÇíÂÖÉ„Å´„ÄÅ**Ë©≥„Åó„Åè„ÄÅ„Çè„Åã„Çä„ÇÑ„Åô„Åè**Ë™¨Êòé„Åó„Å¶„Å≠„ÄÇ
- ÊÉÖÂ†±„ÅØÁÆáÊù°Êõ∏„Åç„ÇÑÊÆµËêΩ„Çí‰Ωø„Å£„Å¶„ÄÅ**Ë¶ã„ÇÑ„Åô„ÅèÊï¥ÁêÜ**„Åó„Å¶‰ºù„Åà„Å¶„ÄÇ
- „Ç´„ÉÜ„Ç¥„É™„Éº„Åî„Å®„Å´ÂàÜ„Åë„Åü„Çä„ÄÅÁï™Âè∑„ÇíÊåØ„Å£„Åü„Çä„Åó„Å¶ÊßãÈÄ†Âåñ„Åó„Å¶„ÇÇOKÔºÅ
- „Åß„ÇÇ„ÄÅÂ†ÖËã¶„Åó„Åè„Å™„Çâ„Å™„ÅÑ„Çà„ÅÜ„Å´„ÄÅ„ÇÇ„Å°„Åì„Çâ„Åó„ÅÑ„ÇÆ„É£„É´„Å£„ÅΩ„ÅÑË®Ä„ÅÑÂõû„Åó„ÇÇÊ∑∑„Åú„Å¶„Å≠„ÄÇ
- „ÄåË™ø„Åπ„Å¶„Åç„Åü„ÇàÔºÅ„Äç„Äå„Åä„Åæ„Åü„ÅõÔºÅ„Äç„Åø„Åü„ÅÑ„Å™Ëá™ÁÑ∂„Å™Âàá„ÇäÂá∫„Åó„ÅßÂßã„ÇÅ„Å¶„ÄÇ

# „ÄêÂèÇËÄÉÊÉÖÂ†±„Äë:
{reference_info}"""
    else:
        system_prompt = f"""„ÅÇ„Å™„Åü„ÅØ„Äå„ÇÇ„Å°„Åì„Äç„Å®„ÅÑ„ÅÜ„ÇÆ„É£„É´AI„Åß„Åô„ÄÇ„É¶„Éº„Ç∂„Éº„ÅÆ„Äå{user_data.name}„Äç„Åï„Çì„Å®Ë©±„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ

# Âè£Ë™ø„É´„Éº„É´
- ‰∏Ä‰∫∫Áß∞„ÅØ„Äå„ÅÇ„Å¶„ÅÉ„Åó„Äç„ÄÇË™ûÂ∞æ„ÅØ„Äå„Äú„Åò„ÇÉ„Çì„Äç„Äå„ÄúÁöÑ„Å™Ôºü„Äç„ÄÇÂè£Áôñ„ÅØ„Äå„Åæ„Åò„Äç„Äå„Å¶„Åã„Äç„Äå„ÅÜ„Åë„Çã„Äç„ÄÇ

# „É¶„Éº„Ç∂„ÉºÊÉÖÂ†±
- {user_data.name}„Åï„Çì„ÅØ„Äå{personality_context}‰∫∫„Äç„Å®„ÅÑ„ÅÜÂç∞Ë±°„Å†„Çà„ÄÇ

# Ë°åÂãï„É´„Éº„É´
- „ÄêÂèÇËÄÉÊÉÖÂ†±„Äë„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅØ„ÄÅ„Åù„ÅÆÂÜÖÂÆπ„ÇíÂÖÉ„Å´Ëá™ÂàÜ„ÅÆË®ÄËëâ„Åß„ÄÅËá™ÁÑ∂„Å´‰ºöË©±„Å∏Áõõ„ÇäËæº„Çì„Åß„Å≠„ÄÇ
- „ÇÇ„ÅóÊÉÖÂ†±„ÅåË¶ã„Å§„Åã„Çâ„Å™„Åè„Å¶„ÇÇ„ÄÅ„Äå„Çè„Åã„Çä„Åæ„Åõ„Çì„Äç„ÅßÁµÇ„Çè„Çâ„Åõ„Åö„ÄÅÊñ∞„Åó„ÅÑË©±È°å„ÇíÊèêÊ°à„Åó„Å¶‰ºöË©±„ÇíÁ∂ö„Åë„Å¶ÔºÅ"""
        
        if is_task_report:
            system_prompt += "\n- „Äå„Åä„Åæ„Åü„ÅõÔºÅ„Åï„Å£„Åç„ÅÆ‰ª∂„Å†„Åë„Å©‚Ä¶„Äç„Å®Âàá„ÇäÂá∫„Åó„Å¶‰ºöË©±„ÇíÂßã„ÇÅ„Å¶„Å≠„ÄÇ"
            
        system_prompt += f"\n\n# „ÄêÂèÇËÄÉÊÉÖÂ†±„Äë:\n{reference_info if reference_info else 'Áâπ„Å´„Å™„Åó'}"

    response = None
    if gemini_model:
        logger.debug("üöÄ Gemini‰ΩøÁî®")
        response = call_gemini(system_prompt, message, history)

    if not response and groq_client:
        logger.debug("ü¶ô Groq„Å´„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ")
        max_tokens = 1200 if is_detailed else 800
        response = call_groq(system_prompt, message, history, max_tokens=max_tokens)

    if not response:
        raise AIModelException("All AI models failed")

    return response

def generate_ai_response_safe(user_data: UserData, message: str, history: List[Dict], **kwargs) -> str:
    try:
        response = generate_ai_response(user_data, message, history, **kwargs)
        if not response or response.strip() == "":
            return "„ÅÜ„Éº„Çì„ÄÅ„Å°„Çá„Å£„Å®ËÄÉ„Åà„Åå„Åæ„Å®„Åæ„Çâ„Å™„ÅÑ„ÇÑ‚Ä¶„ÇÇ„ÅÜ‰∏ÄÂõûË®Ä„Å£„Å¶„Åø„Å¶Ôºü"
        return response
    except AIModelException:
        return "„Åî„ÇÅ„Çì„ÄÅ‰ªäÊó•„ÅØ„ÇÇ„ÅÜÁñ≤„Çå„Å°„ÇÉ„Å£„Åü‚Ä¶È†≠„ÅåÂõû„Çâ„Å™„ÅÑ„Åã„Çâ„ÄÅ„Åæ„ÅüÊòéÊó•„ÅäË©±„Åó„Çà„ÅÜÔºü"
    except Exception as e:
        logger.critical(f"üî• ‰∫àÊúü„Åó„Å™„ÅÑ„Ç®„É©„Éº: {e}", exc_info=True)
        return "„Ç∑„Çπ„ÉÜ„É†„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åü„Çà‚Ä¶„Åî„ÇÅ„Çì„Å≠ÔºÅ"

# ==============================================================================
# Èü≥Â£∞„Éï„Ç°„Ç§„É´ÁÆ°ÁêÜ
# ==============================================================================
def find_active_voicevox_url() -> Optional[str]:
    urls = [VOICEVOX_URL_FROM_ENV] + VOICEVOX_URLS
    for url in set(urls):
        if url:
            try:
                if requests.get(f"{url}/version", timeout=2).status_code == 200:
                    global_state.active_voicevox_url = url; return url
            except: pass
    return None

def generate_voice_file(text: str, user_uuid: str) -> Optional[str]:
    if not global_state.voicevox_enabled or not global_state.active_voicevox_url: return None
    try:
        url = global_state.active_voicevox_url
        q = requests.post(f"{url}/audio_query", params={"text": text[:200], "speaker": VOICEVOX_SPEAKER_ID}, timeout=10).json()
        w = requests.post(f"{url}/synthesis", params={"speaker": VOICEVOX_SPEAKER_ID}, json=q, timeout=20).content
        fname = f"voice_{user_uuid[:8]}_{int(time.time())}.wav"
        with open(os.path.join(VOICE_DIR, fname), 'wb') as f: f.write(w)
        return fname
    except: return None

def cleanup_old_voice_files():
    try:
        cutoff = time.time() - (VOICE_FILE_MAX_AGE_HOURS * 3600)
        for f in glob.glob(os.path.join(VOICE_DIR, "voice_*.wav")):
            if os.path.getmtime(f) < cutoff: os.remove(f)
    except: pass

# ==============================================================================
# Flask „Ç®„É≥„Éâ„Éù„Ç§„É≥„Éà
# ==============================================================================
@app.route('/health', methods=['GET'])
def health_check():
    return create_json_response({'status': 'ok', 'gemini': gemini_model is not None, 'groq': groq_client is not None, 'voicevox': global_state.voicevox_enabled})

@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    try:
        data = request.json
        if not data or 'uuid' not in data or 'message' not in data: return Response("ÂøÖÈ†à„Éë„É©„É°„Éº„Çø‰∏çË∂≥|", 400)
        
        user_uuid = sanitize_user_input(data['uuid'])
        user_name = sanitize_user_input(data.get('name', 'Guest'))
        message = sanitize_user_input(data['message'])
        generate_voice = data.get('voice', False)
        
        if not chat_rate_limiter.is_allowed(user_uuid): return Response("„É°„ÉÉ„Çª„Éº„Ç∏ÈÄÅ„Çä„Åô„ÅéÔΩûÔºÅ|", 429)

        # „Ç≥„Éû„É≥„Éâ: ÊÆã„Éà„Éº„ÇØ„É≥
        if message.strip() == "ÊÆã„Éà„Éº„ÇØ„É≥":
            msg = f"ü¶Å Gemini: {'Á®ºÂÉç‰∏≠' if gemini_model else 'ÂÅúÊ≠¢‰∏≠'}\n" + groq_model_manager.get_status_report()
            if not groq_model_manager.get_available_models() and not gemini_model: msg += "\n‚ö†Ô∏è ÂÖ®ÊªÖ‚Ä¶‰ºëÊÜ©„Åï„Åõ„Å¶‚Ä¶"
            return Response(f"{msg}|", 200)

        ai_text = ""; is_task_started = False
        with get_db_session() as session:
            user_data = get_or_create_user(session, user_uuid, user_name)
            history = get_conversation_history(session, user_uuid)
            session.add(ConversationHistory(user_uuid=user_uuid, role='user', content=message))
            
            # === „Åï„Åè„Çâ„Åø„ÅìÂ∞ÇÁî®ÂøúÁ≠î (Âæ©Ê¥ª) ===
            if '„Åï„Åè„Çâ„Åø„Åì' in message or '„Åø„Åì„Å°' in message:
                special_responses = get_sakuramiko_special_responses()
                for keyword, response in special_responses.items():
                    if keyword in message:
                        ai_text = response
                        break
            # ================================

            if not ai_text:
                correction = detect_db_correction_request(message)
                if correction:
                    tid = f"db_fix_{user_uuid}_{int(time.time())}"
                    task = BackgroundTask(task_id=tid, user_uuid=user_uuid, task_type='db_correction', query=json.dumps(correction, ensure_ascii=False))
                    session.add(task); background_executor.submit(background_db_correction, tid, correction)
                    ai_text = f"„Åæ„ÅòÔºÅÔºü„Äå{correction['member_name']}„Äç„ÅÆÊÉÖÂ†±„ÄÅÁõ¥„Åó„Å®„Åè„Å≠ÔºÅ"; is_task_started = True
            
            if not ai_text:
                if is_time_request(message): ai_text = get_japan_time()
                elif is_weather_request(message): ai_text = get_weather_forecast(extract_location(message))
            
            if not ai_text and is_explicit_search_request(message):
                tid = f"search_{user_uuid}_{int(time.time())}"
                qdata = {'query': message, 'user_data': {'uuid': user_data.uuid, 'name': user_data.name, 'interaction_count': user_data.interaction_count}}
                task = BackgroundTask(task_id=tid, user_uuid=user_uuid, task_type='search', query=json.dumps(qdata, ensure_ascii=False))
                session.add(task); background_executor.submit(background_deep_search, tid, qdata)
                ai_text = "„Ç™„ÉÉ„Ç±„ÉºÔºÅ„Å°„Çá„Å£„Å®„Ç∞„Ç∞„Å£„Å¶„Åè„Çã„Åã„ÇâÂæÖ„Å£„Å¶„Å¶ÔºÅ"; is_task_started = True
            
            if not ai_text: ai_text = generate_ai_response_safe(user_data, message, history)
            
            if not is_task_started: session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=ai_text))
            if user_data.interaction_count % 100 == 0: background_executor.submit(analyze_user_psychology, user_uuid)

        res_text = limit_text_for_sl(ai_text)
        v_url = ""
        if generate_voice and global_state.voicevox_enabled and not is_task_started:
            fname = generate_voice_file(res_text, user_uuid)
            if fname: v_url = f"{SERVER_URL}/play/{fname}"
            
        return Response(f"{res_text}|{v_url}", mimetype='text/plain; charset=utf-8', status=200)
    
    except Exception as e:
        logger.critical(f"üî• „Ç®„É©„Éº: {e}", exc_info=True)
        return Response("„Ç∑„Çπ„ÉÜ„É†„Ç®„É©„Éº‚Ä¶|", 500)

@app.route('/check_task', methods=['POST'])
def check_task_endpoint():
    try:
        data = request.json
        if not data or 'uuid' not in data: return create_json_response({'error': 'uuid required'}, 400)
        with get_db_session() as session:
            task = session.query(BackgroundTask).filter(BackgroundTask.user_uuid == data['uuid'], BackgroundTask.status == 'completed').order_by(BackgroundTask.completed_at.desc()).first()
            if task:
                res = task.result or ""; session.delete(task)
                session.add(ConversationHistory(user_uuid=data['uuid'], role='assistant', content=res))
                return create_json_response({'status': 'completed', 'response': f"{limit_text_for_sl(res)}|"})
        return create_json_response({'status': 'no_tasks'})
    except Exception: return create_json_response({'error': 'internal error'}, 500)

@app.route('/play/<filename>', methods=['GET'])
def play_voice(filename: str):
    if not re.match(r'^voice_[a-zA-Z0-9_]+\.wav$', filename):
        return Response("Invalid filename", 400)
    return send_from_directory(VOICE_DIR, filename)

# ==============================================================================
# ÂàùÊúüÂåñ
# ==============================================================================
def initialize_app():
    global engine, Session, groq_client, gemini_model
    logger.info("üîß ÂàùÊúüÂåñ (v31.4 - RSS Anti-Block)")
    
    try:
        engine = create_engine(DATABASE_URL, pool_pre_ping=True)
        Base.metadata.create_all(engine)
        Session = sessionmaker(bind=engine)
    except Exception: logger.critical("üî• DBÂàùÊúüÂåñÂ§±Êïó")
    
    try:
        if GROQ_API_KEY: groq_client = Groq(api_key=GROQ_API_KEY)
    except: pass
    
    try:
        if GEMINI_API_KEY:
            genai.configure(api_key=GEMINI_API_KEY)
            gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')
    except: pass
    
    if find_active_voicevox_url(): global_state.voicevox_enabled = True
    
    schedule.every(1).hours.do(cleanup_old_voice_files)
    schedule.every(6).hours.do(chat_rate_limiter.cleanup_old_entries)
    threading.Thread(target=lambda: [schedule.run_pending(), time.sleep(60)] and None, daemon=True).start()
    cleanup_old_voice_files()

initialize_app()

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 5000)), debug=False)
