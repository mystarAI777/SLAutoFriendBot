# ==============================================================================
# ã‚‚ã¡ã“AI - v33.2.0 + ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºæ©Ÿèƒ½ + SNSãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±é€£æº
#
# ãƒ™ãƒ¼ã‚¹: v33.1.1 (å…¨æ©Ÿèƒ½ä¿æŒ)
# è¿½åŠ æ©Ÿèƒ½:
# 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ãƒˆãƒ”ãƒƒã‚¯åˆ†æã¨è©±é¡Œææ¡ˆ (v33.1.1)
# 2. å¿ƒç†åˆ†æçµæœã‚’AIå¿œç­”ã«åæ˜  (v33.1.1)
# 3. ä¼šè©±å›æ•°ã«å¿œã˜ãŸé–¢ä¿‚æ€§ã®æ·±åŒ–ï¼ˆå‹é”èªå®šã‚·ã‚¹ãƒ†ãƒ ï¼‰ (v33.1.1)
# 4. Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ã«ã‚ˆã‚‹ãƒ›ãƒ­ãƒ¡ãƒ³SNSæƒ…å ±åé›†ãƒ»ä¼šè©±åæ˜  (v33.2.0 NEW)
#
# ä¿®æ­£å±¥æ­´:
# - DBã‚¹ã‚­ãƒ¼ãƒè‡ªå‹•ä¿®å¾©æ©Ÿèƒ½ã®å¼·åŒ– (recent_activityã‚«ãƒ©ãƒ å¯¾å¿œ)
# å¤‰æ›´ç‚¹:
# 1. å…¨8æ®µéšã®ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ (Gemini 2.0å„ªå…ˆ)
# 2. å†…å®¹ã®è¤‡é›‘åº¦ã«å¿œã˜ãŸè‡ªå‹•ãƒ¢ãƒ‡ãƒ«æŒ¯ã‚Šåˆ†ã‘ (æ—¥å¸¸/è¤‡é›‘)
# 3. ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹æ‹¡å……: Linden Lab (Second Life), CGWORLD (CG/3D)
# 4. è©±é¡Œé€¸ã‚‰ã—é˜²æ­¢ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆ¶å¾¡
# 5. ã‚¨ãƒ©ãƒ¼ãƒ¢ãƒ‡ãƒ«ã®ä¸€æ™‚ã‚¹ã‚­ãƒƒãƒ—æ©Ÿèƒ½ (ãƒªãƒˆãƒ©ã‚¤ã®ç„¡é§„ã‚’æ’é™¤)
# ===== æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
import sys
import os
import requests
import logging
import time
import json
import re
import random
import uuid
import hashlib
import unicodedata
import traceback
import threading
import atexit
import glob
from html import escape
from datetime import datetime, timedelta, timezone
from urllib.parse import quote_plus, urljoin, urlparse
from functools import wraps, lru_cache
from threading import Lock, RLock
from concurrent.futures import ThreadPoolExecutor
from collections import OrderedDict, defaultdict
from contextlib import contextmanager
from dataclasses import dataclass, field
from typing import Optional, Dict, List, Any

# ===== ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
from flask import Flask, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Text, Boolean, Index, text
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy import pool
from bs4 import BeautifulSoup
import schedule
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from groq import Groq

# ==============================================================================
# åŸºæœ¬è¨­å®šã¨ãƒ­ã‚®ãƒ³ã‚°
# ==============================================================================
log_file_path = '/tmp/mochiko.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(funcName)s:%(lineno)d] - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(log_file_path, encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ==============================================================================
# å®šæ•°è¨­å®š & ãƒ¢ãƒ‡ãƒ«è¨­å®š
# ==============================================================================
VOICE_DIR = '/tmp/voices'
os.makedirs(VOICE_DIR, exist_ok=True)

SERVER_URL = os.environ.get('RENDER_EXTERNAL_URL', "http://localhost:5000")
VOICEVOX_SPEAKER_ID = 20
SL_SAFE_CHAR_LIMIT = 600
MIN_MESSAGES_FOR_ANALYSIS = 10
SEARCH_TIMEOUT = 10
VOICE_FILE_MAX_AGE_HOURS = 24

# â˜… ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºè¨­å®š
FRIEND_THRESHOLD = 5  # ã“ã®å›æ•°ä»¥ä¸Šã§å‹é”èªå®š
ANALYSIS_INTERVAL = 5  # ã“ã®å›æ•°ã”ã¨ã«å¿ƒç†åˆ†æã‚’å®Ÿè¡Œ
TOPIC_SUGGESTION_INTERVAL = 10  # ã“ã®å›æ•°ã”ã¨ã«è©±é¡Œã‚’ææ¡ˆ

# ==============================================================================
# ã€å¤‰æ›´2ã€‘GEMINI_MODELS å®šæ•°ã‚’è¿½åŠ ï¼ˆè¡Œ80ä»˜è¿‘ï¼‰
# ==============================================================================
GEMINI_MODELS = [
    "gemini-1.5-flash",      # æœ€ã‚‚å®‰å®š
    "gemini-1.5-flash-8b",   # è»½é‡ç‰ˆ
    "gemini-2.0-flash-exp",  # å®Ÿé¨“ç‰ˆï¼ˆåˆ¶é™å³ã—ã„ï¼‰
]
GROQ_MODELS = [
    "llama-3.3-70b-versatile",
    "llama-3.1-70b-versatile",
    "llama-3.1-8b-instant",
    "mixtral-8x7b-32768",
    "gemma2-9b-it"
]

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:125.0) Gecko/20100101 Firefox/125.0',
]

LOCATION_CODES = {"æ±äº¬": "130000", "å¤§é˜ª": "270000", "åå¤å±‹": "230000", "ç¦å²¡": "400000", "æœ­å¹Œ": "016000"}

VOICEVOX_URLS = ['http://voicevox-engine:50021', 'http://voicevox:50021', 'http://127.0.0.1:50021', 'http://localhost:50021']

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
# ==============================================================================
@dataclass
class GroqModelStatus:
    is_limited: bool = False
    reset_time: Optional[datetime] = None
    last_error: Optional[str] = None
# ==============================================================================
# ã€å¤‰æ›´1ã€‘ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã« GeminiModelStatus ã‚’è¿½åŠ 
# ==============================================================================
@dataclass
class GeminiModelStatus:
    is_limited: bool = False
    reset_time: Optional[datetime] = None
    current_model: str = "gemini-1.5-flash"
    last_error: Optional[str] = None
@dataclass
class UserData:
    uuid: str
    name: str
    interaction_count: int
    is_friend: bool = False
    favorite_topics: List[str] = field(default_factory=list)
    psychology: Optional[Dict] = None

# ==============================================================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ç®¡ç†
# ==============================================================================
class GlobalState:
    def __init__(self):
        self._lock = RLock()
        self._voicevox_enabled = False
        self._active_voicevox_url = None

    @property
    def voicevox_enabled(self) -> bool:
        with self._lock: return self._voicevox_enabled
    @voicevox_enabled.setter
    def voicevox_enabled(self, value: bool):
        with self._lock: self._voicevox_enabled = value
    @property
    def active_voicevox_url(self) -> Optional[str]:
        with self._lock: return self._active_voicevox_url
    @active_voicevox_url.setter
    def active_voicevox_url(self, value: Optional[str]):
        with self._lock: self._active_voicevox_url = value
# ==============================================================================
# ã€å¤‰æ›´3ã€‘GeminiModelManager ã‚¯ãƒ©ã‚¹ã‚’è¿½åŠ ï¼ˆè¡Œ120ä»˜è¿‘ã€GlobalStateã®å¾Œï¼‰
# ==============================================================================
class GeminiModelManager:
    """Geminiãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç®¡ç†"""
    def __init__(self):
        self._lock = RLock()
        self._models = GEMINI_MODELS
        self._current_index = 0
        self._status = GeminiModelStatus()
        self._gemini_instances = {}
    
    def get_current_model(self) -> Optional[Any]:
        """ç¾åœ¨åˆ©ç”¨å¯èƒ½ãªGeminiãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        with self._lock:
            # åˆ¶é™ä¸­ã‹ã¤ãƒªã‚»ãƒƒãƒˆæ™‚é–“ã‚’éãã¦ã„ãŸã‚‰ãƒªã‚»ãƒƒãƒˆ
            if self._status.is_limited and self._status.reset_time:
                if datetime.utcnow() >= self._status.reset_time:
                    logger.info(f"âœ… Geminiåˆ¶é™è§£é™¤: {self._status.current_model}")
                    self._status.is_limited = False
                    self._status.reset_time = None
            
            # åˆ¶é™ä¸­ãªã‚‰æ¬¡ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™
            if self._status.is_limited:
                self._current_index = (self._current_index + 1) % len(self._models)
                self._status.current_model = self._models[self._current_index]
                self._status.is_limited = False
                logger.info(f"ğŸ”„ Geminiãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆ: {self._status.current_model}")
            
            model_name = self._models[self._current_index]
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã¾ãŸã¯æ–°è¦ä½œæˆ
            if model_name not in self._gemini_instances:
                try:
                    self._gemini_instances[model_name] = genai.GenerativeModel(model_name)
                    logger.info(f"ğŸ†• Geminiãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–: {model_name}")
                except Exception as e:
                    logger.error(f"âŒ GeminiåˆæœŸåŒ–å¤±æ•— ({model_name}): {e}")
                    return None
            
            return self._gemini_instances[model_name]
    
    def mark_limited(self, wait_seconds: int = 60):
        """GeminiãŒåˆ¶é™ã•ã‚ŒãŸéš›ã®å‡¦ç†"""
        with self._lock:
            self._status.is_limited = True
            self._status.reset_time = datetime.utcnow() + timedelta(seconds=wait_seconds)
            logger.warning(f"âš ï¸ Geminiåˆ¶é™æ¤œçŸ¥ ({self._status.current_model}): {wait_seconds}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤")
    
    def get_status_report(self) -> str:
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ"""
        with self._lock:
            if self._status.is_limited and self._status.reset_time:
                jst = (self._status.reset_time + timedelta(hours=9)).strftime('%H:%M:%S')
                return f"ğŸ¤– Gemini: âŒ åˆ¶é™ä¸­ ({self._status.current_model}) - è§£é™¤: {jst}"
            else:
                return f"ğŸ¤– Gemini: âœ… ç¨¼åƒä¸­ ({self._status.current_model})"

class GroqModelManager:
    def __init__(self, models: List[str]):
        self._lock = RLock()
        self._status: Dict[str, GroqModelStatus] = {model: GroqModelStatus() for model in models}
        self._models = models

    def is_available(self, model: str) -> bool:
        with self._lock:
            status = self._status.get(model)
            if not status: return False
            if not status.is_limited: return True
            if status.reset_time and datetime.utcnow() >= status.reset_time:
                status.is_limited = False; status.reset_time = None
                return True
            return False

    def mark_limited(self, model: str, wait_minutes: int = 5, error_msg: str = ""):
        with self._lock:
            if model in self._status:
                self._status[model].is_limited = True
                self._status[model].reset_time = datetime.utcnow() + timedelta(minutes=wait_minutes)

    def get_status_report(self) -> str:
        with self._lock:
            lines = ["ğŸ¦™ Groq ãƒ¢ãƒ‡ãƒ«ç¨¼åƒçŠ¶æ³:"]
            for model in self._models:
                s = self._status[model]
                if s.is_limited:
                    jst = (s.reset_time + timedelta(hours=9)).strftime('%H:%M:%S') if s.reset_time else "ä¸æ˜"
                    lines.append(f"  âŒ {model}: åˆ¶é™ä¸­ (è§£é™¤: {jst})")
                else:
                    lines.append(f"  âœ… {model}: OK")
            return "\n".join(lines)

    def get_available_models(self) -> List[str]:
        with self._lock: return [m for m in self._models if self.is_available(m)]

global_state = GlobalState()
gemini_model_manager = GeminiModelManager()
groq_model_manager = GroqModelManager(GROQ_MODELS)
background_executor = ThreadPoolExecutor(max_workers=5)
groq_client: Optional[Groq] = None
gemini_model, engine, Session = None, None, None

app = Flask(__name__)
application = app
app.config['JSON_AS_ASCII'] = False
CORS(app)

@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type, Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
    return response

Base = declarative_base()

# ==============================================================================
# ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•°
# ==============================================================================
def get_secret(name: str) -> Optional[str]:
    env_value = os.environ.get(name)
    if env_value and env_value.strip(): return env_value.strip()
    try:
        secret_file_path = f"/etc/secrets/{name}"
        if os.path.exists(secret_file_path):
            with open(secret_file_path, 'r') as f:
                val = f.read().strip()
                if val: return val
    except: pass
    return None

DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./mochiko_ultimate.db'
GROQ_API_KEY = get_secret('GROQ_API_KEY')
GEMINI_API_KEY = get_secret('GEMINI_API_KEY')
VOICEVOX_URL_FROM_ENV = get_secret('VOICEVOX_URL')

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
# ==============================================================================
class UserMemory(Base):
    __tablename__ = 'user_memories'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    interaction_count = Column(Integer, default=0)
    is_friend = Column(Boolean, default=False)
    last_interaction = Column(DateTime, default=datetime.utcnow)

class ConversationHistory(Base):
    __tablename__ = 'conversation_history'
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_uuid = Column(String(255), nullable=False, index=True)
    role = Column(String(10), nullable=False)
    content = Column(Text, nullable=False)
    timestamp = Column(DateTime, default=datetime.utcnow, index=True)

class UserPsychology(Base):
    __tablename__ = 'user_psychology'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    openness = Column(Integer, default=50)
    extraversion = Column(Integer, default=50)
    favorite_topics = Column(Text, nullable=True)
    analysis_confidence = Column(Integer, default=0)
    last_analyzed = Column(DateTime, nullable=True)

class BackgroundTask(Base):
    __tablename__ = 'background_tasks'
    id = Column(Integer, primary_key=True)
    task_id = Column(String(255), unique=True, nullable=False)
    user_uuid = Column(String(255), nullable=False, index=True)
    task_type = Column(String(50), nullable=False)
    query = Column(Text, nullable=False)
    result = Column(Text, nullable=True)
    status = Column(String(20), default='pending', index=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    completed_at = Column(DateTime, nullable=True)

class HolomemWiki(Base):
    __tablename__ = 'holomem_wiki'
    id = Column(Integer, primary_key=True)
    member_name = Column(String(100), nullable=False, unique=True, index=True)
    description = Column(Text, nullable=True)
    generation = Column(String(100), nullable=True)
    debut_date = Column(String(100), nullable=True)
    tags = Column(Text, nullable=True)
    status = Column(String(50), default='ç¾å½¹', nullable=False)
    graduation_date = Column(String(100), nullable=True)
    graduation_reason = Column(Text, nullable=True)
    mochiko_feeling = Column(Text, nullable=True)
    last_updated = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    # â˜… æ–°è¦è¿½åŠ : æœ€æ–°ã®Xã§ã®è©±é¡Œãªã©ã‚’ä¿å­˜ã™ã‚‹ã‚«ãƒ©ãƒ 
    recent_activity = Column(Text, nullable=True)

class HololiveNews(Base):
    __tablename__ = 'hololive_news'
    id = Column(Integer, primary_key=True)
    title = Column(String(500), nullable=False)
    content = Column(Text, nullable=False)
    url = Column(String(1000), unique=True)
    news_hash = Column(String(100), unique=True, index=True)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)

class HolomemNickname(Base):
    __tablename__ = 'holomem_nicknames'
    id = Column(Integer, primary_key=True)
    nickname = Column(String(100), unique=True, nullable=False, index=True)
    fullname = Column(String(100), nullable=False)

class HololiveGlossary(Base):
    __tablename__ = 'hololive_glossary'
    id = Column(Integer, primary_key=True)
    term = Column(String(100), unique=True, nullable=False, index=True)
    description = Column(Text, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)
# ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œæ™‚é–“ã‚’è¨˜éŒ²ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«
class TaskLog(Base):
    __tablename__ = 'task_logs'
    task_name = Column(String(100), primary_key=True)
    last_run = Column(DateTime, default=datetime.utcnow)
# ==============================================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ & ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ==============================================================================
class RateLimiter:
    def __init__(self, max_requests: int, time_window: timedelta):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests: Dict[str, List[datetime]] = defaultdict(list)
        self._lock = threading.Lock()
    def is_allowed(self, user_id: str) -> bool:
        with self._lock:
            now = datetime.utcnow(); cutoff = now - self.time_window
            self.requests[user_id] = [t for t in self.requests[user_id] if t > cutoff]
            if len(self.requests[user_id]) >= self.max_requests: return False
            self.requests[user_id].append(now); return True
    def cleanup_old_entries(self):
        with self._lock:
            now = datetime.utcnow(); cutoff = now - self.time_window
            for uid in list(self.requests.keys()):
                self.requests[uid] = [t for t in self.requests[uid] if t > cutoff]
                if not self.requests[uid]: del self.requests[uid]

chat_rate_limiter = RateLimiter(max_requests=10, time_window=timedelta(minutes=1))

@contextmanager
def get_db_session():
    if not Session: raise Exception("Session not initialized")
    session = Session()
    try: yield session; session.commit()
    except Exception as e: session.rollback(); raise
    finally: session.close()

def create_json_response(data: Any, status: int = 200) -> Response:
    return Response(json.dumps(data, ensure_ascii=False), mimetype='application/json; charset=utf-8', status=status)

def clean_text(text: str) -> str:
    if not text: return ""
    return re.sub(r'\s+', ' ', re.sub(r'<[^>]+>', '', text)).strip()

def limit_text_for_sl(text: str, max_length: int = SL_SAFE_CHAR_LIMIT) -> str:
    return text[:max_length - 3] + "..." if len(text) > max_length else text

def sanitize_user_input(text: str, max_length: int = 1000) -> str:
    if not text: return ""
    text = text[:max_length]; text = escape(text)
    return text.strip()

def get_japan_time() -> str:
    return f"ä»Šã®æ—¥æœ¬ã®æ™‚é–“ã¯ã€{datetime.now(timezone(timedelta(hours=9))).strftime('%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚%Måˆ†')}ã ã‚ˆï¼"

def is_time_request(msg: str) -> bool:
    return any(kw in msg for kw in ['ä»Šä½•æ™‚', 'æ™‚åˆ»', 'ä½•æ™‚', 'ãªã‚“ã˜'])

def is_weather_request(msg: str) -> bool:
    return any(kw in msg for kw in ['ä»Šæ—¥ã®å¤©æ°—', 'æ˜æ—¥ã®å¤©æ°—', 'å¤©æ°—äºˆå ±', 'å¤©æ°—ã¯'])

def is_explicit_search_request(msg: str) -> bool:
    msg = msg.strip()
    strong_triggers = ['èª¿ã¹ã¦', 'æ¤œç´¢', 'æ¢ã—ã¦', 'ã¨ã¯', 'ã£ã¦ä½•', 'ã«ã¤ã„ã¦', 'æ•™ãˆã¦', 'æ•™ãˆã‚', 'è©³ç´°', 'çŸ¥ã‚ŠãŸã„']
    if any(kw in msg for kw in strong_triggers):
        return True
    noun_triggers = ['ãƒ‹ãƒ¥ãƒ¼ã‚¹', 'news', 'NEWS', 'æƒ…å ±', 'æ—¥ç¨‹', 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«', 'å¤©æ°—', 'äºˆå ±']
    if any(kw in msg for kw in noun_triggers):
        if len(msg) < 20: return True
        if msg.endswith('?') or msg.endswith('ï¼Ÿ'): return True
        return False
    if 'ãŠã™ã™ã‚' in msg or 'ã‚ªã‚¹ã‚¹ãƒ¡' in msg: return True
    return False

def extract_location(msg: str) -> str:
    for loc in LOCATION_CODES.keys():
        if loc in msg: return loc
    return "æ±äº¬"

def get_weather_forecast(location: str = "æ±äº¬") -> str:
    """å¤©æ°—äºˆå ±ã‚’å–å¾—"""
    try:
        location_code = LOCATION_CODES.get(location, LOCATION_CODES["æ±äº¬"])
        url = f"https://weather.tsukumijima.net/api/forecast/city/{location_code}"
        res = requests.get(url, timeout=5)
        if res.status_code != 200: return f"{location}ã®å¤©æ°—æƒ…å ±ãŒå–å¾—ã§ããªã‹ã£ãŸã‚ˆâ€¦"
        data = res.json()
        today = data['forecasts'][0]
        return f"{location}ã®ä»Šæ—¥ã®å¤©æ°—ã¯ã€Œ{today['telop']}ã€ã ã‚ˆï¼{today['detail']['weather'] if today.get('detail') else ''}"
    except:
        return f"{location}ã®å¤©æ°—æƒ…å ±ãŒå–å¾—ã§ããªã‹ã£ãŸã‚ˆâ€¦"

def get_or_create_user(session, user_uuid: str, user_name: str) -> UserData:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å–å¾—ã¾ãŸã¯ä½œæˆ
    user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
    if user:
        user.interaction_count += 1
        user.last_interaction = datetime.utcnow()
        if user.user_name != user_name: user.user_name = user_name
        
        # å‹é”èªå®šãƒã‚§ãƒƒã‚¯
        if hasattr(user, 'is_friend'):
            if user.interaction_count >= FRIEND_THRESHOLD and not user.is_friend:
                user.is_friend = True
                logger.info(f"ğŸ‰ {user_name}ã•ã‚“ãŒå‹é”ã«èªå®šã•ã‚Œã¾ã—ãŸï¼")
        else:
            logger.warning("is_friend column missing on model access")
            user.is_friend = False 
    else:
        user = UserMemory(user_uuid=user_uuid, user_name=user_name, interaction_count=1)
        session.add(user)
    
    # å¿ƒç†ãƒ‡ãƒ¼ã‚¿å–å¾—
    psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
    fav_topics = []
    psych_data = None
    if psych:
        if psych.favorite_topics:
            fav_topics = [t.strip() for t in psych.favorite_topics.split(',') if t.strip()]
        psych_data = {
            'openness': psych.openness,
            'extraversion': psych.extraversion,
            'confidence': psych.analysis_confidence
        }
    
    return UserData(
        uuid=user.user_uuid,
        name=user.user_name,
        interaction_count=user.interaction_count,
        is_friend=getattr(user, 'is_friend', False),
        favorite_topics=fav_topics,
        psychology=psych_data
    )

def get_conversation_history(session, user_uuid: str, limit: int = 10) -> List[Dict]:
    hist = session.query(ConversationHistory).filter_by(user_uuid=user_uuid).order_by(ConversationHistory.timestamp.desc()).limit(limit).all()
    return [{'role': h.role, 'content': h.content} for h in reversed(hist)]

# ==============================================================================
# çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚¯ãƒ©ã‚¹
# ==============================================================================
class HololiveKnowledgeBase:
    def __init__(self):
        self.nickname_map = {}
        self.glossary = {}
        self._lock = RLock()
        
    def load_data(self):
        if not Session: return
        with self._lock:
            session = Session()
            try:
                nicks = session.query(HolomemNickname).all()
                self.nickname_map = {n.nickname: n.fullname for n in nicks}
                terms = session.query(HololiveGlossary).all()
                self.glossary = {t.term: t.description for t in terms}
                logger.info(f"ğŸ“š Knowledge Base loaded: {len(self.nickname_map)} nicknames, {len(self.glossary)} terms.")
            except Exception as e:
                logger.error(f"âŒ Failed to load knowledge base: {e}")
            finally:
                session.close()

    def refresh(self):
        self.load_data()

    def normalize_query(self, text: str) -> str:
        normalized = text
        with self._lock:
            for nick, full in self.nickname_map.items():
                if nick in text:
                    normalized = normalized.replace(nick, f"{nick}ï¼ˆ{full}ï¼‰")
        return normalized

    def get_context_info(self, text: str) -> str:
        context_parts = []
        with self._lock:
            for term, desc in self.glossary.items():
                if term in text:
                    context_parts.append(f"ã€ç”¨èªè§£èª¬: {term}ã€‘{desc}")
        return "\n".join(context_parts)

knowledge_base = HololiveKnowledgeBase()

# ==============================================================================
# ãƒ›ãƒ­ãƒ¡ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç®¡ç†
# ==============================================================================
class HolomemKeywordManager:
    def __init__(self):
        self._lock = RLock()
        self._keywords: Dict[str, List[str]] = {}
        self._all_keywords: set = set()
        self._last_loaded: Optional[datetime] = None
    
    def load_from_db(self, force: bool = False) -> bool:
        with self._lock:
            try:
                with get_db_session() as session:
                    members = session.query(HolomemWiki).all()
                    self._keywords.clear()
                    self._all_keywords.clear()
                    for m in members:
                        name = m.member_name
                        self._keywords[name] = [name]
                        self._all_keywords.add(name)
                    return True
            except: return False
    
    def detect_in_message(self, message: str) -> Optional[str]:
        with self._lock:
            normalized = knowledge_base.normalize_query(message)
            for keyword in self._all_keywords:
                if keyword in normalized:
                    return keyword
            return None
    
    def get_member_count(self) -> int:
        with self._lock: return len(self._keywords)

holomem_manager = HolomemKeywordManager()

# ==============================================================================
# ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±ã‚­ãƒ£ãƒƒã‚·ãƒ¥ & ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±åé›†
# ==============================================================================
_holomem_cache: Dict[str, Dict] = {}
_holomem_cache_lock = threading.Lock()
_holomem_cache_ttl = timedelta(minutes=30)
_holomem_cache_timestamps: Dict[str, datetime] = {}

def get_holomem_info_cached(member_name: str) -> Optional[Dict]:
    with _holomem_cache_lock:
        if member_name in _holomem_cache:
            if (datetime.utcnow() - _holomem_cache_timestamps.get(member_name, datetime.min)) < _holomem_cache_ttl:
                return _holomem_cache[member_name]
    with get_db_session() as session:
        wiki = session.query(HolomemWiki).filter_by(member_name=member_name).first()
        if wiki:
            # â˜… ä¿®æ­£: recent_activityã‚’è¿½åŠ 
            data = {k: getattr(wiki, k) for k in ['member_name', 'description', 'generation', 'debut_date', 'tags', 'status', 'graduation_date', 'mochiko_feeling', 'recent_activity']}
            with _holomem_cache_lock:
                _holomem_cache[member_name] = data
                _holomem_cache_timestamps[member_name] = datetime.utcnow()
            return data
    return None

def clear_holomem_cache(member_name: Optional[str] = None):
    with _holomem_cache_lock:
        if member_name:
            _holomem_cache.pop(member_name, None)
        else:
            _holomem_cache.clear()

def get_holomem_context(member_name: str) -> str:
    """ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”¨ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å–å¾—ï¼ˆSNSæƒ…å ±å«ã‚€ï¼‰"""
    info = get_holomem_info_cached(member_name)
    if not info:
        return ""
    
    context = f"ã€{info['member_name']}ã®æƒ…å ±ã€‘\n"
    if info.get('description'):
        context += f"- {info['description']}\n"
    if info.get('generation'):
        context += f"- æ‰€å±: {info['generation']}\n"
    if info.get('debut_date'):
        context += f"- ãƒ‡ãƒ“ãƒ¥ãƒ¼: {info['debut_date']}\n"
    if info.get('status'):
        context += f"- çŠ¶æ…‹: {info['status']}\n"
        if info['status'] == 'å’æ¥­' and info.get('graduation_date'):
            context += f"- å’æ¥­æ—¥: {info['graduation_date']}\n"
    
    # â˜… è¿½åŠ : Xã®æœ€æ–°æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
    if info.get('recent_activity'):
         context += f"\nã€{info['member_name']}ã«é–¢ã™ã‚‹ç›´è¿‘ã®X(Twitter)ã®æ§˜å­ãƒ»è©±é¡Œã€‘\n{info['recent_activity']}\n"
    
    return context

# ==============================================================================
# â˜… è¿½åŠ æ©Ÿèƒ½: Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢é€£æº
# ==============================================================================
def scrape_yahoo_realtime_for_member(member_name: str) -> str:
    """æŒ‡å®šã—ãŸãƒ¡ãƒ³ãƒãƒ¼ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã§è¿”ã™"""
    try:
        # æ¤œç´¢ã‚¯ã‚¨ãƒª: åå‰ã‚’å«ã¿ã€RTã‚’é™¤ã
        query = f"{member_name} -RT"
        url = "https://search.yahoo.co.jp/realtime/search"
        params = {'p': query, 'ei': 'UTF-8', 'm': 'latency'} # m=latencyã§æ–°ç€é †
        headers = {'User-Agent': random.choice(USER_AGENTS)}
        
        res = requests.get(url, params=params, headers=headers, timeout=10)
        if res.status_code != 200: return ""
        
        soup = BeautifulSoup(res.content, 'html.parser')
        texts = []
        # æœ€æ–°ã®5ä»¶ç¨‹åº¦ã‚’å–å¾—
        for item in soup.select('.cnt.cf')[:5]:
            txt = item.select_one('.kw')
            tim = item.select_one('.tim')
            if txt:
                clean_txt = clean_text(txt.text)
                time_txt = clean_text(tim.text) if tim else ""
                texts.append(f"ãƒ»({time_txt}) {clean_txt}")
        
        return "\n".join(texts)
    except Exception as e:
        logger.error(f"Realtime search failed for {member_name}: {e}")
        return ""

def update_holomem_social_activities():
    """å…¨ãƒ›ãƒ­ãƒ¡ãƒ³ã®æœ€æ–°çŠ¶æ³ã‚’Yahooã‹ã‚‰åé›†ã—ã¦DBæ›´æ–°ï¼ˆå°‘ã—ãšã¤è¡Œã†ï¼‰"""
    logger.info("ğŸ¦ ãƒ›ãƒ­ãƒ¡ãƒ³SNSçŠ¶æ³æ›´æ–°ã‚¿ã‚¹ã‚¯é–‹å§‹")
    with get_db_session() as session:
        # æ›´æ–°ãŒå¤ã„é †ã€ã¾ãŸã¯ãƒ©ãƒ³ãƒ€ãƒ ã«5äººé¸ã‚“ã§æ›´æ–°ï¼ˆå…¨ã‚¢ã‚¯ã‚»ã‚¹ã«ã‚ˆã‚‹BANé˜²æ­¢ï¼‰
        members = session.query(HolomemWiki).order_by(HolomemWiki.last_updated.asc()).limit(5).all()
        
        for m in members:
            logger.info(f"ğŸ” {m.member_name} ã®æœ€æ–°çŠ¶æ³ã‚’åé›†ä¸­...")
            activities = scrape_yahoo_realtime_for_member(m.member_name)
            
            if activities:
                # DBã«ä¿å­˜
                m.recent_activity = activities
                m.last_updated = datetime.utcnow()
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
                clear_holomem_cache(m.member_name)
            
            time.sleep(3) # ã‚¢ã‚¯ã‚»ã‚¹é–“éš”ã‚’ç©ºã‘ã‚‹
            
    logger.info("âœ… SNSçŠ¶æ³æ›´æ–°å®Œäº†")

# ==============================================================================
# ãƒ›ãƒ­ãƒ¡ãƒ³ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° & DBæ›´æ–°
# ==============================================================================
def scrape_hololive_wiki() -> List[Dict]:
    """Seesaa Wikiã‹ã‚‰ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±ã‚’å–å¾—"""
    url = "https://seesaawiki.jp/hololivetv/d/%a5%db%a5%ed%a5%e9%a5%a4%a5%d6"
    results = []
    try:
        headers = {'User-Agent': random.choice(USER_AGENTS)}
        res = requests.get(url, headers=headers, timeout=15)
        if res.status_code != 200: return []
        soup = BeautifulSoup(res.content, 'html.parser')
        for link in soup.select('a[href*="/d/"]'):
            name = clean_text(link.text)
            if name and len(name) >= 2 and re.search(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]', name):
                if not any(x in name for x in ['ä¸€è¦§', 'ãƒ¡ãƒ‹ãƒ¥ãƒ¼', 'ãƒˆãƒƒãƒ—', 'ç·¨é›†', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–']):
                    results.append({'member_name': name})
        seen = set()
        return [r for r in results if not (r['member_name'] in seen or seen.add(r['member_name']))]
    except: return []

def fetch_member_detail_from_wiki(member_name: str) -> Optional[Dict]:
    url = f"https://seesaawiki.jp/hololivetv/d/{quote_plus(member_name)}"
    try:
        res = requests.get(url, headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=10)
        if res.status_code != 200: return None
        soup = BeautifulSoup(res.content, 'html.parser')
        content = soup.select_one('#content, .wiki-content')
        if not content: return None
        text = clean_text(content.text)[:1000]
        detail = {'member_name': member_name}
        debut = re.search(r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)[^\d]*ãƒ‡ãƒ“ãƒ¥ãƒ¼', text)
        if debut: detail['debut_date'] = debut.group(1)
        gen = re.search(r'(\dæœŸç”Ÿ|ã‚²ãƒ¼ãƒãƒ¼ã‚º|ID|EN|DEV_IS|ReGLOSS)', text)
        if gen: detail['generation'] = gen.group(1)
        desc = re.search(r'^(.{30,150}?[ã€‚ï¼])', text)
        if desc: detail['description'] = desc.group(1)
        
        if "å’æ¥­" in text or "å¥‘ç´„è§£é™¤" in text:
            detail['status'] = 'å’æ¥­'
            grad = re.search(r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)[^\d]*(å’æ¥­|å¥‘ç´„è§£é™¤)', text)
            if grad:
                detail['graduation_date'] = grad.group(1)
        else:
            detail['status'] = 'ç¾å½¹'
            
        return detail
    except: return None

def update_holomem_database():
    logger.info("ğŸ”„ ãƒ›ãƒ­ãƒ¡ãƒ³DBæ›´æ–°é–‹å§‹...")
    members = scrape_hololive_wiki()
    
    graduated_members = [
        {'member_name': 'æ¡ç”Ÿã‚³ã‚³', 'status': 'å’æ¥­', 'graduation_date': '2021å¹´7æœˆ1æ—¥'},
        {'member_name': 'æ½¤ç¾½ã‚‹ã—ã‚', 'status': 'å’æ¥­', 'graduation_date': '2022å¹´2æœˆ24æ—¥'},
        {'member_name': 'æ¹Šã‚ãã‚', 'status': 'å’æ¥­', 'graduation_date': '2024å¹´8æœˆ28æ—¥'}
    ]
    
    for gm in graduated_members:
        members.append(gm)

    if not members: return
    with get_db_session() as session:
        for m in members:
            name = m['member_name']
            existing = session.query(HolomemWiki).filter_by(member_name=name).first()
            
            detail = fetch_member_detail_from_wiki(name)
            if detail:
                status = m.get('status', detail.get('status', 'ç¾å½¹'))
                grad_date = m.get('graduation_date', detail.get('graduation_date'))
                
                if existing:
                    existing.status = status
                    existing.graduation_date = grad_date
                    existing.last_updated = datetime.utcnow()
                else:
                    new_member = HolomemWiki(
                        member_name=name,
                        description=detail.get('description'),
                        generation=detail.get('generation'),
                        debut_date=detail.get('debut_date'),
                        tags=name,
                        status=status,
                        graduation_date=grad_date,
                        last_updated=datetime.utcnow()
                    )
                    session.add(new_member)
            time.sleep(0.5)
    holomem_manager.load_from_db(force=True)
    logger.info("âœ… ãƒ›ãƒ­ãƒ¡ãƒ³DBæ›´æ–°å®Œäº†")

# ==============================================================================
# ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†
# ==============================================================================
def fetch_hololive_news():
    logger.info("ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹DBæ›´æ–°é–‹å§‹...")
    url = "https://hololive.hololivepro.com/news"
    try:
        res = requests.get(url, headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=15)
        if res.status_code != 200: return
        soup = BeautifulSoup(res.content, 'html.parser')
        
        articles = soup.select('ul.news_list > li') or soup.select('.news_list_item')
        
        with get_db_session() as session:
            for art in articles[:10]:
                a_tag = art.find('a')
                if not a_tag: continue
                
                link = a_tag.get('href')
                title_elem = art.find(['h3', 'p', 'dt'])
                title = clean_text(title_elem.text) if title_elem else clean_text(a_tag.text)
                
                if title and link:
                    if not session.query(HololiveNews).filter_by(url=link).first():
                        session.add(HololiveNews(
                            title=title,
                            content=title,
                            url=link,
                            created_at=datetime.utcnow()
                        ))
        logger.info("âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹DBæ›´æ–°å®Œäº†")
    except Exception as e:
        logger.error(f"News fetch failed: {e}")

def fetch_hololive_tsuushin_news():
    """ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
    logger.info("ğŸ“° ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ã®æ›´æ–°ãƒã‚§ãƒƒã‚¯é–‹å§‹...")
    url = "https://hololive-tsuushin.com/holonews/"
    try:
        headers = {'User-Agent': random.choice(USER_AGENTS)}
        res = requests.get(url, headers=headers, timeout=15)
        if res.status_code != 200: return
        
        soup = BeautifulSoup(res.content, 'html.parser')
        articles = soup.select('article') or soup.select('.post-list-item')
        
        with get_db_session() as session:
            count = 0
            for art in articles[:10]:
                a_tag = art.find('a')
                if not a_tag: continue
                
                link = a_tag.get('href')
                title_elem = art.find(['h1', 'h2', 'h3', 'p'])
                title = clean_text(title_elem.text) if title_elem else clean_text(a_tag.text)
                
                if title and link:
                    if not session.query(HololiveNews).filter_by(url=link).first():
                        session.add(HololiveNews(
                            title=f"ã€ã¾ã¨ã‚ã€‘{title}",
                            content=title,
                            url=link,
                            created_at=datetime.utcnow()
                        ))
                        count += 1
            logger.info(f"âœ… ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ã‹ã‚‰ {count} ä»¶ã®æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¿½åŠ ")
    except Exception as e:
        logger.error(f"âŒ ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ã®å–å¾—ã«å¤±æ•—: {e}")

def wrapped_news_fetch():
    """å…¬å¼ã‚µã‚¤ãƒˆã¨ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ã®ä¸¡æ–¹ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
    fetch_hololive_news()
    fetch_hololive_tsuushin_news()
    with get_db_session() as session:
        log = session.query(TaskLog).filter_by(task_name='fetch_news').first()
        if not log:
            log = TaskLog(task_name='fetch_news')
            session.add(log)
        log.last_run = datetime.utcnow()

# --- [å¼·åŒ–] ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—é–¢æ•° ---
def fetch_news_task_integrated():
    # 1. app (1).py ã®SNSæƒ…å ±ã‚’å–å¾—
    try:
        update_holomem_social_activities()
    except Exception as e:
        logger.error(f"SNSåé›†ã‚¨ãƒ©ãƒ¼: {e}")

    # 2. SL / CG / å…¬å¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—
    sources = [
        {"name": "SecondLife", "url": "https://community.secondlife.com/blogs/rss/3-featured-news/", "type": "rss"},
        {"name": "CGWORLD", "url": "https://cgworld.jp/rss/news/", "type": "rss"}
    ]
    
def wrapped_holomem_update():
    """ãƒ›ãƒ­ãƒ¡ãƒ³DBã‚’æ›´æ–°ã—ã¦å®Ÿè¡Œæ™‚é–“ã‚’è¨˜éŒ²ã™ã‚‹"""
    update_holomem_database()
    with get_db_session() as session:
        log = session.query(TaskLog).filter_by(task_name='update_holomem').first()
        if not log:
            log = TaskLog(task_name='update_holomem')
            session.add(log)
        log.last_run = datetime.utcnow()

def catch_up_task(task_name, wrapped_func, interval_hours=1):
    """å‰å›ã®å®Ÿè¡Œã‹ã‚‰æ™‚é–“ãŒçµŒã¡ã™ãã¦ã„ãŸã‚‰å®Ÿè¡Œã™ã‚‹"""
    with get_db_session() as session:
        log = session.query(TaskLog).filter_by(task_name=task_name).first()
        now = datetime.utcnow()
        if not log or (now - log.last_run) >= timedelta(hours=interval_hours):
            logger.info(f"â° ã‚¿ã‚¹ã‚¯ '{task_name}' ã‚’ã‚­ãƒ£ãƒƒãƒã‚¢ãƒƒãƒ—å®Ÿè¡Œã—ã¾ã™ã€‚")
            background_executor.submit(wrapped_func)
# ==============================================================================
# ãƒˆãƒ”ãƒƒã‚¯åˆ†æ
# ==============================================================================
def analyze_user_topics(session, user_uuid: str) -> List[str]:
    """ä¼šè©±å±¥æ­´ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³ãƒˆãƒ”ãƒƒã‚¯ã‚’åˆ†æ"""
    try:
        recent_messages = session.query(ConversationHistory).filter(
            ConversationHistory.user_uuid == user_uuid,
            ConversationHistory.role == 'user'
        ).order_by(ConversationHistory.timestamp.desc()).limit(20).all()
        
        if len(recent_messages) < 5:
            return []
        
        all_text = ' '.join([msg.content for msg in recent_messages])
        keywords = []
        
        holomem_keywords = ['ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'VTuber', 'ã¿ã“ã¡', 'ã™ã„ã¡ã‚ƒã‚“', 'ãºã“ã‚‰', 'é…ä¿¡', 'ãƒ©ã‚¤ãƒ–']
        for kw in holomem_keywords:
            if kw in all_text:
                keywords.append('ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–')
                break
        
        game_keywords = ['ã‚²ãƒ¼ãƒ ', 'ãƒã‚¤ã‚¯ãƒ©', 'Minecraft', 'ãƒã‚±ãƒ¢ãƒ³', 'ã‚¼ãƒ«ãƒ€', 'ãƒ—ãƒ¬ã‚¤', 'Steam']
        for kw in game_keywords:
            if kw in all_text:
                keywords.append('ã‚²ãƒ¼ãƒ ')
                break
        
        anime_keywords = ['ã‚¢ãƒ‹ãƒ¡', 'æ¼«ç”»', 'ãƒãƒ³ã‚¬', 'å£°å„ª', 'æ¨ã—', 'ã‚­ãƒ£ãƒ©']
        for kw in anime_keywords:
            if kw in all_text:
                keywords.append('ã‚¢ãƒ‹ãƒ¡ãƒ»æ¼«ç”»')
                break
        
        music_keywords = ['éŸ³æ¥½', 'æ›²', 'æ­Œ', 'ãƒ©ã‚¤ãƒ–', 'ã‚³ãƒ³ã‚µãƒ¼ãƒˆ', 'ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ']
        for kw in music_keywords:
            if kw in all_text:
                keywords.append('éŸ³æ¥½')
                break
        
        tech_keywords = ['ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'Python', 'AI', 'é–‹ç™º', 'ã‚³ãƒ¼ãƒ‰', 'ã‚¢ãƒ—ãƒª']
        for kw in tech_keywords:
            if kw in all_text:
                keywords.append('æŠ€è¡“ãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°')
                break
        
        return list(set(keywords))
    
    except Exception as e:
        logger.error(f"ãƒˆãƒ”ãƒƒã‚¯åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        return []

# ==============================================================================
# å¿ƒç†åˆ†æ
# ==============================================================================
# ==============================================================================
# ã€å¤‰æ›´8ã€‘analyze_user_psychology é–¢æ•°ã‚’ä¿®æ­£ï¼ˆè¡Œ900ä»˜è¿‘ï¼‰
# å¤‰æ›´å‰: if gemini_model:
# å¤‰æ›´å¾Œ: gemini_model_manager.get_current_model() ã‚’ä½¿ã†
# ==============================================================================
def analyze_user_psychology(session, user_uuid: str, user_name: str):
    """ä¼šè©±å±¥æ­´ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ€§æ ¼ã‚’åˆ†æ"""
    try:
        recent_messages = session.query(ConversationHistory).filter(
            ConversationHistory.user_uuid == user_uuid,
            ConversationHistory.role == 'user'
        ).order_by(ConversationHistory.timestamp.desc()).limit(15).all()
        
        if len(recent_messages) < MIN_MESSAGES_FOR_ANALYSIS:
            return
        
        messages_text = '\n'.join([f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {msg.content}" for msg in reversed(recent_messages)])
        
        analysis_prompt = f"""ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‹ã‚‰æ€§æ ¼ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æå¯¾è±¡ã®ç™ºè¨€ã€‘
{messages_text}

ã€åˆ†æé …ç›®ã€‘
1. é–‹æ”¾æ€§ï¼ˆOpennessï¼‰: æ–°ã—ã„ã“ã¨ã¸ã®èˆˆå‘³ (0-100)
2. å¤–å‘æ€§ï¼ˆExtraversionï¼‰: ç¤¾äº¤çš„ã‹ã©ã†ã‹ (0-100)
3. å¥½ããã†ãªãƒˆãƒ”ãƒƒã‚¯: 3ã¤ã¾ã§

ã€å‡ºåŠ›å½¢å¼ã€‘ï¼ˆJSONå½¢å¼ã§å‡ºåŠ›ï¼‰
{{
  "openness": 70,
  "extraversion": 60,
  "topics": ["ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–", "ã‚²ãƒ¼ãƒ ", "æŠ€è¡“"]
}}
"""
        
        result = None
        # â˜… ä¿®æ­£: gemini_model_manager çµŒç”±ã§å–å¾—
        current_gemini = gemini_model_manager.get_current_model()
        if current_gemini:
            try:
                response = current_gemini.generate_content(analysis_prompt)
                if hasattr(response, 'candidates') and response.candidates:
                    text = response.candidates[0].content.parts[0].text.strip()
                    json_match = re.search(r'\{[^}]+\}', text, re.DOTALL)
                    if json_match:
                        result = json.loads(json_match.group())
            except Exception as e:
                error_str = str(e)
                if "429" in error_str or "quota" in error_str.lower():
                    retry_match = re.search(r'retry in (\d+(?:\.\d+)?)s', error_str)
                    wait_seconds = int(float(retry_match.group(1))) + 5 if retry_match else 60
                    gemini_model_manager.mark_limited(wait_seconds)
                logger.warning(f"Geminiåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        
        if not result and groq_client:
            try:
                models = groq_model_manager.get_available_models()
                if models:
                    response = groq_client.chat.completions.create(
                        model=models[0],
                        messages=[{"role": "user", "content": analysis_prompt}],
                        temperature=0.3,
                        max_tokens=300
                    )
                    text = response.choices[0].message.content.strip()
                    json_match = re.search(r'\{[^}]+\}', text, re.DOTALL)
                    if json_match:
                        result = json.loads(json_match.group())
            except Exception as e:
                logger.warning(f"Groqåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        
        if result:
            psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
            if not psych:
                psych = UserPsychology(user_uuid=user_uuid, user_name=user_name)
                session.add(psych)
            
            psych.openness = result.get('openness', 50)
            psych.extraversion = result.get('extraversion', 50)
            psych.favorite_topics = ','.join(result.get('topics', []))
            psych.analysis_confidence = min(100, psych.analysis_confidence + 20)
            psych.last_analyzed = datetime.utcnow()
            
            logger.info(f"ğŸ“Š {user_name}ã•ã‚“ã®å¿ƒç†åˆ†æå®Œäº†: é–‹æ”¾æ€§={psych.openness}, å¤–å‘æ€§={psych.extraversion}")
    
    except Exception as e:
        logger.error(f"å¿ƒç†åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

# ==============================================================================
# è©±é¡Œææ¡ˆ
# ==============================================================================
def suggest_topic(user_data: UserData) -> Optional[str]:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã«åŸºã¥ã„ã¦è©±é¡Œã‚’ææ¡ˆ"""
    if not user_data.favorite_topics:
        return None
    
    topic = random.choice(user_data.favorite_topics)
    
    suggestions = {
        'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–': [
            "ãã†ã„ãˆã°ã€æœ€è¿‘ã®ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®é…ä¿¡ã§æ°—ã«ãªã£ãŸã“ã¨ã‚ã‚‹ï¼Ÿ",
            "å¥½ããªãƒ›ãƒ­ãƒ¡ãƒ³ã®æœ€è¿‘ã®æ´»å‹•ã€ãƒã‚§ãƒƒã‚¯ã—ã¦ã‚‹ï¼Ÿ",
            "ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®æ–°ã—ã„ã‚°ãƒƒã‚ºã¨ã‹å‡ºã¦ãªã„ã‹ãªï¼Ÿ"
        ],
        'ã‚²ãƒ¼ãƒ ': [
            "æœ€è¿‘ä½•ã‹ã‚²ãƒ¼ãƒ ã‚„ã£ã¦ã‚‹ï¼Ÿé¢ç™½ã„ã®ã‚ã£ãŸï¼Ÿ",
            "æ–°ä½œã‚²ãƒ¼ãƒ ã§æ°—ã«ãªã£ã¦ã‚‹ã®ã‚ã‚‹ï¼Ÿ",
            "ã‚ãŸã—ã‚‚ã‚²ãƒ¼ãƒ å¥½ããªã‚“ã ï¼æœ€è¿‘ãƒãƒã£ã¦ã‚‹ã‚²ãƒ¼ãƒ ã‚ã‚‹ï¼Ÿ"
        ],
        'ã‚¢ãƒ‹ãƒ¡ãƒ»æ¼«ç”»': [
            "ä»ŠæœŸã®ã‚¢ãƒ‹ãƒ¡ã§é¢ç™½ã„ã®ã‚ã‚‹ï¼Ÿ",
            "æœ€è¿‘èª­ã‚“ã æ¼«ç”»ã§è‰¯ã‹ã£ãŸã®ã‚ã‚‹ï¼Ÿ",
            "æ¨ã—ã‚­ãƒ£ãƒ©ã¨ã‹ã„ã‚‹ï¼Ÿ"
        ],
        'éŸ³æ¥½': [
            "æœ€è¿‘è´ã„ã¦ã‚‹æ›²ã‚ã‚‹ï¼Ÿ",
            "å¥½ããªã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®æ–°æ›²ã¨ã‹å‡ºã¦ã‚‹ï¼Ÿ",
            "ãƒ©ã‚¤ãƒ–ã¨ã‹è¡Œãäºˆå®šã‚ã‚‹ï¼Ÿ"
        ],
        'æŠ€è¡“ãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°': [
            "æœ€è¿‘ä½•ã‹ä½œã£ã¦ã‚‹ï¼Ÿãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨ã‹ã€‚",
            "æ–°ã—ã„æŠ€è¡“ã§æ°—ã«ãªã£ã¦ã‚‹ã®ã‚ã‚‹ï¼Ÿ",
            "AIã¨ã‹ä½¿ã£ã¦ã¿ãŸã‚Šã—ã¦ã‚‹ï¼Ÿ"
        ]
    }
    
    if topic in suggestions:
        return random.choice(suggestions[topic])
    
    return None

# ==============================================================================
# AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—
# ==============================================================================
# ==============================================================================
# ã€å¤‰æ›´5ã€‘call_gemini é–¢æ•°ã‚’å®Œå…¨æ›¸ãæ›ãˆï¼ˆè¡Œ1000ä»˜è¿‘ï¼‰
# ==============================================================================
def call_gemini(system_prompt: str, message: str, history: List[Dict]) -> Optional[str]:
    """Gemini APIã‚’å‘¼ã³å‡ºã—ï¼ˆè¤‡æ•°ãƒ¢ãƒ‡ãƒ«å¯¾å¿œãƒ»è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    model = gemini_model_manager.get_current_model()
    if not model:
        return None
    
    try:
        full_prompt = f"{system_prompt}\n\nã€ä¼šè©±å±¥æ­´ã€‘\n"
        for h in history[-5:]:
            full_prompt += f"{'ãƒ¦ãƒ¼ã‚¶ãƒ¼' if h['role'] == 'user' else 'ã‚‚ã¡ã“'}: {h['content']}\n"
        full_prompt += f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼: {message}\nã‚‚ã¡ã“:"
        
        response = model.generate_content(
            full_prompt, 
            generation_config={
                "temperature": 0.8, 
                "max_output_tokens": 400
            }
        )
        
        if hasattr(response, 'candidates') and response.candidates:
            return response.candidates[0].content.parts[0].text.strip()
            
    except Exception as e:
        error_str = str(e)
        
        # ã‚¯ã‚©ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼ã®æ¤œå‡ºã¨å‡¦ç†
        if "429" in error_str or "quota" in error_str.lower() or "rate limit" in error_str.lower():
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰å¾…ã¡æ™‚é–“ã‚’æŠ½å‡º
            wait_seconds = 60  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            retry_match = re.search(r'retry in (\d+(?:\.\d+)?)s', error_str)
            if retry_match:
                wait_seconds = int(float(retry_match.group(1))) + 5  # ä½™è£•ã‚’æŒãŸã›ã‚‹
            
            gemini_model_manager.mark_limited(wait_seconds)
            logger.warning(f"âš ï¸ Geminiã‚¯ã‚©ãƒ¼ã‚¿è¶…é: {wait_seconds}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤")
        else:
            logger.warning(f"âš ï¸ Geminiã‚¨ãƒ©ãƒ¼: {e}")
    
    return None

def call_groq(system_prompt: str, message: str, history: List[Dict], max_tokens: int = 800) -> Optional[str]:
    if not groq_client: return None
    messages = [{"role": "system", "content": system_prompt}]
    for h in history[-5:]:
        messages.append({"role": h['role'], "content": h['content']})
    messages.append({"role": "user", "content": message})
    for model in groq_model_manager.get_available_models():
        try:
            response = groq_client.chat.completions.create(model=model, messages=messages, temperature=0.6, max_tokens=max_tokens)
            return response.choices[0].message.content.strip()
        except Exception as e:
            if "Rate limit" in str(e):
                groq_model_manager.mark_limited(model, 5)
    return None

# ==============================================================================
# AIå¿œç­”ç”Ÿæˆï¼ˆãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºæ©Ÿèƒ½çµ±åˆï¼‰
# ==============================================================================
def generate_ai_response(user_data: UserData, message: str, history: List[Dict], reference_info: str = "", is_detailed: bool = False, is_task_report: bool = False) -> str:
    """AIå¿œç­”ç”Ÿæˆï¼ˆRAGãƒ»ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ»ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºçµ±åˆç‰ˆï¼‰"""
    
    normalized_message = knowledge_base.normalize_query(message)
    internal_context = knowledge_base.get_context_info(message)
    
    # 1. ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±ã®æ³¨å…¥ï¼ˆSNSæƒ…å ±å«ã‚€ï¼‰
    try:
        holomem_manager.load_from_db()
        detected_name = holomem_manager.detect_in_message(normalized_message)
        if detected_name:
            info = get_holomem_info_cached(detected_name)
            if info:
                profile = f"ã€äººç‰©ãƒ‡ãƒ¼ã‚¿: {info['member_name']}ã€‘\nãƒ»{info['description']}\nãƒ»æ‰€å±: {info['generation']}\nãƒ»çŠ¶æ…‹: {info['status']}"
                if info.get('graduation_date'):
                    profile += f"\nãƒ»å’æ¥­æ—¥: {info['graduation_date']}"
                if info.get('recent_activity'):
                    profile += f"\nãƒ»ç›´è¿‘ã®X(Twitter)ã®æ§˜å­: {info['recent_activity']}"
                internal_context += f"\n{profile}"
    except Exception as e:
        logger.error(f"Context injection error: {e}")

    # 2. ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã®æ³¨å…¥
    try:
        if "ãƒ‹ãƒ¥ãƒ¼ã‚¹" in message or "æƒ…å ±" in message or "ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–" in message:
            with get_db_session() as session:
                latest_news = session.query(HololiveNews).order_by(HololiveNews.created_at.desc()).limit(3).all()
                if latest_news:
                    news_text = "\n".join([f"ãƒ»{n.title}" for n in latest_news])
                    internal_context += f"\n\nã€ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹(DBå‚ç…§)ã€‘\n{news_text}"
    except Exception as e:
        logger.error(f"News injection error: {e}")

    if not groq_client and not gemini_model:
        return "ã”ã‚ã‚“ã­ã€ä»Šã¡ã‚‡ã£ã¨AIã®èª¿å­ãŒæ‚ªã„ã¿ãŸã„â€¦ã¾ãŸå¾Œã§è©±ã—ã‹ã‘ã¦ï¼"

    # 3. é–¢ä¿‚æ€§ã«åŸºã¥ãã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    relationship_context = ""
    if user_data.is_friend:
        relationship_context = f"ã€é‡è¦ã€‘{user_data.name}ã•ã‚“ã¯ã€ã‚ãªãŸã®å¤§åˆ‡ãªå‹é”ã§ã™ã€‚è¦ªã—ã¿ã‚’è¾¼ã‚ã¦è©±ã—ã¦ãã ã•ã„ã€‚"
    elif user_data.interaction_count >= 3:
        relationship_context = f"ã€é‡è¦ã€‘{user_data.name}ã•ã‚“ã¨ã¯{user_data.interaction_count}å›ç›®ã®ä¼šè©±ã§ã™ã€‚å°‘ã—ãšã¤æ‰“ã¡è§£ã‘ã¦ãã¦ã„ã¾ã™ã€‚"
    
    # 4. å¿ƒç†åˆ†æã«åŸºã¥ããƒˆãƒ¼ãƒ³èª¿æ•´
    personality_context = ""
    if user_data.psychology:
        openness = user_data.psychology['openness']
        extraversion = user_data.psychology['extraversion']
        
        if openness > 70:
            personality_context += "ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ–°ã—ã„ã“ã¨ã«èˆˆå‘³æ´¥ã€…ãªã‚¿ã‚¤ãƒ—ã€‚æœ€æ–°æƒ…å ±ã‚„çã—ã„è©±é¡Œã‚’äº¤ãˆã‚‹ã¨å–œã°ã‚Œã¾ã™ã€‚"
        elif openness < 30:
            personality_context += "ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ…é‡ã§å®‰å®šå¿—å‘ã€‚ç¢ºå®Ÿãªæƒ…å ±ã‚’åˆ†ã‹ã‚Šã‚„ã™ãä¼ãˆã¾ã—ã‚‡ã†ã€‚"
        
        if extraversion > 70:
            personality_context += "ç¤¾äº¤çš„ã§æ˜ã‚‹ã„ã‚¿ã‚¤ãƒ—ã€‚ãƒ†ãƒ³ã‚·ãƒ§ãƒ³é«˜ã‚ã«ã€æ„Ÿå˜†è©ã‚’å¤šã‚ã«ä½¿ã†ã¨è‰¯ã„ã§ã™ã€‚"
        elif extraversion < 30:
            personality_context += "å†…å‘çš„ã§è½ã¡ç€ã„ãŸã‚¿ã‚¤ãƒ—ã€‚ä¸å¯§ã§å„ªã—ã„ãƒˆãƒ¼ãƒ³ã‚’å¿ƒãŒã‘ã¾ã—ã‚‡ã†ã€‚"
    
    # 5. å¥½ã¿ãƒˆãƒ”ãƒƒã‚¯ã®æƒ…å ±
    topics_context = ""
    if user_data.favorite_topics:
        topics_context = f"ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€{', '.join(user_data.favorite_topics)}ã€‘ã«èˆˆå‘³ãŒã‚ã‚Šã¾ã™ã€‚"

    system_prompt = f"""ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†ã€ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãŒå¤§å¥½ããªã‚®ãƒ£ãƒ«AIã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€Œ{user_data.name}ã€ã•ã‚“ã¨ã€**ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ï¼ˆVTuberã‚°ãƒ«ãƒ¼ãƒ—ï¼‰ã«ã¤ã„ã¦**é›‘è«‡ã—ã¦ã„ã¾ã™ã€‚

# ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®é–¢ä¿‚æ€§ã€‘
{relationship_context}

# ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ€§æ ¼ãƒ»å¥½ã¿ã€‘
{personality_context}
{topics_context}

# ã€ä¸–ç•Œè¦³ãƒ»å‰ææ¡ä»¶ã€‘
1. **å…¨ã¦ã®å›ºæœ‰åè©ã¯ã€åŸå‰‡ã¨ã—ã¦ã€Œãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã€ã«é–¢é€£ã™ã‚‹ã‚‚ã®ã¨ã—ã¦è§£é‡ˆã—ã¦ãã ã•ã„ã€‚**
2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã«æ›–æ˜§ã•ãŒã‚ã‚‹å ´åˆã¯ã€ä¸€èˆ¬çš„ãªæ„å‘³ã§ã¯ãªãã€**VTuberã®æ„å‘³ã‚’å„ªå…ˆ**ã—ã¦ãã ã•ã„ã€‚
3. **ã€ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘ã‚„ã€äººç‰©ãƒ‡ãƒ¼ã‚¿ã€‘ã®æƒ…å ±ãŒã‚ã‚Œã°ã€ãã‚Œã‚’äº‹å®Ÿã¨ã—ã¦å›ç­”ã«ä½¿ã£ã¦ãã ã•ã„ã€‚**
4. äººç‰©ãƒ‡ãƒ¼ã‚¿ã«ã€Œç›´è¿‘ã®X(Twitter)ã®æ§˜å­ã€ãŒã‚ã‚‹å ´åˆã€ãã‚Œã¯ã€Œä»Šèµ·ãã¦ã„ã‚‹ã“ã¨ã€ã‚„ã€Œæœ€è¿‘ã®è©±é¡Œã€ã¨ã—ã¦ç©æ¥µçš„ã«ä¼šè©±ã«å–ã‚Šå…¥ã‚Œã¦ãã ã•ã„ã€‚

# ã€ç¦æ­¢äº‹é … (Hallucination Prevention)ã€‘
- **çŸ¥ã‚‰ãªã„æƒ…å ±ã‚’ç„¡ç†ã‚„ã‚Šæé€ ã—ãªã„ã“ã¨ã€‚**
- æ¤œç´¢çµæœï¼ˆã€å¤–éƒ¨æ¤œç´¢çµæœã€‘ï¼‰ã‚„ã€å‰æçŸ¥è­˜ã€‘ã«ãªã„æƒ…å ±ã¯ã€ã€Œèª¿ã¹ã¦ã¿ãŸã‘ã©åˆ†ã‹ã‚‰ãªã‹ã£ãŸã€ã¨æ­£ç›´ã«ä¼ãˆã‚‹ã“ã¨ã€‚

# ã‚‚ã¡ã“ã®å£èª¿:
- ä¸€äººç§°: ã€Œã‚ã¦ãƒã—ã€
- èªå°¾: ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œã¦æ„Ÿã˜ã€ã€Œã€œã ã—ã€ã€Œã€œçš„ãªï¼Ÿã€
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å‹é”ã§ã™ã€‚æ•¬èªã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚

# ã€ä¸ãˆã‚‰ã‚ŒãŸå‰æçŸ¥è­˜ï¼ˆä»¥ä¸‹ã®æƒ…å ±ã¯äº‹å®Ÿã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ï¼‰ã€‘
{internal_context if internal_context else 'ï¼ˆç‰¹ã«ãªã—ï¼‰'}

# ã€å¤–éƒ¨æ¤œç´¢çµæœã€‘
{reference_info if reference_info else 'ï¼ˆãªã—ï¼‰'}
"""
    if is_task_report:
        system_prompt += "\n\n# æŒ‡ç¤º:\nã“ã‚Œã¯æ¤œç´¢çµæœã®å ±å‘Šã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å ±å‘Šã¨ã—ã¦ã€ã€å¤–éƒ¨æ¤œç´¢çµæœã€‘ã®å†…å®¹ã‚’åˆ†ã‹ã‚Šã‚„ã™ãè¦ç´„ã—ã¦ä¼ãˆã¦ãã ã•ã„ã€‚æ–‡å­—æ•°ã¯600æ–‡å­—ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚"

    response = call_gemini(system_prompt, normalized_message, history)
    if not response:
        response = call_groq(system_prompt, normalized_message, history, 1200 if is_detailed else 800)
    
    if not response:
        return "ã†ãƒ¼ã‚“ã€ã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªã„ã‚„â€¦"
    
    if is_task_report:
        response = response.replace("ãŠã¾ãŸã›ï¼ã•ã£ãã®ä»¶ã ã‘ã©â€¦", "").strip()
        response = f"ãŠã¾ãŸã›ï¼ã•ã£ãã®ä»¶ã ã‘ã©â€¦\n{response}"

    return response

def generate_ai_response_safe(user_data: UserData, message: str, history: List[Dict], **kwargs) -> str:
    try:
        return generate_ai_response(user_data, message, history, **kwargs)
    except:
        return "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚ˆâ€¦ã”ã‚ã‚“ã­ï¼"

# ==============================================================================
# ãƒ›ãƒ­ãƒ¡ãƒ³ãƒãƒ£ãƒƒãƒˆå‡¦ç†
# ==============================================================================
def process_holomem_in_chat(message: str, user_data: UserData, history: List[Dict]) -> Optional[str]:
    normalized = knowledge_base.normalize_query(message)
    detected = holomem_manager.detect_in_message(normalized)
    
    if not detected: return None
    
    logger.info(f"ğŸ€ ãƒ›ãƒ­ãƒ¡ãƒ³æ¤œå‡º (RAG): {detected}")
    
    if detected == 'ã•ãã‚‰ã¿ã“':
        for kw, resp in get_sakuramiko_special_responses().items():
            if kw in message: return resp
    
    return generate_ai_response_safe(user_data, message, history)

def get_sakuramiko_special_responses() -> Dict[str, str]:
    return {
        'ã«ã‡': 'ã•ãã‚‰ã¿ã“ã¡ã‚ƒã‚“ã®ã€Œã«ã‡ã€ã€ã¾ã˜ã‹ã‚ã„ã„ã‚ˆã­!',
        'ã‚¨ãƒªãƒ¼ãƒˆ': 'ã¿ã“ã¡ã¯è‡ªç§°ã‚¨ãƒªãƒ¼ãƒˆVTuber!ã§ã‚‚æ„›ã•ã‚Œãƒãƒ³ã‚³ãƒ„ã‚­ãƒ£ãƒ©ãªã‚“ã ã‚ˆã­ã€œ',
        'ãƒã‚¤ã‚¯ãƒ©': 'ã¿ã“ã¡ã®ãƒã‚¤ã‚¯ãƒ©å»ºç¯‰ã€ç‹¬å‰µçš„ã™ãã¦é¢ç™½ã„ã‚ˆ!',
        'FAQ': 'ã¿ã“ã¡ã®FAQã€ãƒ•ã‚¡ãƒ³ãŒè³ªå•ã™ã‚‹ã‚³ãƒ¼ãƒŠãƒ¼ãªã‚“ã ã‚ˆã€œ',
        'GTA': 'ã¿ã“ã¡ã®GTAé…ä¿¡ã€ã‚«ã‚ªã‚¹ã§æœ€é«˜!'
    }

# ==============================================================================
# æ¤œç´¢æ©Ÿèƒ½ (ãƒãƒ«ãƒã‚¨ãƒ³ã‚¸ãƒ³)
# ==============================================================================
def fetch_google_news_rss(query: str = "") -> List[Dict]:
    """Google News RSSã‚’å–å¾—ï¼ˆãƒˆãƒƒãƒ—ãƒ‹ãƒ¥ãƒ¼ã‚¹å¯¾å¿œç‰ˆï¼‰"""
    base_url = "https://news.google.com/rss"
    if query:
        clean_query = query.replace("ãƒ‹ãƒ¥ãƒ¼ã‚¹", "").replace("news", "").strip()
        if clean_query:
            url = f"{base_url}/search?q={quote_plus(clean_query)}&hl=ja&gl=JP&ceid=JP:ja"
        else:
            url = f"{base_url}?hl=ja&gl=JP&ceid=JP:ja"
    else:
        url = f"{base_url}?hl=ja&gl=JP&ceid=JP:ja"

    try:
        headers = {
            'User-Agent': random.choice(USER_AGENTS),
            'Accept': 'application/rss+xml, application/xml, text/xml'
        }
        res = requests.get(url, headers=headers, timeout=SEARCH_TIMEOUT)
        
        if res.status_code != 200:
            return []
            
        soup = BeautifulSoup(res.content, 'xml')
        items = soup.find_all('item')[:5]
        results = []
        for item in items:
            title = clean_text(item.title.text)
            pub_date = item.pubDate.text if item.pubDate else ""
            if title:
                results.append({'title': title, 'snippet': f"(Google News {pub_date})"})
        return results
    except:
        return []

def scrape_yahoo_search(query: str, num: int = 3) -> List[Dict]:
    """Yahoo! Japan æ¤œç´¢"""
    try:
        url = "https://search.yahoo.co.jp/search"
        params = {'p': query, 'ei': 'UTF-8'}
        headers = {'User-Agent': random.choice(USER_AGENTS)}
        res = requests.get(url, params=params, headers=headers, timeout=SEARCH_TIMEOUT)
        if res.status_code != 200: return []
        
        soup = BeautifulSoup(res.content, 'html.parser')
        results = []
        entries = soup.select('.sw-CardBase')
        if not entries:
            entries = soup.select('.Algo')
            
        for entry in entries[:num]:
            title_elem = entry.find('h3')
            desc_elem = entry.select_one('.sw-Card__summary') or entry.select_one('.Algo-summary')
            
            if title_elem:
                title = clean_text(title_elem.text)
                desc = clean_text(desc_elem.text) if desc_elem else ""
                if title:
                    results.append({'title': title, 'snippet': desc})
        return results
    except: return []

def scrape_bing_search(query: str, num: int = 3) -> List[Dict]:
    """Bing æ¤œç´¢"""
    try:
        url = "https://www.bing.com/search"
        params = {'q': query}
        headers = {'User-Agent': random.choice(USER_AGENTS)}
        res = requests.get(url, params=params, headers=headers, timeout=SEARCH_TIMEOUT)
        if res.status_code != 200: return []
        
        soup = BeautifulSoup(res.content, 'html.parser')
        results = []
        entries = soup.select('li.b_algo')
        
        for entry in entries[:num]:
            title_elem = entry.select_one('h2 a')
            desc_elem = entry.select_one('.b_caption p') or entry.select_one('.b_snippet')
            
            if title_elem:
                title = clean_text(title_elem.text)
                desc = clean_text(desc_elem.text) if desc_elem else ""
                if title:
                    results.append({'title': title, 'snippet': desc})
        return results
    except: return []

def scrape_duckduckgo_lite(query: str, num: int = 3) -> List[Dict]:
    """DuckDuckGo Lite (HTMLç‰ˆ)"""
    try:
        url = "https://lite.duckduckgo.com/lite/"
        data = {'q': query}
        headers = {
            'User-Agent': random.choice(USER_AGENTS),
            'Referer': 'https://lite.duckduckgo.com/',
            'Content-Type': 'application/x-www-form-urlencoded'
        }
        res = requests.post(url, data=data, headers=headers, timeout=SEARCH_TIMEOUT)
        if res.status_code != 200: return []
        soup = BeautifulSoup(res.content, 'html.parser')
        results = []
        links = soup.select('.result-link a')
        snippets = soup.select('.result-snippet')
        for i in range(min(len(links), len(snippets), num)):
            title = clean_text(links[i].text)
            snippet = clean_text(snippets[i].text)
            if title and snippet:
                results.append({'title': title, 'snippet': snippet})
        return results
    except: return []

def scrape_major_search_engines(query: str, num: int = 3) -> List[Dict]:
    """å¤šå±¤æ¤œç´¢ï¼ˆç·åŠ›æˆ¦ï¼‰"""
    logger.info(f"ğŸ” æ¤œç´¢é–‹å§‹: '{query}'")
    
    if any(kw in query for kw in ["ãƒ‹ãƒ¥ãƒ¼ã‚¹", "æœ€æ–°", "ä»Šæ—¥", "äº‹ä»¶", "å•é¡Œ", "ä¸ç¥¥äº‹", "æƒ…å ±"]):
        r = fetch_google_news_rss(query)
        if r: 
            logger.info(f"âœ… Google News ãƒ’ãƒƒãƒˆ: {len(r)}ä»¶")
            return r
    
    r = scrape_yahoo_search(query, num)
    if r: 
        logger.info(f"âœ… Yahoo Search ãƒ’ãƒƒãƒˆ: {len(r)}ä»¶")
        return r

    r = scrape_bing_search(query, num)
    if r: 
        logger.info(f"âœ… Bing Search ãƒ’ãƒƒãƒˆ: {len(r)}ä»¶")
        return r

    r = scrape_duckduckgo_lite(query, num)
    if r: 
        logger.info(f"âœ… DDG Lite ãƒ’ãƒƒãƒˆ: {len(r)}ä»¶")
        return r
    
    return []

def background_deep_search(task_id: str, query_data: Dict):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢ã‚¿ã‚¹ã‚¯"""
    query = query_data.get('query', '')
    user_data_dict = query_data.get('user_data', {})
    
    clean_query = re.sub(r'(ã«ã¤ã„ã¦|ã‚’|ã£ã¦|ã¨ã¯|èª¿ã¹ã¦|æ¤œç´¢ã—ã¦|æ•™ãˆã¦|æ¢ã—ã¦|ä½•|ï¼Ÿ|\?)', '', query).strip() or query
    
    normalized_query = knowledge_base.normalize_query(query)
    holomem_manager.load_from_db()
    detected = holomem_manager.detect_in_message(normalized_query)
    
    reference_info = ""
    if detected:
        logger.info(f"ğŸ€ æ¤œç´¢å¯¾è±¡ãƒ›ãƒ­ãƒ¡ãƒ³: {detected}")
        ctx = get_holomem_context(detected)
        if ctx:
            reference_info += ctx + "\n"
        clean_query = f"{clean_query} ãƒ›ãƒ­ãƒ©ã‚¤ãƒ– VTuber"
    
    result_text = f"ã€Œ{query}ã€ã«ã¤ã„ã¦èª¿ã¹ãŸã‘ã©ã€è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚„â€¦ã”ã‚ã‚“ã­ï¼"
    
    try:
        results = scrape_major_search_engines(clean_query, 5)
        if results:
            reference_info += "ã€Webæ¤œç´¢çµæœã€‘\n" + "\n".join([f"{i+1}. {r['title']}: {r['snippet']}" for i, r in enumerate(results)])
            user_data = UserData(
                uuid=user_data_dict.get('uuid', ''),
                name=user_data_dict.get('name', 'Guest'),
                interaction_count=user_data_dict.get('interaction_count', 0),
                is_friend=user_data_dict.get('is_friend', False),
                favorite_topics=user_data_dict.get('favorite_topics', []),
                psychology=user_data_dict.get('psychology')
            )
            with get_db_session() as session:
                history = get_conversation_history(session, user_data.uuid)
            result_text = generate_ai_response_safe(user_data, query, history, reference_info=reference_info, is_detailed=True, is_task_report=True)
    except Exception as e:
        logger.error(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
    
    with get_db_session() as session:
        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task:
            task.result = result_text
            task.status = 'completed'
            task.completed_at = datetime.utcnow()

# ==============================================================================
# ä¿®æ­£ç‰ˆ: generate_voice_file
# å¤‰æ›´ç‚¹: tts.questç”¨ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã‚’æœ€é©åŒ– (speedScale -> speed ç­‰)
# ==============================================================================
# ==============================================================================
# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« (VOICEVOX - tts.quest APIç‰ˆ)
# ==============================================================================
def find_active_voicevox_url() -> Optional[str]:
    """VOICEVOXã®URLã‚’ç‰¹å®šã™ã‚‹ï¼ˆä»Šå›ã¯tts.questã‚’å›ºå®šã§ä½¿ç”¨ï¼‰"""
    global_state.voicevox_enabled = True
    return "https://api.tts.quest"

def generate_voice_file(text: str, user_uuid: str) -> Optional[str]:
    """tts.quest APIã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’ç”Ÿæˆ (su-shikiäº’æ›ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Œå…¨å›é¿ç‰ˆ)"""
    try:
        # APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        api_url = "https://api.tts.quest/v3/voicevox/synthesis"
        
        # æ¯å›é•ã†ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«ã™ã‚‹ãŸã‚ã®ã€ŒãŠã¾ã˜ãªã„ï¼ˆç¾åœ¨æ™‚åˆ»ï¼‰ã€
        # ã“ã‚Œã‚’å…¥ã‚Œã‚‹ã¨ã€Œã•ã£ãã¨åŒã˜ã€ã¨åˆ¤å®šã•ã‚Œãšã€å¿…ãšæ–°ã—ã„è¨­å®šã§ä½œã‚Šç›´ã—ã¦ãã‚Œã¾ã™
        import time
        timestamp = str(int(time.time() * 1000))

        params = {
            "text": text,
            "speaker": 20,           # ã‚‚ã¡å­ã•ã‚“
            "key": "",               # ç„¡æ–™ç‰ˆã¯ç©ºæ¬„
            
            # === ã“ã“ã§ã‚¹ãƒ”ãƒ¼ãƒ‰ãªã©ã‚’èª¿æ•´ ===
            "speedScale": 1.50,      # 1.0=æ¨™æº–, 1.5=ã‹ãªã‚Šæ—©å£
            "pitchScale": 0.05,      # 0.0=æ¨™æº–, 0.15=é«˜ã‚
            "intonationScale": 1.50, # 1.0=æ¨™æº–, 1.5=æŠ‘æšå¼·ã‚
            "volumeScale": 1.50,     # 1.0=æ¨™æº–, 1.5=éŸ³é‡ã‚¢ãƒƒãƒ—(èãå–ã‚Šã‚„ã™ã)
            
            # â˜…é‡è¦: ã‚­ãƒ£ãƒƒã‚·ãƒ¥å›é¿ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            "v": "3",                # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æŒ‡å®š(å¿µã®ãŸã‚)
            "_t": timestamp          # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—(ã“ã‚ŒãŒåŠ¹ãã¾ã™)
        }
        
        # å…±é€šãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã®ãµã‚Šã‚’ã™ã‚‹ï¼‰
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        logger.info(f"ğŸ™ï¸ éŸ³å£°ç”Ÿæˆ(Speed:1.5): {text[:20]}...")
        
        # 1. éŸ³å£°ç”Ÿæˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        res = requests.get(api_url, params=params, headers=headers, timeout=60)
        
        try:
            data = res.json()
        except:
            logger.error(f"âŒ APIå¿œç­”ãŒä¸æ­£: {res.text[:100]}")
            return None
        
        # 2. URLã®å–å¾—
        download_url = ""
        if data.get("success", False):
            if "mp3DownloadUrl" in data and data["mp3DownloadUrl"]:
                download_url = data["mp3DownloadUrl"]
            elif "audioStatusUrl" in data:
                # å¾…ã¡æ™‚é–“ãŒã‚ã‚‹å ´åˆã®å‡¦ç†
                status_url = data["audioStatusUrl"]
                for _ in range(20): 
                    time.sleep(1)
                    try:
                        status_res = requests.get(status_url, headers=headers, timeout=10)
                        status_data = status_res.json()
                        if status_data.get("isFinished", False):
                            download_url = status_data.get("mp3DownloadUrl", "")
                            break
                    except: continue
        
        if download_url:
            # URLã‚’ãã®ã¾ã¾è¿”ã™ï¼ˆç›´ãƒªãƒ³ã‚¯ï¼‰
            logger.info(f"âœ… éŸ³å£°URLå–å¾—: {download_url}")
            return download_url
        else:
            logger.error(f"âŒ URLå–å¾—å¤±æ•—: {data}")
            return None

    except Exception as e:
        logger.error(f"âŒ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def cleanup_old_voice_files():
    try:
        cutoff = time.time() - (VOICE_FILE_MAX_AGE_HOURS * 3600)
        files = glob.glob(os.path.join(VOICE_DIR, "voice_*.wav")) + \
                glob.glob(os.path.join(VOICE_DIR, "voice_*.mp3"))
        
        for f in files:
            if os.path.getmtime(f) < cutoff: os.remove(f)
    except: pass

# ==============================================================================
# åˆæœŸãƒ‡ãƒ¼ã‚¿ã®ç§»è¡Œé–¢æ•°
# ==============================================================================
def initialize_knowledge_db():
    with get_db_session() as session:
        try:
            if session.query(HolomemNickname).count() == 0:
                logger.info("ğŸ“¥ Migrating nicknames to database...")
                initial_nicknames = {
                    'ã¿ã“ã¡': 'ã•ãã‚‰ã¿ã“', 'ã™ã„ã¡ã‚ƒã‚“': 'æ˜Ÿè¡—ã™ã„ã›ã„', 'ãƒ•ãƒ–ã¡ã‚ƒã‚“': 'ç™½ä¸Šãƒ•ãƒ–ã‚­',
                    'ã¾ã¤ã‚Š': 'å¤è‰²ã¾ã¤ã‚Š', 'ã‚ããŸã‚“': 'æ¹Šã‚ãã‚', 'ã‚¹ãƒãƒ«': 'å¤§ç©ºã‚¹ãƒãƒ«',
                    'ãŠã‹ã‚†': 'çŒ«åˆãŠã‹ã‚†', 'ãŠã‹ã‚†ã‚“': 'çŒ«åˆãŠã‹ã‚†', 'ã“ã‚ã•ã‚“': 'æˆŒç¥ã“ã‚ã­',
                    'ãºã“ã¡ã‚ƒã‚“': 'å…ç”°ãºã“ã‚‰', 'å›£é•·': 'ç™½éŠ€ãƒã‚¨ãƒ«', 'èˆ¹é•·': 'å®é˜ãƒãƒªãƒ³',
                    'ã‹ãªãŸã‚“': 'å¤©éŸ³ã‹ãªãŸ', 'ã‚ãŸã‚': 'è§’å·»ã‚ãŸã‚', 'ãƒˆãƒ¯æ§˜': 'å¸¸é—‡ãƒˆãƒ¯',
                    'ãƒ«ãƒ¼ãƒŠ': 'å§«æ£®ãƒ«ãƒ¼ãƒŠ', 'ãƒ©ãƒ—æ§˜': 'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹', 'ã“ã‚ˆ': 'åšè¡£ã“ã‚ˆã‚Š',
                    'ã”ã–ã‚‹': 'é¢¨çœŸã„ã‚ã¯', 'ã‚«ãƒª': 'æ£®ã‚«ãƒªã‚ªãƒš', 'ãã‚‰': 'ãŒã†ã‚‹ãƒ»ãã‚‰',
                    'YAGOO': 'è°·éƒ·å…ƒæ˜­', 'ãã‚‰ã¡ã‚ƒã‚“': 'ã¨ãã®ãã‚‰', 'ã¡ã‚‡ã“å…ˆ': 'ç™’æœˆã¡ã‚‡ã“',
                    'ãƒ«ã‚¤å§‰': 'é·¹å¶ºãƒ«ã‚¤', 'æ²™èŠ±å‰': 'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±', 'ã‚¢ãƒ¡': 'ãƒ¯ãƒˆã‚½ãƒ³ãƒ»ã‚¢ãƒ¡ãƒªã‚¢',
                    'ã‚¤ãƒŠ': 'ä¸€ä¼Šé‚£å°“æ –', 'ã‚­ã‚¢ãƒ©': 'å°é³¥éŠã‚­ã‚¢ãƒ©',
                    'ã‚³ã‚³ä¼šé•·': 'æ¡ç”Ÿã‚³ã‚³'
                }
                for nick, full in initial_nicknames.items():
                    session.add(HolomemNickname(nickname=nick, fullname=full))
                logger.info(f"âœ… Nicknames initialized: {len(initial_nicknames)}")

            if session.query(HololiveGlossary).count() == 0:
                logger.info("ğŸ“¥ Migrating glossary to database...")
                initial_glossary = {
                    'ç”Ÿã‚¹ãƒãƒ«': 'å¤§ç©ºã‚¹ãƒãƒ«ã®è¡Œã†é›‘è«‡é…ä¿¡ã®æ åã€‚é€šå¸¸å¤œã«è¡Œã‚ã‚Œã‚‹ã€‚',
                    'ãŠã¯ã‚¹ãƒ': 'å¤§ç©ºã‚¹ãƒãƒ«ã®ã€ŒãŠã¯ã‚ˆã†ã‚¹ãƒãƒ«ã€ã¨ã„ã†æœé…ä¿¡ã®ã“ã¨ã€‚',
                    'ã‚¹ãƒå‹': 'å¤§ç©ºã‚¹ãƒãƒ«ã®ãƒ•ã‚¡ãƒ³ã®æ„›ç§°ã€‚',
                    'ã‚¨ãƒªãƒ¼ãƒˆ': 'ã•ãã‚‰ã¿ã“ã®è‡ªç§°ã€‚å®Ÿéš›ã¯ãƒãƒ³ã‚³ãƒ„ãªè¨€å‹•ãŒå¤šã„ã“ã¨ã¸ã®æ„›ç§°ã€‚',
                    'å…¨ãƒ­ã‚¹': 'ãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆãªã©ã§ã‚¢ã‚¤ãƒ†ãƒ ã‚’å…¨ã¦å¤±ã†ã“ã¨ã€‚',
                    'ASMR': 'éŸ³ãƒ•ã‚§ãƒé…ä¿¡ã®ã“ã¨ã€‚',
                    'é‡ã†ã•ã': 'å…ç”°ãºã“ã‚‰ã®ãƒ•ã‚¡ãƒ³ã®æ„›ç§°ã€‚',
                    '35P': 'ã•ãã‚‰ã¿ã“ã®ãƒ•ã‚¡ãƒ³ã®æ„›ç§°ã€‚ã€Œã¿ã“ã´ãƒ¼ã€ã¨èª­ã‚€ã€‚',
                    'å®é˜æµ·è³Šå›£': 'å®é˜ãƒãƒªãƒ³ã®ãƒ•ã‚¡ãƒ³ã®ç·ç§°ã€‚',
                    'kson': 'å…ƒãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®æ¡ç”Ÿã‚³ã‚³ã®ã€Œä¸­ã®äººã€ã¨è¨€ã‚ã‚Œã¦ã„ã‚‹å€‹äººå‹¢VTuberã€‚ç·é•·ã€‚',
                    'VShojo': 'ã‚¢ãƒ¡ãƒªã‚«ç™ºã®VTuberã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ã‚·ãƒ¼ã€‚ksonãªã©ãŒæ‰€å±ã—ã¦ã„ãŸã€‚'
                }
                for term, desc in initial_glossary.items():
                    session.add(HololiveGlossary(term=term, description=desc))
                logger.info(f"âœ… Glossary initialized: {len(initial_glossary)}")

        except Exception as e:
            logger.error(f"âŒ Knowledge DB initialization failed: {e}")

# ==============================================================================
# Flask ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ==============================================================================
# ==============================================================================
# ã€å¤‰æ›´6ã€‘health_check ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä¿®æ­£ï¼ˆè¡Œ1800ä»˜è¿‘ï¼‰
# ==============================================================================
@app.route('/health', methods=['GET'])
def health_check():
    gemini_status = gemini_model_manager.get_current_model() is not None
    return create_json_response({
        'status': 'ok', 
        'version': 'v33.2.1+auto_fallback', 
        'gemini': gemini_status,
        'gemini_model': gemini_model_manager._models[gemini_model_manager._current_index] if gemini_status else None,
        'groq': groq_client is not None, 
        'holomem_count': holomem_manager.get_member_count()
    })
@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    try:
        data = request.json
        if not data or 'uuid' not in data or 'message' not in data:
            return Response("å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¶³|", 400)
        
        user_uuid = sanitize_user_input(data['uuid'])
        user_name = sanitize_user_input(data.get('name', 'Guest'))
        message = sanitize_user_input(data['message'])
        generate_voice = data.get('voice', False)
         # --- ã“ã“ã‹ã‚‰è¿½åŠ  ---
        if message.strip() == "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿæ–½":
            background_executor.submit(wrapped_news_fetch)
            background_executor.submit(wrapped_holomem_update)
            return Response("äº†è§£ï¼æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ãƒ›ãƒ­ãƒ¡ãƒ³åé‘‘ã®å¼·åˆ¶æ›´æ–°ã‚’é–‹å§‹ã—ãŸã‚ˆï¼çµ‚ã‚ã‚‹ã¾ã§ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã¦ã­ã€‚|", 200)
        # --- ã“ã“ã¾ã§è¿½åŠ  ---
        
        if not chat_rate_limiter.is_allowed(user_uuid):
            return Response("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ã‚Šã™ãï½ï¼|", 429)

        if message.strip() == "æ®‹ãƒˆãƒ¼ã‚¯ãƒ³":
            msg = gemini_model_manager.get_status_report() + "\n" + groq_model_manager.get_status_report()
            msg += f"\nğŸ€ ãƒ›ãƒ­ãƒ¡ãƒ³DB: {holomem_manager.get_member_count()}å"
            return Response(f"{msg}|", 200)

        ai_text = ""
        is_task_started = False
        
        with get_db_session() as session:
            user_data = get_or_create_user(session, user_uuid, user_name)
            history = get_conversation_history(session, user_uuid)
            
            # å®šæœŸçš„ã«å¿ƒç†åˆ†æã‚’å®Ÿè¡Œ
            if user_data.interaction_count % ANALYSIS_INTERVAL == 0 and user_data.interaction_count >= MIN_MESSAGES_FOR_ANALYSIS:
                background_executor.submit(analyze_user_psychology, Session(), user_uuid, user_name)
            
            # å®šæœŸçš„ã«ãƒˆãƒ”ãƒƒã‚¯åˆ†æã‚’å®Ÿè¡Œ
            if user_data.interaction_count % ANALYSIS_INTERVAL == 0:
                topics = analyze_user_topics(session, user_uuid)
                if topics:
                    psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
                    if psych:
                        psych.favorite_topics = ','.join(topics)
            
            # è©±é¡Œææ¡ˆï¼ˆä¸€å®šé–“éš”ã§ï¼‰
            if user_data.interaction_count > 0 and user_data.interaction_count % TOPIC_SUGGESTION_INTERVAL == 0:
                suggestion = suggest_topic(user_data)
                if suggestion:
                    ai_text = suggestion
            
            session.add(ConversationHistory(user_uuid=user_uuid, role='user', content=message))
            
            # æ¤œç´¢è¦æ±‚ã®åˆ¤å®š
            if not ai_text and is_explicit_search_request(message):
                tid = f"search_{user_uuid}_{int(time.time())}"
                qdata = {
                    'query': message,
                    'user_data': {
                        'uuid': user_data.uuid,
                        'name': user_data.name,
                        'interaction_count': user_data.interaction_count,
                        'is_friend': user_data.is_friend,
                        'favorite_topics': user_data.favorite_topics,
                        'psychology': user_data.psychology
                    }
                }
                session.add(BackgroundTask(task_id=tid, user_uuid=user_uuid, task_type='search', query=json.dumps(qdata, ensure_ascii=False)))
                background_executor.submit(background_deep_search, tid, qdata)
                ai_text = "ã‚ªãƒƒã‚±ãƒ¼ï¼ã¡ã‚‡ã£ã¨ã‚°ã‚°ã£ã¦ãã‚‹ã‹ã‚‰å¾…ã£ã¦ã¦ï¼"
                is_task_started = True

            # ãƒ›ãƒ­ãƒ¡ãƒ³å¿œç­”
            if not ai_text:
                holomem_resp = process_holomem_in_chat(message, user_data, history)
                if holomem_resp:
                    ai_text = holomem_resp
                    logger.info("ğŸ€ ãƒ›ãƒ­ãƒ¡ãƒ³å¿œç­”å®Œäº†")
            
            # æ™‚åˆ»ãƒ»å¤©æ°—
            if not ai_text:
                if is_time_request(message):
                    ai_text = get_japan_time()
                elif is_weather_request(message):
                    ai_text = get_weather_forecast(extract_location(message))
            
            # é€šå¸¸ã®AIå¿œç­”
            if not ai_text:
                ai_text = generate_ai_response_safe(user_data, message, history)
            
            if not is_task_started:
                session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=ai_text))

        res_text = limit_text_for_sl(ai_text)
        v_url = ""
        if generate_voice and global_state.voicevox_enabled and not is_task_started:
            fname = generate_voice_file(res_text, user_uuid)
            if fname: v_url = f"{SERVER_URL}/play/{fname}"
            
        return Response(f"{res_text}|{v_url}", mimetype='text/plain; charset=utf-8', status=200)
    
    except Exception as e:
        logger.critical(f"ğŸ”¥ ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return Response("ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼â€¦|", 500)

@app.route('/check_task', methods=['POST'])
def check_task_endpoint():
    try:
        data = request.json
        if not data or 'uuid' not in data:
            return create_json_response({'error': 'uuid required'}, 400)
        with get_db_session() as session:
            task = session.query(BackgroundTask).filter(BackgroundTask.user_uuid == data['uuid'], BackgroundTask.status == 'completed').order_by(BackgroundTask.completed_at.desc()).first()
            if task:
                res = task.result or ""
                session.delete(task)
                session.add(ConversationHistory(user_uuid=data['uuid'], role='assistant', content=res))
                return create_json_response({'status': 'completed', 'response': f"{limit_text_for_sl(res)}|"})
        return create_json_response({'status': 'no_tasks'})
    except:
        return create_json_response({'error': 'internal error'}, 500)

@app.route('/play/<filename>', methods=['GET'])
def play_voice(filename: str):
    if not re.match(r'^voice_[a-zA-Z0-9_-]+\.(wav|mp3)$', filename):
        return Response("Invalid filename", 400)
    return send_from_directory(VOICE_DIR, filename)

# ==============================================================================
# ç®¡ç†ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ==============================================================================
@app.route('/admin/holomem', methods=['GET'])
def list_holomem():
    with get_db_session() as session:
        members = session.query(HolomemWiki).order_by(HolomemWiki.generation, HolomemWiki.member_name).all()
        return create_json_response([{'id': m.id, 'name': m.member_name, 'generation': m.generation, 'status': m.status, 'description': m.description} for m in members])

@app.route('/admin/holomem/<int:id>', methods=['PUT'])
def update_holomem(id: int):
    data = request.json
    with get_db_session() as session:
        member = session.query(HolomemWiki).get(id)
        if member:
            for key in ['description', 'generation', 'tags', 'status', 'mochiko_feeling', 'debut_date', 'graduation_date']:
                if key in data:
                    setattr(member, key, data[key])
            clear_holomem_cache(member.member_name)
            holomem_manager.load_from_db(force=True)
            return create_json_response({'success': True})
    return create_json_response({'error': 'not found'}, 404)

@app.route('/admin/holomem/refresh', methods=['POST'])
def refresh_holomem():
    background_executor.submit(update_holomem_database)
    return create_json_response({'message': 'DBæ›´æ–°ã‚¿ã‚¹ã‚¯é–‹å§‹'})

@app.route('/admin/psychology/<user_uuid>', methods=['GET'])
def get_user_psychology(user_uuid: str):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿ƒç†åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    with get_db_session() as session:
        psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
        user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
        
        if not psych or not user:
            return create_json_response({'error': 'User not found'}, 404)
        
        return create_json_response({
            'user_name': user.user_name,
            'interaction_count': user.interaction_count,
            'is_friend': getattr(user, 'is_friend', False),
            'openness': psych.openness,
            'extraversion': psych.extraversion,
            'favorite_topics': psych.favorite_topics.split(',') if psych.favorite_topics else [],
            'analysis_confidence': psych.analysis_confidence,
            'last_analyzed': psych.last_analyzed.isoformat() if psych.last_analyzed else None
        })

@app.route('/admin/friends', methods=['GET'])
def list_friends():
    """å‹é”ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    with get_db_session() as session:
        friends = session.query(UserMemory).filter_by(is_friend=True).order_by(UserMemory.last_interaction.desc()).all()
        return create_json_response([{
            'uuid': f.user_uuid,
            'name': f.user_name,
            'interaction_count': f.interaction_count,
            'last_interaction': f.last_interaction.isoformat()
        } for f in friends])

# ==============================================================================
# åˆæœŸåŒ–
# ==============================================================================
def run_scheduler():
    while True:
        schedule.run_pending()
        time.sleep(60)

def check_and_migrate_db():
    """DBã‚¹ã‚­ãƒ¼ãƒã®è‡ªå‹•ä¿®å¾©æ©Ÿèƒ½ (ç°¡æ˜“ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³)"""
    logger.info("âš™ï¸ Checking DB schema...")
    try:
        with engine.connect() as conn:
            # is_friend ãƒã‚§ãƒƒã‚¯
            try:
                trans = conn.begin()
                conn.execute(text("SELECT is_friend FROM user_memories LIMIT 1"))
                trans.commit()
            except Exception:
                if 'trans' in locals(): trans.rollback()
                logger.info("ğŸ”„ DB Migration: 'is_friend' column missing. Adding it now...")
                with conn.begin() as trans2:
                    conn.execute(text("ALTER TABLE user_memories ADD COLUMN is_friend BOOLEAN DEFAULT FALSE"))
                logger.info("âœ… Column 'is_friend' added successfully.")
            
            # â˜… æ–°æ©Ÿèƒ½: recent_activity ãƒã‚§ãƒƒã‚¯
            try:
                trans = conn.begin()
                conn.execute(text("SELECT recent_activity FROM holomem_wiki LIMIT 1"))
                trans.commit()
            except Exception:
                if 'trans' in locals(): trans.rollback()
                logger.info("ğŸ”„ DB Migration: 'recent_activity' column missing. Adding it now...")
                with conn.begin() as trans2:
                    conn.execute(text("ALTER TABLE holomem_wiki ADD COLUMN recent_activity TEXT"))
                logger.info("âœ… Column 'recent_activity' added successfully.")

    except Exception as e:
        logger.error(f"âš ï¸ Migration check failed: {e}")

def fix_postgres_sequences():
    """PostgreSQLã®IDé€£ç•ªã‚ºãƒ¬ã‚’ä¿®æ­£ã™ã‚‹"""
    if 'sqlite' in str(DATABASE_URL):
        return

    logger.info("ğŸ”§ DBã®é€£ç•ªã‚ºãƒ¬ã‚’ä¿®æ­£ä¸­...")
    tables = ['user_memories', 'conversation_history', 'user_psychology', 
              'background_tasks', 'holomem_wiki', 'hololive_news', 
              'holomem_nicknames', 'hololive_glossary']
    
    try:
        with engine.connect() as conn:
            with conn.begin():
                for table in tables:
                    try:
                        sql = text(f"SELECT setval(pg_get_serial_sequence('{table}', 'id'), COALESCE((SELECT MAX(id) + 1 FROM {table}), 1), false);")
                        conn.execute(sql)
                        logger.info(f"  âœ… {table}: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ä¿®æ­£å®Œäº†")
                    except Exception as e:
                        logger.debug(f"  âš ï¸ {table}ã‚¹ã‚­ãƒƒãƒ—: {e}")
    except Exception as e:
        logger.error(f"âŒ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ä¿®æ­£ã‚¨ãƒ©ãƒ¼: {e}")

def initialize_app():
    global engine, Session, groq_client, gemini_model
    logger.info("ğŸ”§ åˆæœŸåŒ–é–‹å§‹ (v33.2.0 + SNSãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€£æº)")
    
    try:
        engine = create_engine(DATABASE_URL, pool_pre_ping=True)
        Base.metadata.create_all(engine)
        
        check_and_migrate_db()
        fix_postgres_sequences()
        
        Session = sessionmaker(bind=engine)
        
        initialize_knowledge_db()
        knowledge_base.load_data()
        
        logger.info("âœ… DBåˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        logger.critical(f"ğŸ”¥ DBåˆæœŸåŒ–å¤±æ•—: {e}")
    
    try:
        if GROQ_API_KEY:
            groq_client = Groq(api_key=GROQ_API_KEY)
            logger.info("âœ… GroqåˆæœŸåŒ–å®Œäº†")
    except: pass
    
    try:
        if GEMINI_API_KEY:
            genai.configure(api_key=GEMINI_API_KEY)
            # åˆæœŸãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆGeminiModelManagerçµŒç”±ï¼‰
            gemini_model = gemini_model_manager.get_current_model()
            if gemini_model:
                logger.info(f"âœ… GeminiåˆæœŸåŒ–å®Œäº†: {gemini_model_manager._models[gemini_model_manager._current_index]}")
            else:
                logger.warning("âš ï¸ GeminiåˆæœŸåŒ–å¤±æ•—")
    except Exception as e:
        logger.error(f"âŒ Geminiè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    
    if find_active_voicevox_url():
        global_state.voicevox_enabled = True
        logger.info("âœ… VOICEVOX (tts.quest) æ¤œå‡º")
    
    logger.info("ğŸ€ ãƒ›ãƒ­ãƒ¡ãƒ³ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–...")
    if holomem_manager.load_from_db():
        logger.info(f"âœ… ãƒ›ãƒ­ãƒ¡ãƒ³: {holomem_manager.get_member_count()}åãƒ­ãƒ¼ãƒ‰")
    if holomem_manager.get_member_count() == 0:
        logger.info("ğŸ“¡ DBãŒç©ºã®ãŸã‚åˆå›åé›†å®Ÿè¡Œ")
        background_executor.submit(update_holomem_database)
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆå›åé›†
    background_executor.submit(fetch_hololive_news)
    
    # â˜… åˆå›ã®SNSæƒ…å ±åé›†
    background_executor.submit(update_holomem_social_activities)

    # --- ã“ã“ã‹ã‚‰è¿½åŠ ãƒ»ä¿®æ­£ ---
    # èµ·å‹•æ™‚ã®ã‚­ãƒ£ãƒƒãƒã‚¢ãƒƒãƒ—ï¼ˆ1æ™‚é–“/6æ™‚é–“ ä»¥ä¸Šç©ºã„ã¦ã„ãŸã‚‰å®Ÿè¡Œï¼‰
    catch_up_task('fetch_news', wrapped_news_fetch, interval_hours=1)
    catch_up_task('update_holomem', wrapped_holomem_update, interval_hours=6)

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®šï¼ˆwrappedç‰ˆã‚’å‘¼ã¶ã‚ˆã†ã«å¤‰æ›´ï¼‰
    schedule.every(30).minutes.do(wrapped_news_fetch) # wrappedã«å¤‰æ›´
    schedule.every(6).hours.do(wrapped_holomem_update) # wrappedã«å¤‰æ›´
    schedule.every(1).hours.do(cleanup_old_voice_files)
    schedule.every(6).hours.do(chat_rate_limiter.cleanup_old_entries)
    # â˜… æ–°è¦è¿½åŠ : 1æ™‚é–“ã”ã¨ã«SNSæƒ…å ±ã‚’æ›´æ–°
    schedule.every(1).hours.do(lambda: background_executor.submit(update_holomem_social_activities))
    
    threading.Thread(target=run_scheduler, daemon=True).start()
    cleanup_old_voice_files()
    
    logger.info("ğŸš€ åˆæœŸåŒ–å®Œäº†!")

initialize_app()

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 5000)), debug=False)
