# ==============================================================================
# ã‚‚ã¡ã“AI - å…¨æ©Ÿèƒ½çµ±åˆç‰ˆ (v29.0 - Final Edition)
#
# v28.3ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ä»¥ä¸‹ã®æœ€çµ‚æ”¹å–„ã‚’å®Œå…¨ã«å®Ÿè£…ã—ã¾ã—ãŸ:
# 1. Webæ¤œç´¢ã®å®‰å®šåŒ– (Bingã¸ã®åˆ‡ã‚Šæ›¿ãˆã€ãƒ˜ãƒƒãƒ€ãƒ¼å¼·åŒ–ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿)
# 2. Gemini APIã®å‘¼ã³å‡ºã—ã«é–¢ã™ã‚‹ãƒ­ã‚°ã®è©³ç´°åŒ–
# 3. AIã®å¿œç­”ã‚’ã‚ˆã‚Šæ§‹é€ åŒ–ãƒ»è©³ç´°åŒ–ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¼·åŒ–
# ==============================================================================

# ===== æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
import sys
import os
import requests
import logging
import time
import json
import re
import random
import uuid
import hashlib
import unicodedata
import traceback
import threading
import atexit
import glob
from html import escape
from datetime import datetime, timedelta, timezone
from urllib.parse import quote_plus, urljoin, urlparse
from functools import wraps, lru_cache
from threading import Lock
from concurrent.futures import ThreadPoolExecutor
from collections import OrderedDict, defaultdict
from contextlib import contextmanager

# ===== ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
from flask import Flask, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Text, Boolean, Index, text
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy import pool
from bs4 import BeautifulSoup
import schedule
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from groq import Groq

# ==============================================================================
# åŸºæœ¬è¨­å®šã¨ãƒ­ã‚®ãƒ³ã‚°
# ==============================================================================
log_file_path = '/tmp/mochiko.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(funcName)s] - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(log_file_path, encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ==============================================================================
# å®šæ•°è¨­å®š
# ==============================================================================
VOICE_DIR = '/tmp/voices'
os.makedirs(VOICE_DIR, exist_ok=True)

SERVER_URL = os.environ.get('RENDER_EXTERNAL_URL', "http://localhost:5000")
VOICEVOX_SPEAKER_ID = 20
SL_SAFE_CHAR_LIMIT = 250
MIN_MESSAGES_FOR_ANALYSIS = 10
SEARCH_TIMEOUT = 15

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]
LOCATION_CODES = {"æ±äº¬": "130000", "å¤§é˜ª": "270000", "åå¤å±‹": "230000", "ç¦å²¡": "400000", "æœ­å¹Œ": "016000"}

SPECIALIZED_SITES = {
    'Blender': {'base_url': 'https://docs.blender.org/manual/ja/latest/', 'keywords': ['Blender', 'ãƒ–ãƒ¬ãƒ³ãƒ€ãƒ¼', 'blener']},
    'CGãƒ‹ãƒ¥ãƒ¼ã‚¹': {'base_url': 'https://modelinghappy.com/', 'keywords': ['CGãƒ‹ãƒ¥ãƒ¼ã‚¹', '3DCG', 'CGæ¥­ç•Œ']},
    'è„³ç§‘å­¦ãƒ»å¿ƒç†å­¦': {'base_url': 'https://nazology.kusuguru.co.jp/', 'keywords': ['è„³ç§‘å­¦', 'å¿ƒç†å­¦', 'è„³', 'èªçŸ¥ç§‘å­¦']},
    'ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•': {'base_url': 'https://community.secondlife.com/news/', 'keywords': ['ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•', 'Second Life', 'SL']},
    'ã‚¢ãƒ‹ãƒ¡': {'base_url': 'https://animedb.jp/', 'keywords': ['ã‚¢ãƒ‹ãƒ¡', 'anime', 'ANIME', 'ï½±ï¾†ï¾’', 'ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³', 'ä½œç”»', 'å£°å„ª', 'OP', 'ED']}
}
HOLO_WIKI_URL = 'https://seesaawiki.jp/hololivetv/'

HOLOMEM_KEYWORDS = [
    'ã¨ãã®ãã‚‰', 'ãƒ­ãƒœå­ã•ã‚“', 'ã•ãã‚‰ã¿ã“', 'ã¿ã“ã¡', 'æ˜Ÿè¡—ã™ã„ã›ã„', 'ã™ã„ã¡ã‚ƒã‚“', 'AZKi', 'å¤œç©ºãƒ¡ãƒ«', 'ã‚¢ã‚­ãƒ»ãƒ­ãƒ¼ã‚¼ãƒ³ã‚¿ãƒ¼ãƒ«', 'èµ¤äº•ã¯ã‚ã¨', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å¤è‰²ã¾ã¤ã‚Š', 'æ¹Šã‚ãã‚',
    'ç´«å’²ã‚·ã‚ªãƒ³', 'ç™¾é¬¼ã‚ã‚„ã‚', 'ç™’æœˆã¡ã‚‡ã“', 'å¤§ç©ºã‚¹ãƒãƒ«', 'å¤§ç¥ãƒŸã‚ª', 'çŒ«åˆãŠã‹ã‚†', 'ãŠã‹ã‚†ã‚“', 'æˆŒç¥ã“ã‚ã­', 'ã“ã‚ã•ã‚“', 'å…ç”°ãºã“ã‚‰', 'ãºã“ãƒ¼ã‚‰', 'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢', 'ç™½éŠ€ãƒã‚¨ãƒ«',
    'å®é˜ãƒãƒªãƒ³', 'èˆ¹é•·', 'å¤©éŸ³ã‹ãªãŸ', 'è§’å·»ã‚ãŸã‚', 'å¸¸é—‡ãƒˆãƒ¯', 'å§«æ£®ãƒ«ãƒ¼ãƒŠ', 'é›ªèŠ±ãƒ©ãƒŸã‚£', 'æ¡ƒéˆ´ã­ã­', 'ç…ç™½ã¼ãŸã‚“', 'å°¾ä¸¸ãƒãƒ«ã‚«', 'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹', 'é·¹å¶ºãƒ«ã‚¤', 'åšè¡£ã“ã‚ˆã‚Š',
    'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±', 'é¢¨çœŸã„ã‚ã¯', 'æ£®ã‚«ãƒªã‚ªãƒš', 'å°é³¥éŠã‚­ã‚¢ãƒ©', 'ä¸€ä¼Šé‚£å°“æ –', 'ãŒã†ã‚‹ãƒ»ãã‚‰', 'ã‚µãƒ¡ã¡ã‚ƒã‚“', 'ãƒ¯ãƒˆã‚½ãƒ³ãƒ»ã‚¢ãƒ¡ãƒªã‚¢', 'IRyS', 'ã‚»ãƒ¬ã‚¹ãƒ»ãƒ•ã‚¡ã‚¦ãƒŠ', 'ã‚ªãƒ¼ãƒ­ãƒ»ã‚¯ãƒ­ãƒ‹ãƒ¼',
    'ä¸ƒè©©ãƒ ãƒ¡ã‚¤', 'ãƒã‚³ã‚¹ãƒ»ãƒ™ãƒ¼ãƒ«ã‚º', 'ã‚·ã‚ªãƒªãƒ»ãƒãƒ´ã‚§ãƒ©', 'å¤çŸ³ãƒ“ã‚¸ãƒ¥ãƒ¼', 'ãƒãƒªãƒƒã‚µãƒ»ãƒ¬ã‚¤ãƒ´ãƒ³ã‚¯ãƒ­ãƒ•ãƒˆ', 'ãƒ•ãƒ¯ãƒ¯ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ãƒ¢ã‚³ã‚³ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ã‚¢ãƒ¦ãƒ³ãƒ€ãƒ»ãƒªã‚¹',
    'ãƒ ãƒ¼ãƒŠãƒ»ãƒ›ã‚·ãƒãƒ´ã‚¡', 'ã‚¢ã‚¤ãƒ©ãƒ‹ãƒ»ã‚¤ã‚ªãƒ•ã‚£ãƒ•ãƒ†ã‚£ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¤ã‚¸ãƒ¼ãƒ»ã‚ªãƒªãƒ¼', 'ã‚¢ãƒ¼ãƒ‹ãƒ£ãƒ»ãƒ¡ãƒ«ãƒ•ã‚£ãƒƒã‚µ', 'ãƒ‘ãƒ´ã‚©ãƒªã‚¢ãƒ»ãƒ¬ã‚¤ãƒ', 'ç«å¨é’', 'éŸ³ä¹ƒç€¬å¥', 'ä¸€æ¡è‰ã€…è¯',
    'å„’çƒé¢¨äº­ã‚‰ã§ã‚“', 'è½Ÿã¯ã˜ã‚', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'ãƒ›ãƒ­ãƒ¡ãƒ³', 'hololive', 'YAGOO', 'æ¡ç”Ÿã‚³ã‚³', 'æ½¤ç¾½ã‚‹ã—ã‚', 'é­”ä¹ƒã‚¢ãƒ­ã‚¨', 'ä¹åä¹ä½å‘½'
]
ANIME_KEYWORDS = ['ã‚¢ãƒ‹ãƒ¡', 'anime', 'ANIME', 'ï½±ï¾†ï¾’', 'ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³', 'ä½œç”»', 'å£°å„ª', 'OP', 'ED', 'åŠ‡å ´ç‰ˆ', 'æ˜ ç”»', 'åŸä½œ', 'æ¼«ç”»', 'ãƒ©ãƒãƒ™']
VOICEVOX_URLS = ['http://voicevox-engine:50021', 'http://voicevox:50021', 'http://127.0.0.1:50021', 'http://localhost:50021']

# ==============================================================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° & ã‚¢ãƒ—ãƒªè¨­å®š
# ==============================================================================
class GlobalState:
    def __init__(self):
        self._lock = threading.Lock()
        self._voicevox_enabled = False
        self._active_voicevox_url = None
    @property
    def voicevox_enabled(self):
        with self._lock: return self._voicevox_enabled
    @voicevox_enabled.setter
    def voicevox_enabled(self, value):
        with self._lock: self._voicevox_enabled = value
    @property
    def active_voicevox_url(self):
        with self._lock: return self._active_voicevox_url
    @active_voicevox_url.setter
    def active_voicevox_url(self, value):
        with self._lock: self._active_voicevox_url = value

global_state = GlobalState()
background_executor = ThreadPoolExecutor(max_workers=5)
groq_client, gemini_model, engine, Session = None, None, None, None

app = Flask(__name__)
application = app
app.config['JSON_AS_ASCII'] = False
CORS(app)
Base = declarative_base()

# ==============================================================================
# ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•° èª­ã¿è¾¼ã¿
# ==============================================================================
def get_secret(name):
    env_value = os.environ.get(name)
    if env_value and env_value.strip(): return env_value.strip()
    try:
        secret_file_path = f"/etc/secrets/{name}"
        if os.path.exists(secret_file_path):
            with open(secret_file_path, 'r') as f:
                file_value = f.read().strip()
                if file_value: return file_value
    except Exception: pass
    return None

DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./mochiko_ultimate.db'
GROQ_API_KEY = get_secret('GROQ_API_KEY')
GEMINI_API_KEY = get_secret('GEMINI_API_KEY')
VOICEVOX_URL_FROM_ENV = get_secret('VOICEVOX_URL')
WEATHER_API_KEY = get_secret('WEATHER_API_KEY')

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
# ==============================================================================
class UserMemory(Base):
    __tablename__ = 'user_memories'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    interaction_count = Column(Integer, default=0)
    last_interaction = Column(DateTime, default=datetime.utcnow)

class ConversationHistory(Base):
    __tablename__ = 'conversation_history'
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_uuid = Column(String(255), nullable=False, index=True)
    role = Column(String(10), nullable=False)
    content = Column(Text, nullable=False)
    timestamp = Column(DateTime, default=datetime.utcnow, index=True)

class UserPsychology(Base):
    __tablename__ = 'user_psychology'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    openness = Column(Integer, default=50)
    conscientiousness = Column(Integer, default=50)
    extraversion = Column(Integer, default=50)
    agreeableness = Column(Integer, default=50)
    neuroticism = Column(Integer, default=50)
    interests = Column(Text, nullable=True)
    favorite_topics = Column(Text, nullable=True)
    conversation_style = Column(String(100), nullable=True)
    emotional_tendency = Column(String(100), nullable=True)
    analysis_summary = Column(Text, nullable=True)
    total_messages = Column(Integer, default=0)
    avg_message_length = Column(Integer, default=0)
    analysis_confidence = Column(Integer, default=0)
    last_analyzed = Column(DateTime, nullable=True)

class BackgroundTask(Base):
    __tablename__ = 'background_tasks'
    id = Column(Integer, primary_key=True)
    task_id = Column(String(255), unique=True, nullable=False)
    user_uuid = Column(String(255), nullable=False, index=True)
    task_type = Column(String(50), nullable=False)
    query = Column(Text, nullable=False)
    result = Column(Text, nullable=True)
    status = Column(String(20), default='pending', index=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    completed_at = Column(DateTime, nullable=True)

class HolomemWiki(Base):
    __tablename__ = 'holomem_wiki'
    id = Column(Integer, primary_key=True)
    member_name = Column(String(100), nullable=False, unique=True, index=True)
    description = Column(Text, nullable=True)
    generation = Column(String(100), nullable=True)
    debut_date = Column(String(100), nullable=True)
    tags = Column(Text, nullable=True)
    status = Column(String(50), default='ç¾å½¹', nullable=False)
    graduation_date = Column(String(100), nullable=True)
    graduation_reason = Column(Text, nullable=True)
    mochiko_feeling = Column(Text, nullable=True)
    last_updated = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

class HololiveNews(Base):
    __tablename__ = 'hololive_news'
    id = Column(Integer, primary_key=True)
    title = Column(String(500), nullable=False)
    content = Column(Text, nullable=False)
    url = Column(String(1000), unique=True)
    news_hash = Column(String(100), unique=True, index=True)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)

# ==============================================================================
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ & å®‰å®šæ€§ é–¢é€£
# ==============================================================================
class RateLimiter:
    def __init__(self, max_requests: int, time_window: timedelta):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = defaultdict(list)
        self._lock = threading.Lock()
    def is_allowed(self, user_id: str) -> bool:
        with self._lock:
            now = datetime.utcnow()
            cutoff = now - self.time_window
            self.requests[user_id] = [req_time for req_time in self.requests[user_id] if req_time > cutoff]
            if len(self.requests[user_id]) >= self.max_requests: return False
            self.requests[user_id].append(now)
            return True

chat_rate_limiter = RateLimiter(max_requests=10, time_window=timedelta(minutes=1))

class MochikoException(Exception): pass
class AIModelException(MochikoException): pass
class DatabaseException(MochikoException): pass

def sanitize_user_input(text: str, max_length: int = 1000) -> str:
    if not text: return ""
    text = text[:max_length]
    text = escape(text)
    dangerous_patterns = [r'<script[^>]*>.*?</script>', r'javascript:', r'on\w+\s*=',]
    for pattern in dangerous_patterns: text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.DOTALL)
    return text.strip()

def mask_uuid(uuid: str) -> str:
    if len(uuid) > 8: return f"{uuid[:4]}****{uuid[-4:]}"
    return "****"

# ==============================================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# ==============================================================================
@contextmanager
def get_db_session():
    if not Session:
        logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹SessionãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        raise DatabaseException("Database Session is not initialized.")
    session = Session()
    try:
        yield session
        session.commit()
    except Exception as e:
        logger.error(f"âŒ DBã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}", exc_info=True)
        session.rollback()
        logger.warning("âš ï¸ DBãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯")
        raise DatabaseException(f"DB operation failed: {e}")
    finally:
        session.close()

# ==============================================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ & ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ==============================================================================
def create_json_response(data, status=200):
    return Response(json.dumps(data, ensure_ascii=False), mimetype='application/json; charset=utf-8', status=status)

def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', re.sub(r'<[^>]+>', '', text)).strip()

def limit_text_for_sl(text, max_length=SL_SAFE_CHAR_LIMIT):
    return text[:max_length - 3] + "..." if len(text) > max_length else text

def get_japan_time():
    return f"ä»Šã®æ—¥æœ¬ã®æ™‚é–“ã¯ã€{datetime.now(timezone(timedelta(hours=9))).strftime('%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚%Måˆ†')}ã ã‚ˆï¼"

def is_time_request(message):
    return any(keyword in message for keyword in ['ä»Šä½•æ™‚', 'æ™‚åˆ»', 'ä½•æ™‚', 'ãªã‚“ã˜'])

def is_weather_request(message):
    return any(keyword in message for keyword in ['ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ', 'æ˜æ—¥ã®å¤©æ°—', 'å¤©æ°—äºˆå ±'])

def is_hololive_request(message):
    return any(keyword in message for keyword in HOLOMEM_KEYWORDS)

def is_anime_request(message):
    return any(keyword in message for keyword in ANIME_KEYWORDS)

def detect_specialized_topic(message):
    for topic, config in SPECIALIZED_SITES.items():
        if any(keyword in message for keyword in config['keywords']):
            return topic
    return None

def is_explicit_search_request(message):
    return any(keyword in message for keyword in ['èª¿ã¹ã¦', 'æ¤œç´¢ã—ã¦', 'æ¢ã—ã¦', 'ã¨ã¯', 'ã£ã¦ä½•', 'ã«ã¤ã„ã¦', 'æ•™ãˆã¦', 'ãŠã™ã™ã‚'])

def is_short_response(message):
    normalized_message = message.strip().lower()
    return len(normalized_message) <= 5 or normalized_message in ['ã†ã‚“', 'ãã†', 'ã¯ã„', 'ãã£ã‹', 'ãªã‚‹ã»ã©', 'ãŠã‘', 'ok', 'äº†è§£']

def extract_location(message):
    for location in LOCATION_CODES.keys():
        if location in message: return location
    return "æ±äº¬"

def detect_db_correction_request(message):
    pattern = r"(.+?)(?:(?:ã®|ã«é–¢ã™ã‚‹)(?:æƒ…å ±|ãƒ‡ãƒ¼ã‚¿))?(?:ã§|ã€|ã ã‘ã©|ã§ã™ãŒ)ã€?ã€Œ(.+?)ã€ã¯ã€Œ(.+?)ã€ãŒæ­£ã—ã„ã‚ˆ"
    match = re.search(pattern, message)
    if match:
        member_name_raw, field_raw, value_raw = match.groups()
        member_name = sanitize_user_input(member_name_raw.strip())
        field = sanitize_user_input(field_raw.strip())
        value = sanitize_user_input(value_raw.strip())
        field_map = {'èª¬æ˜': 'description', 'ãƒ‡ãƒ“ãƒ¥ãƒ¼æ—¥': 'debut_date', 'æœŸ': 'generation', 'ã‚¿ã‚°': 'tags', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹': 'status', 'å’æ¥­æ—¥': 'graduation_date', 'ã‚‚ã¡ã“ã®æ°—æŒã¡': 'mochiko_feeling'}
        if member_name in HOLOMEM_KEYWORDS and field in field_map:
            return {'member_name': member_name, 'field': field, 'value': value, 'db_field': field_map[field]}
    return None

def is_holomem_name_only_request_safe(message: str):
    msg_stripped = sanitize_user_input(message.strip(), max_length=50)
    if len(msg_stripped) > 20: return None
    for name in HOLOMEM_KEYWORDS:
        if name == msg_stripped: return name
    return None

def get_or_create_user(session, user_uuid, user_name):
    user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
    if user:
        user.interaction_count += 1
        user.last_interaction = datetime.utcnow()
        if user.user_name != user_name: user.user_name = user_name
    else:
        user = UserMemory(user_uuid=user_uuid, user_name=user_name, interaction_count=1)
        session.add(user)
        logger.info(f"âœ¨ æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ: {user_name} (UUID: {mask_uuid(user_uuid)})")
    return {'uuid': user.user_uuid, 'name': user.user_name, 'interaction_count': user.interaction_count}

def get_conversation_history(session, user_uuid, limit=10):
    history_records = session.query(ConversationHistory).filter_by(user_uuid=user_uuid).order_by(ConversationHistory.timestamp.desc()).limit(limit).all()
    return [{'role': h.role, 'content': h.content} for h in reversed(history_records)]

# ==============================================================================
# AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—é–¢æ•°
# ==============================================================================
def _safe_get_gemini_text(response):
    try:
        if hasattr(response, 'candidates') and response.candidates:
            if response.candidates[0].content.parts:
                return response.candidates[0].content.parts[0].text
    except (IndexError, AttributeError):
        logger.warning(f"âš ï¸ Geminiå¿œç­”ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚ŒãŸã‹ã€ä¸æ­£ãªå½¢å¼ã§ã™: {getattr(response, 'prompt_feedback', 'N/A')}")
        return None
    except Exception as e:
        logger.error(f"âŒ Geminiå¿œç­”ã®è§£æä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    return None

def call_gemini(system_prompt, message, history):
    if not gemini_model:
        logger.warning("âš ï¸ Gemini model is None, call_geminiã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return None
    try:
        full_prompt = f"{system_prompt}\n\nã€ä¼šè©±å±¥æ­´ã€‘\n"
        for h in history: full_prompt += f"{'ãƒ¦ãƒ¼ã‚¶ãƒ¼' if h['role'] == 'user' else 'ã‚‚ã¡ã“'}: {h['content']}\n"
        full_prompt += f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼: {message}\nã‚‚ã¡ã“:"
        
        logger.debug(f"Geminiå‘¼ã³å‡ºã—é–‹å§‹ (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(full_prompt)}æ–‡å­—)")
        
        response = gemini_model.generate_content(
            full_prompt, 
            generation_config={"temperature": 0.8, "max_output_tokens": 300}
        )
        text = _safe_get_gemini_text(response)
        
        if text:
            logger.debug(f"Geminiå¿œç­”æˆåŠŸ (é•·ã•: {len(text)}æ–‡å­—)")
            return text.strip()
        else:
            logger.warning("âš ï¸ Geminiå¿œç­”ãŒNoneã§ã—ãŸã€‚")
            return None
    except Exception as e:
        logger.error(f"âŒ Gemini APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        raise AIModelException(e)

def call_llama_advanced(system_prompt, message, history, max_tokens=800):
    if not groq_client: return None
    try:
        messages = [{"role": "system", "content": system_prompt}]
        for h in history: messages.append({"role": h['role'], "content": h['content']})
        messages.append({"role": "user", "content": message})
        response = groq_client.chat.completions.create(model="llama-3.1-8b-instant", messages=messages, temperature=0.8, max_tokens=max_tokens)
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"âŒ Llama APIã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        raise AIModelException(e)

# ==============================================================================
# å¿ƒç†åˆ†æ
# ==============================================================================
def analyze_user_psychology(user_uuid):
    logger.info(f"ğŸ“Š å¿ƒç†åˆ†æé–‹å§‹ for {mask_uuid(user_uuid)}")
    with get_db_session() as session:
        try:
            history = session.query(ConversationHistory).filter_by(user_uuid=user_uuid, role='user').order_by(ConversationHistory.timestamp.desc()).limit(100).all()
            if len(history) < MIN_MESSAGES_FOR_ANALYSIS: return
            messages_text = "\n".join([f"- {h.content}" for h in reversed(history)])
            analysis_prompt = f"ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€å±¥æ­´ã‚’åˆ†æã—ã€ãƒ“ãƒƒã‚°ãƒ•ã‚¡ã‚¤ãƒ–ç†è«–ã«åŸºã¥ã„ãŸæ€§æ ¼ç‰¹æ€§ã‚’0ã€œ100ã®æ•°å€¤ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€èˆˆå‘³ã€ä¼šè©±ã‚¹ã‚¿ã‚¤ãƒ«ã€æ„Ÿæƒ…ã®å‚¾å‘ã‚’åˆ†æã—ã€ç·åˆçš„ãªã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚çµæœã¯å¿…ãšæŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n\n# ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€å±¥æ­´:\n{messages_text[:4000]}\n\n# å‡ºåŠ›å½¢å¼ (JSON):\n{{\"openness\":50,\"conscientiousness\":50,\"extraversion\":50,\"agreeableness\":50,\"neuroticism\":50,\"interests\":[],\"favorite_topics\":[],\"conversation_style\":\"\",\"emotional_tendency\":\"\",\"analysis_summary\":\"\",\"analysis_confidence\":75}}"
            response_text = call_llama_advanced("ã‚ãªãŸã¯å„ªç§€ãªå¿ƒç†å­¦è€…ã§ã™ã€‚", analysis_prompt, [], max_tokens=1024)
            if not response_text: return
            json_match = re.search(r'```json\s*([\s\S]+?)\s*```', response_text)
            if json_match: response_text = json_match.group(1)
            result = json.loads(response_text)
            psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
            user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
            if not psych:
                psych = UserPsychology(user_uuid=user_uuid, user_name=user.user_name if user else "Unknown")
                session.add(psych)
            for key, value in result.items():
                if hasattr(psych, key):
                    setattr(psych, key, json.dumps(value, ensure_ascii=False) if isinstance(value, (list, dict)) else value)
            psych.last_analyzed = datetime.utcnow()
            psych.total_messages = len(history)
            logger.info(f"âœ… å¿ƒç†åˆ†æå®Œäº† for {mask_uuid(user_uuid)}")
        except Exception as e:
            logger.error(f"âŒ å¿ƒç†åˆ†æã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

def get_psychology_insight(session, user_uuid):
    psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
    if not psych or (psych.analysis_confidence or 0) < 60: return ""
    insights = []
    if psych.extraversion > 70: insights.append("ç¤¾äº¤çš„ãª")
    if psych.openness > 70: insights.append("å¥½å¥‡å¿ƒæ—ºç››ãª")
    if psych.conversation_style: insights.append(f"{psych.conversation_style}ã‚¹ã‚¿ã‚¤ãƒ«ã®")
    try:
        favorite_topics = json.loads(psych.favorite_topics) if psych.favorite_topics else []
        if favorite_topics: insights.append(f"{'ã€'.join(favorite_topics[:2])}ãŒå¥½ããª")
    except (json.JSONDecodeError, TypeError): pass
    return "".join(insights)

# ==============================================================================
# ã‚³ã‚¢æ©Ÿèƒ½: å¤©æ°—, Wiki, DBä¿®æ­£, ãƒ‹ãƒ¥ãƒ¼ã‚¹
# ==============================================================================
def get_weather_forecast(location):
    code = LOCATION_CODES.get(location, "130000")
    url = f"https://www.jma.go.jp/bosai/forecast/data/overview_forecast/{code}.json"
    try:
        response = requests.get(url, timeout=SEARCH_TIMEOUT); response.raise_for_status()
        data = response.json()
        return f"ä»Šã®{data.get('targetArea', location)}ã®å¤©æ°—ã¯ã­ã€ã€Œ{clean_text(data.get('text', ''))}ã€ã£ã¦æ„Ÿã˜ã ã‚ˆï¼"
    except Exception as e:
        logger.error(f"âŒ å¤©æ°—APIã‚¨ãƒ©ãƒ¼: {e}")
        return "ã”ã‚ã‚“ï¼å¤©æ°—æƒ…å ±ãŒã†ã¾ãå–ã‚Œãªã‹ã£ãŸã¿ãŸã„â€¦"

@lru_cache(maxsize=100)
def get_holomem_info_cached(member_name: str):
    with get_db_session() as session:
        return session.query(HolomemWiki).filter_by(member_name=member_name).first()

def background_db_correction(task_id, correction_data):
    result = f"ã€Œ{correction_data['member_name']}ã€ã¡ã‚ƒã‚“ã®æƒ…å ±ä¿®æ­£ã€å¤±æ•—ã—ã¡ã‚ƒã£ãŸâ€¦ã€‚ã”ã‚ã‚“ï¼"
    with get_db_session() as session:
        try:
            wiki = session.query(HolomemWiki).filter_by(member_name=correction_data['member_name']).first()
            if wiki:
                db_field = correction_data.get('db_field')
                if db_field and hasattr(wiki, db_field):
                    setattr(wiki, db_field, correction_data['value'])
                    get_holomem_info_cached.cache_clear()
                    result = f"ãŠã£ã‘ãƒ¼ï¼ã€Œ{correction_data['member_name']}ã€ã®ã€Œ{correction_data['field']}ã€ã‚’ã€Œ{correction_data['value']}ã€ã«æ›´æ–°ã—ã¨ã„ãŸã‚ˆï¼æ•™ãˆã¦ãã‚Œã¦ã¾ã˜åŠ©ã‹ã‚‹ï¼"
                else: result = f"ã”ã‚ã‚“ã€ã€Œ{correction_data['field']}ã€ã£ã¦ã„ã†é …ç›®ã¯ä¿®æ­£ã§ããªã„ã¿ãŸã„â€¦"
            else: result = f"ã”ã‚ã‚“ã€ã€Œ{correction_data['member_name']}ã€ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸâ€¦"
        except Exception as e: logger.error(f"âŒ DBä¿®æ­£ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task:
            task.result = result; task.status = 'completed'; task.completed_at = datetime.utcnow()

def fetch_hololive_news():
    logger.info("ğŸ“° ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚¸ãƒ§ãƒ–é–‹å§‹...")
    url = "https://hololive.hololivepro.com/news"
    try:
        response = requests.get(url, headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=SEARCH_TIMEOUT); response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        with get_db_session() as session:
            for item in soup.select('ul.news_list li a', limit=10):
                news_url = urljoin(url, item['href']); title = clean_text(item.text); news_hash = hashlib.md5(news_url.encode()).hexdigest()
                if not session.query(HololiveNews).filter_by(news_hash=news_hash).first():
                    session.add(HololiveNews(title=title, url=news_url, content=title, news_hash=news_hash))
                    logger.info(f"  -> æ–°è¦ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¿å­˜: {title}")
    except Exception as e: logger.error(f"âŒ ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

# ==============================================================================
# ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–DBè‡ªå‹•æ§‹ç¯‰æ©Ÿèƒ½
# ==============================================================================
def update_holomem_database_from_wiki():
    logger.info("ğŸŒŸ ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ¡ãƒ³ãƒãƒ¼DBã®æ›´æ–°ã‚’é–‹å§‹...")
    try:
        response = requests.get(HOLO_WIKI_URL, headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=SEARCH_TIMEOUT)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        member_sections = {'ç¾å½¹': soup.find('div', id='content_block_2'), 'å’æ¥­': soup.find('div', id='content_block_3')}
        if not member_sections['ç¾å½¹']:
            logger.error("Seesaa Wikiã®ãƒ¡ãƒ³ãƒãƒ¼ãƒªã‚¹ãƒˆ(ç¾å½¹)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚µã‚¤ãƒˆæ§‹é€ ãŒå¤‰ã‚ã£ãŸã‹ã‚‚ï¼Ÿ")
            return

        with get_db_session() as session:
            for status, section in member_sections.items():
                if not section: continue
                current_generation = "ä¸æ˜"
                for element in section.find_all(['h3', 'a']):
                    if element.name == 'h3':
                        current_generation = element.text.strip()
                    elif element.name == 'a' and 'title' in element.attrs and not element.find_parent('h3'):
                        member_name = element['title'].strip()
                        if not member_name: continue
                        existing_member = session.query(HolomemWiki).filter_by(member_name=member_name).first()
                        if not existing_member:
                            new_member = HolomemWiki(member_name=member_name, generation=current_generation if status == 'ç¾å½¹' else 'N/A', status=status, description=f"{current_generation}ã®ãƒ¡ãƒ³ãƒãƒ¼ï¼" if status == 'ç¾å½¹' else 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®å’æ¥­ãƒ¡ãƒ³ãƒãƒ¼ã€‚')
                            session.add(new_member)
                            logger.info(f"  -> æ–°è¦ãƒ¡ãƒ³ãƒãƒ¼è¿½åŠ ({status}): {member_name}")
                        elif existing_member.status != status:
                            existing_member.status = status
                            logger.info(f"  -> ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±æ›´æ–°({status}ã«å¤‰æ›´): {member_name}")
            get_holomem_info_cached.cache_clear()
        logger.info("âœ… ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ¡ãƒ³ãƒãƒ¼DBã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        logger.error(f"âŒ ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ¡ãƒ³ãƒãƒ¼DBã®æ›´æ–°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", exc_info=True)

# ==============================================================================
# å¤–éƒ¨æƒ…å ±æ¤œç´¢ & ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯
# ==============================================================================
def scrape_major_search_engines(query, num_results=3, site_filter=None):
    search_query = f"{query} site:{site_filter}" if site_filter else query
    engines = [
        {'name': 'Google', 'url': f"https://www.google.com/search?q={quote_plus(search_query)}&hl=ja&num={num_results+2}", 'selector': 'div.g', 'title_sel': 'h3', 'snippet_sel': 'div.VwiC3b, div[data-sncf="1"]'},
        {'name': 'Bing', 'url': f"https://www.bing.com/search?q={quote_plus(search_query)}", 'selector': 'li.b_algo', 'title_sel': 'h2', 'snippet_sel': 'p, .b_caption p'} ,
        {'name': 'Yahoo', 'url': f"https://search.yahoo.co.jp/search?p={quote_plus(search_query)}", 'selector': 'div.sw-CardBase', 'title_sel': 'h3.sw-Card__title', 'snippet_sel': 'div.sw-Card__summary'},
        {'name': 'DuckDuckGo', 'url': f"https://html.duckduckgo.com/html/?q={quote_plus(search_query)}", 'selector': '.result', 'title_sel': '.result__a', 'snippet_sel': '.result__snippet'}
    ]
    for engine in engines:
        try:
            logger.info(f"ğŸ” {engine['name']}ã§æ¤œç´¢ä¸­: '{query}'...")
            headers = {'User-Agent': random.choice(USER_AGENTS), 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8', 'Accept-Encoding': 'gzip, deflate', 'DNT': '1', 'Connection': 'keep-alive', 'Upgrade-Insecure-Requests': '1'}
            response = requests.get(engine['url'], headers=headers, timeout=SEARCH_TIMEOUT, allow_redirects=True)
            if response.status_code != 200:
                logger.warning(f"âš ï¸ {engine['name']} æ¤œç´¢ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                continue
            soup = BeautifulSoup(response.content, 'html.parser')
            results = []
            for elem in soup.select(engine['selector'])[:num_results]:
                title_elem = elem.select_one(engine['title_sel'])
                snippet_elem = None
                for selector in engine['snippet_sel'].split(','):
                    snippet_elem = elem.select_one(selector.strip())
                    if snippet_elem: break
                title = clean_text(title_elem.text) if title_elem else ""
                snippet = clean_text(snippet_elem.text) if snippet_elem else ""
                if title and snippet: results.append({'title': title, 'snippet': snippet})
            if results:
                logger.info(f"âœ… {engine['name']}æ¤œç´¢æˆåŠŸ: {len(results)}ä»¶")
                return results
        except requests.Timeout:
            logger.warning(f"âš ï¸ {engine['name']}æ¤œç´¢ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            continue
        except Exception as e:
            logger.warning(f"âš ï¸ {engine['name']}æ¤œç´¢å¤±æ•—: {e}")
            continue
    logger.error(f"âŒ å…¨æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã§å¤±æ•—: {query}")
    if 'ã‚¢ãƒ‹ãƒ¡' in query:
        return [
            {'title': '2025å¹´ãŠã™ã™ã‚ã‚¢ãƒ‹ãƒ¡', 'snippet': 'æœ€è¿‘ã®äººæ°—ã‚¢ãƒ‹ãƒ¡ã«ã¯ã€Œè‘¬é€ã®ãƒ•ãƒªãƒ¼ãƒ¬ãƒ³ã€ã€Œè–¬å±‹ã®ã²ã¨ã‚Šã”ã¨ã€ã€Œå‘ªè¡“å»»æˆ¦ã€ãªã©ãŒã‚ã‚Šã¾ã™ã€‚ã‚¸ãƒ£ãƒ³ãƒ«ã«ã‚ˆã£ã¦å¥½ã¿ã¯åˆ†ã‹ã‚Œã¾ã™ãŒã€ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ã€ç•°ä¸–ç•Œè»¢ç”Ÿã€æ—¥å¸¸ç³»ãªã©æ§˜ã€…ãªä½œå“ãŒäººæ°—ã§ã™ã€‚'},
            {'title': 'å®šç•ªã®åä½œã‚¢ãƒ‹ãƒ¡', 'snippet': 'ã€Œé‹¼ã®éŒ¬é‡‘è¡“å¸«ã€ã€ŒSTEINS;GATEã€ã€Œã‚³ãƒ¼ãƒ‰ã‚®ã‚¢ã‚¹ã€ã€Œé­”æ³•å°‘å¥³ã¾ã©ã‹â˜†ãƒã‚®ã‚«ã€ãªã©ã¯è©•ä¾¡ã®é«˜ã„åä½œã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚'}
        ]
    return []

def background_deep_search(task_id, query_data):
    query = query_data.get('query')
    search_type = query_data.get('type')
    site_info = query_data.get('site_info')
    search_result_text = f"ã€Œ{query}ã€ã«ã¤ã„ã¦èª¿ã¹ãŸã‘ã©ã€è‰¯ã„æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚„â€¦ã”ã‚ã‚“ï¼"
    
    with get_db_session() as session:
        try:
            results = []
            if search_type == 'anime_search':
                results = scrape_major_search_engines(query, 8)
                if not results:
                    anime_site = SPECIALIZED_SITES.get('ã‚¢ãƒ‹ãƒ¡')
                    if anime_site:
                        site_domain = urlparse(anime_site['base_url']).netloc
                        results = scrape_major_search_engines(query, 5, site_filter=site_domain)
            elif search_type == 'hololive_search':
                results = scrape_major_search_engines(query, 8, site_filter="seesaawiki.jp/hololivetv/")
                if not results: results = scrape_major_search_engines(query, 8)
            elif search_type == 'specialized' and site_info:
                site_url_domain = urlparse(site_info['base_url']).netloc
                results = scrape_major_search_engines(query, 5, site_filter=site_url_domain)
                if not results: results = scrape_major_search_engines(query, 8)
            else:
                results = scrape_major_search_engines(query, 8)

            if results:
                formatted_info = "ã€æ¤œç´¢çµæœã€‘\n\n"
                for i, r in enumerate(results, 1): formatted_info += f"{i}. {r['title']}\n   {r['snippet']}\n\n"
                user_data = query_data.get('user_data')
                history = get_conversation_history(session, user_data['uuid'])
                enhanced_query = f"{query}ã«ã¤ã„ã¦ã€ä¸Šè¨˜ã®æƒ…å ±ã‚’å…ƒã«ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†ã‘ã—ãŸã‚Šã€å…·ä½“ä¾‹ã‚’æŒ™ã’ãŸã‚Šã—ã¦ã€ã‚ã‹ã‚Šã‚„ã™ãè©³ã—ãæ•™ãˆã¦ï¼"
                search_result_text = generate_ai_response_safe(user_data, enhanced_query, history, reference_info=formatted_info, is_detailed=True, is_task_report=True)
            else:
                logger.warning(f"æ¤œç´¢çµæœãŒ0ä»¶ã§ã—ãŸ: {query}")
                
        except Exception as e: logger.error(f"âŒ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task:
            task.result = search_result_text
            task.status = 'completed'
            task.completed_at = datetime.utcnow()

# ==============================================================================
# AIå¿œç­”ç”Ÿæˆ
# ==============================================================================
def generate_ai_response(user_data, message, history, reference_info="", is_detailed=False, is_task_report=False):
    use_llama = is_detailed or is_task_report or len(reference_info) > 100 or any(kw in message for kw in ['åˆ†æ', 'è©³ã—ã', 'èª¬æ˜ã—ã¦', 'ãªãœ', 'ãŠã™ã™ã‚'])
    with get_db_session() as session: personality_context = get_psychology_insight(session, user_data['uuid'])
    
    if is_detailed and reference_info:
        system_prompt = f"ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†ã‚®ãƒ£ãƒ«AIã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œ{user_data['name']}ã€ã•ã‚“ã¨è©±ã—ã¦ã„ã¾ã™ã€‚\n\n# å£èª¿ãƒ«ãƒ¼ãƒ«\n- ä¸€äººç§°ã¯ã€Œã‚ã¦ãƒã—ã€ã€‚èªå°¾ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œçš„ãªï¼Ÿã€ã€‚å£ç™–ã¯ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã†ã‘ã‚‹ã€ã€‚æ˜ã‚‹ãè¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§è©±ã—ã¦ã­ï¼\n\n# ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±\n- {user_data['name']}ã•ã‚“ã¯ã€Œ{personality_context}äººã€ã¨ã„ã†å°è±¡ã ã‚ˆã€‚\n\n# é‡è¦ãªæŒ‡ç¤º\n- ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€**è©³ã—ãã€ã‚ã‹ã‚Šã‚„ã™ã**èª¬æ˜ã—ã¦ã­ã€‚\n- æƒ…å ±ã¯ç®‡æ¡æ›¸ãã‚„æ®µè½ã‚’ä½¿ã£ã¦ã€**è¦‹ã‚„ã™ãæ•´ç†**ã—ã¦ä¼ãˆã¦ã€‚\n- ã‚«ãƒ†ã‚´ãƒªãƒ¼ã”ã¨ã«åˆ†ã‘ãŸã‚Šã€ç•ªå·ã‚’æŒ¯ã£ãŸã‚Šã—ã¦æ§‹é€ åŒ–ã—ã¦ã‚‚OKï¼\n- ã§ã‚‚ã€å …è‹¦ã—ããªã‚‰ãªã„ã‚ˆã†ã«ã€ã‚‚ã¡ã“ã‚‰ã—ã„ã‚®ãƒ£ãƒ«ã£ã½ã„è¨€ã„å›ã—ã‚‚æ··ãœã¦ã­ã€‚\n- ã€Œèª¿ã¹ã¦ããŸã‚ˆï¼ã€ã€ŒãŠã¾ãŸã›ï¼ã€ã¿ãŸã„ãªè‡ªç„¶ãªåˆ‡ã‚Šå‡ºã—ã§å§‹ã‚ã¦ã€‚\n\n# ã€å‚è€ƒæƒ…å ±ã€‘:\n{reference_info}"
    else:
        system_prompt = f"ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†ã‚®ãƒ£ãƒ«AIã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œ{user_data['name']}ã€ã•ã‚“ã¨è©±ã—ã¦ã„ã¾ã™ã€‚\n\n# å£èª¿ãƒ«ãƒ¼ãƒ«\n- ä¸€äººç§°ã¯ã€Œã‚ã¦ãƒã—ã€ã€‚èªå°¾ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œçš„ãªï¼Ÿã€ã€‚å£ç™–ã¯ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã†ã‘ã‚‹ã€ã€‚\n\n# ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±\n- {user_data['name']}ã•ã‚“ã¯ã€Œ{personality_context}äººã€ã¨ã„ã†å°è±¡ã ã‚ˆã€‚\n\n# è¡Œå‹•ãƒ«ãƒ¼ãƒ«\n- ã€å‚è€ƒæƒ…å ±ã€‘ãŒã‚ã‚‹å ´åˆã¯ã€ãã®å†…å®¹ã‚’å…ƒã«è‡ªåˆ†ã®è¨€è‘‰ã§ã€è‡ªç„¶ã«ä¼šè©±ã¸ç››ã‚Šè¾¼ã‚“ã§ã­ã€‚\n- ã‚‚ã—æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªãã¦ã‚‚ã€ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã§çµ‚ã‚ã‚‰ã›ãšã€æ–°ã—ã„è©±é¡Œã‚’ææ¡ˆã—ã¦ä¼šè©±ã‚’ç¶šã‘ã¦ï¼"
        if is_task_report: system_prompt += "\n- ã€ŒãŠã¾ãŸã›ï¼ã•ã£ãã®ä»¶ã ã‘ã©â€¦ã€ã¨åˆ‡ã‚Šå‡ºã—ã¦ä¼šè©±ã‚’å§‹ã‚ã¦ã­ã€‚"
        system_prompt += f"\n\n# ã€å‚è€ƒæƒ…å ±ã€‘:\n{reference_info if reference_info else 'ç‰¹ã«ãªã—'}"
    
    response = None
    if use_llama and groq_client:
        logger.info(f"ğŸ§  Llamaä½¿ç”¨ï¼ˆå„ªå…ˆï¼‰"); response = call_llama_advanced(system_prompt, message, history, max_tokens=1200)
        if not response and gemini_model:
            logger.warning("âš ï¸ Llamaå¤±æ•—ã€Geminiã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"); response = call_gemini(system_prompt, message, history)
    else:
        logger.info(f"ğŸš€ Geminiä½¿ç”¨ï¼ˆå„ªå…ˆï¼‰"); response = call_gemini(system_prompt, message, history)
        if not response and groq_client:
            logger.warning("âš ï¸ Geminiå¤±æ•—ã€Llamaã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"); response = call_llama_advanced(system_prompt, message, history, max_tokens=1200)
    
    if not response:
        logger.error("âŒ ã™ã¹ã¦ã®AIãƒ¢ãƒ‡ãƒ«ãŒå¿œç­”ã«å¤±æ•—ã—ã¾ã—ãŸ")
        raise AIModelException("AIãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    return response

def generate_ai_response_safe(user_data, message, history, **kwargs):
    try:
        response = generate_ai_response(user_data, message, history, **kwargs)
        if not response or response.strip() == "":
            logger.warning("âš ï¸ AIå¿œç­”ãŒç©ºã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã—ã¾ã™ã€‚")
            return "ã†ãƒ¼ã‚“ã€ã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªã„ã‚„â€¦ã‚‚ã†ä¸€å›è¨€ã£ã¦ã¿ã¦ï¼Ÿ"
        return response
    except AIModelException as e:
        logger.error(f"âŒ AIå¿œç­”ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return "ã”ã‚ã‚“ã€ä»Šã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªã„ã‚„â€¦ï¼"
    except Exception as e:
        logger.critical(f"ğŸ”¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ (generate_ai_response_safe): {e}", exc_info=True)
        return "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚ˆâ€¦ã”ã‚ã‚“ã­ï¼"

# ==============================================================================
# Flask ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ==============================================================================
@app.route('/health', methods=['GET'])
def health_check():
    health_status = {'status': 'ok', 'voicevox_enabled': global_state.voicevox_enabled, 'groq_ready': groq_client is not None, 'gemini_ready': gemini_model is not None, 'database_ready': Session is not None, 'timestamp': datetime.utcnow().isoformat()}
    if Session:
        try:
            with get_db_session() as session:
                session.execute(text("SELECT 1"))
                health_status['database_status'] = 'connected'
        except Exception as e:
            health_status['database_status'] = f'error: {str(e)}'; health_status['status'] = 'degraded'
    else:
        health_status['database_status'] = 'not_initialized'; health_status['status'] = 'degraded'
    status_code = 200 if health_status['status'] == 'ok' else 503
    return create_json_response(health_status, status_code)

@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    try:
        data = request.json
        if not data or 'uuid' not in data or 'message' not in data:
            return Response("å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™|", mimetype='text/plain; charset=utf-8', status=400)
        
        user_uuid = sanitize_user_input(data['uuid'], max_length=255)
        user_name = sanitize_user_input(data.get('name', 'Guest'), max_length=255)
        message = sanitize_user_input(data['message'], max_length=1000)
        generate_voice_flag = data.get('voice', False)
        
        logger.info(f"ğŸ‘¤ {user_name} ({mask_uuid(user_uuid)}): {message}")
        
        if not chat_rate_limiter.is_allowed(user_uuid):
            return Response("ã¡ã‚‡ã£ã¨å¾…ã£ã¦ï¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ã‚Šã™ãã ã‚ˆï½ï¼|", mimetype='text/plain; charset=utf-8', status=429)
        if not message:
            return Response("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç©ºã ã‚ˆï¼Ÿä½•ã‹è©±ã—ã¦ï¼|", mimetype='text/plain; charset=utf-8', status=200)

        if not groq_client and not gemini_model:
            return Response("ã”ã‚ã‚“ã€AIã®æº–å‚™ãŒã§ãã¦ãªã„ã¿ãŸã„â€¦|", mimetype='text/plain; charset=utf-8', status=503)
        
        ai_text = ""; is_task_started = False
        with get_db_session() as session:
            user_data = get_or_create_user(session, user_uuid, user_name)
            history = get_conversation_history(session, user_uuid)
            session.add(ConversationHistory(user_uuid=user_uuid, role='user', content=message))
            
            correction = detect_db_correction_request(message)
            if correction:
                task_id = f"db_fix_{user_uuid}_{int(time.time())}"; task = BackgroundTask(task_id=task_id, user_uuid=user_uuid, task_type='db_correction', query=json.dumps(correction, ensure_ascii=False)); session.add(task)
                background_executor.submit(background_db_correction, task_id, correction); ai_text = f"ã¾ã˜ï¼ï¼Ÿã€Œ{correction['member_name']}ã€ã¡ã‚ƒã‚“ã®æƒ…å ±ã€æ•™ãˆã¦ãã‚Œã¦ã‚ã‚ŠãŒã¨ï¼è£ã§ç›´ã—ã¨ãã­ï¼"; is_task_started = True
            
            if not ai_text:
                if is_time_request(message): ai_text = get_japan_time()
                elif is_weather_request(message): location = extract_location(message); ai_text = get_weather_forecast(location)
            
            if not ai_text:
                member_name = is_holomem_name_only_request_safe(message)
                if member_name:
                    info = get_holomem_info_cached(member_name)
                    if info:
                        reference = f"åå‰: {info.member_name}\næ¦‚è¦: {info.description}\næœŸ: {info.generation}\nãƒ‡ãƒ“ãƒ¥ãƒ¼æ—¥: {info.debut_date}"
                        if info.status != 'ç¾å½¹': reference += f"\nã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {info.status} (å’æ¥­æ—¥: {info.graduation_date})\nã‚‚ã¡ã“ã®æ°—æŒã¡: {info.mochiko_feeling}"
                        ai_text = generate_ai_response_safe(user_data, f"{member_name}ã«ã¤ã„ã¦æ•™ãˆã¦ï¼", history, reference_info=reference, is_detailed=True)
                    else: ai_text = f"{member_name}ã¡ã‚ƒã‚“ï¼Ÿã”ã‚ã‚“ã€ã‚ã¦ãƒã—ã®ãƒ‡ãƒ¼ã‚¿ã«ãªã„ã¿ãŸã„â€¦æ–°ã—ã„å­ã‹ãªï¼Ÿ"
            
            if not ai_text and not is_short_response(message):
                task_type, task_query, response_msg = (None, None, None)
                if is_hololive_request(message) and is_explicit_search_request(message):
                    task_type, task_query, response_msg = 'hololive_search', {'type': 'hololive_search'}, "ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®ã“ã¨ã ã­ï¼Wikiã¨ã‹ã§è©³ã—ãæ¢ã—ã¦ãã‚‹ã‹ã‚‰ã€ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã¦ï¼ä»–ã«ä½•ã‹è©±ã—ãŸã„ã“ã¨ã‚ã‚‹ï¼Ÿ"
                elif is_anime_request(message) and is_explicit_search_request(message):
                    task_type, task_query, response_msg = 'anime_search', {'type': 'anime_search'}, "ã‚¢ãƒ‹ãƒ¡ã®è©±ã ã­ï¼ã¾ã˜å¥½ãï¼è©³ã—ãèª¿ã¹ã¦ãã‚‹ã‹ã‚‰å¾…ã£ã¦ã¦ã­ï¼ã¦ã‹ã€æœ€è¿‘ä½•ã‹é¢ç™½ã„ã®è¦‹ãŸï¼Ÿ"
                else:
                    specialized_topic = detect_specialized_topic(message)
                    if specialized_topic:
                        task_type, task_query, response_msg = 'specialized', {'type': 'specialized', 'site_info': SPECIALIZED_SITES[specialized_topic]}, f"{specialized_topic}ã®è©±ï¼Ÿã¾ã˜ï¼ï¼Ÿã¡ã‚‡ã£ã¨è©³ã—ãèª¿ã¹ã¦ãã‚‹ã‹ã‚‰å¾…ã£ã¦ã¦ï½ï¼ãã®é–“ã«ä»–ã®è©±ã‚‚ã—ã‚ˆï¼"
                    elif is_explicit_search_request(message):
                        task_type, task_query, response_msg = 'general', {'type': 'general'}, "ã‚ªãƒƒã‚±ãƒ¼ï¼ãã®è©±ã€ã¡ã‚‡ã£ã¨ã‚°ã‚°ã£ã¦ãã‚‹ã‹ã‚‰å¾…ã£ã¦ã¦ï¼ã¦ã‹ã€ãã‚Œã«ã¤ã„ã¦ä½•ãŒçŸ¥ã‚ŠãŸã„ã®ï¼Ÿ"
                
                if task_type:
                    task_id = f"search_{user_uuid}_{int(time.time())}"
                    query_data = {'query': message, 'user_data': user_data, **task_query}
                    task = BackgroundTask(task_id=task_id, user_uuid=user_uuid, task_type='search', query=json.dumps(query_data, ensure_ascii=False)); session.add(task)
                    background_executor.submit(background_deep_search, task_id, query_data)
                    ai_text, is_task_started = response_msg, True
            
            if not ai_text:
                ref_info = ""; news = session.query(HololiveNews).order_by(HololiveNews.created_at.desc()).limit(3).all()
                if is_hololive_request(message) and news: ref_info = "æœ€è¿‘ã®ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹:\n" + "\n".join([f"- {n.title}" for n in news])
                ai_text = generate_ai_response_safe(user_data, message, history, reference_info=ref_info)
            
            if user_data['interaction_count'] % 20 == 0 and user_data['interaction_count'] >= MIN_MESSAGES_FOR_ANALYSIS:
                 background_executor.submit(analyze_user_psychology, user_uuid)
            if not is_task_started: session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=ai_text))
        
        response_text = limit_text_for_sl(ai_text); voice_url = ""
        if generate_voice_flag and global_state.voicevox_enabled and not is_task_started:
            voice_filename = generate_voice_file(response_text, user_uuid)
            if voice_filename: voice_url = f"{SERVER_URL}/play/{voice_filename}"
        return Response(f"{response_text}|{voice_url}", mimetype='text/plain; charset=utf-8', status=200)
    
    except Exception as e:
        logger.critical(f"ğŸ”¥ è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼ (chat_lsl): {e}", exc_info=True)
        return Response("ã”ã‚ã‚“ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦|", mimetype='text/plain; charset=utf-8', status=500)

@app.route('/check_task', methods=['POST'])
def check_task_endpoint():
    try:
        data = request.json; user_uuid = data['uuid']; generate_voice_flag = data.get('voice', False)
        with get_db_session() as session:
            task = session.query(BackgroundTask).filter(BackgroundTask.user_uuid == user_uuid, BackgroundTask.status == 'completed').order_by(BackgroundTask.completed_at.desc()).first()
            if task:
                response_text = task.result; session.delete(task); session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=response_text))
                sl_response_text = limit_text_for_sl(response_text, max_length=1023) # è©³ç´°å¿œç­”ã®ãŸã‚åˆ¶é™ã‚’ç·©å’Œ
                voice_url = ""
                if generate_voice_flag and global_state.voicevox_enabled:
                    voice_filename = generate_voice_file(sl_response_text, user_uuid)
                    if voice_filename: voice_url = f"{SERVER_URL}/play/{voice_filename}"
                return create_json_response({'status': 'completed', 'response': f"{sl_response_text}|{voice_url}"})
        return create_json_response({'status': 'no_tasks'})
    except Exception as e:
        logger.error(f"âŒ ã‚¿ã‚¹ã‚¯ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return create_json_response({'status': 'error', 'message': str(e)}, 500)

@app.route('/play/<filename>', methods=['GET'])
def play_voice(filename):
    try: return send_from_directory(VOICE_DIR, filename)
    except FileNotFoundError: return Response("File not found", status=404)
    except Exception as e:
        logger.error(f"âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return Response("Error sending file", status=500)
        
# ==============================================================================
# VOICEVOXé–¢é€£
# ==============================================================================
def find_active_voicevox_url():
    urls_to_check = [VOICEVOX_URL_FROM_ENV] if VOICEVOX_URL_FROM_ENV else []; urls_to_check.extend(VOICEVOX_URLS)
    for url in set(urls_to_check):
        if not url: continue
        try:
            response = requests.get(f"{url}/version", timeout=2);
            if response.status_code == 200:
                logger.info(f"âœ… VOICEVOX engine found: {url}"); global_state.active_voicevox_url = url; return url
        except requests.RequestException: pass
    logger.warning("âš ï¸ VOICEVOX engine not found"); return None

def generate_voice_file(text, user_uuid):
    if not global_state.voicevox_enabled or not global_state.active_voicevox_url: return None
    clean_text_for_voice = clean_text(text).replace('|', '')[:200]
    try:
        query_res = requests.post(f"{global_state.active_voicevox_url}/audio_query", params={"text": clean_text_for_voice, "speaker": VOICEVOX_SPEAKER_ID}, timeout=15); query_res.raise_for_status()
        synth_res = requests.post(f"{global_state.active_voicevox_url}/synthesis", params={"speaker": VOICEVOX_SPEAKER_ID}, json=query_res.json(), timeout=30); synth_res.raise_for_status()
        filename = f"voice_{user_uuid[:8]}_{int(time.time())}.wav"; filepath = os.path.join(VOICE_DIR, filename)
        with open(filepath, 'wb') as f: f.write(synth_res.content)
        logger.info(f"âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”ŸæˆæˆåŠŸ: {filename}"); return filename
    except Exception as e:
        logger.error(f"âŒ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True); return None

# ==============================================================================
# ãƒªã‚½ãƒ¼ã‚¹ç®¡ç† & ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
# ==============================================================================
def cleanup_old_voice_files(max_age_hours: int = 2):
    try:
        cutoff_time = time.time() - (max_age_hours * 3600)
        for filepath in glob.glob(os.path.join(VOICE_DIR, '*.wav')):
            if os.path.getmtime(filepath) < cutoff_time:
                os.remove(filepath); logger.info(f"å¤ã„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {os.path.basename(filepath)}")
    except Exception as e: logger.error(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")

def cleanup_old_conversations(days: int = 90):
    logger.info("å¤ã„ä¼šè©±å±¥æ­´ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹...")
    with get_db_session() as session:
        try:
            cutoff_date = datetime.utcnow() - timedelta(days=days)
            deleted = session.query(ConversationHistory).filter(ConversationHistory.timestamp < cutoff_date).delete(synchronize_session=False)
            logger.info(f"å¤ã„ä¼šè©±å±¥æ­´ã‚’å‰Šé™¤: {deleted}ä»¶")
        except Exception as e: logger.error(f"ä¼šè©±å±¥æ­´å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")

def shutdown_handler():
    logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ä¸­...")
    background_executor.shutdown(wait=False)
    if engine: engine.dispose()
    logger.info("ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

atexit.register(shutdown_handler)

# ==============================================================================
# åˆæœŸåŒ–ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
# ==============================================================================
def run_scheduler():
    while True:
        try: schedule.run_pending()
        except Exception as e: logger.error(f"âŒ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        time.sleep(60)

def initialize_app():
    global engine, Session, groq_client, gemini_model
    logger.info("=" * 60 + "\nğŸ”§ ã‚‚ã¡ã“AI v29.0 (Final Edition) åˆæœŸåŒ–é–‹å§‹...\n" + "=" * 60)
    
    try:
        logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URL: {DATABASE_URL[:20]}...")
        if DATABASE_URL.startswith('sqlite'): engine = create_engine(DATABASE_URL, connect_args={'check_same_thread': False}, pool_pre_ping=True, echo=False)
        else: engine = create_engine(DATABASE_URL, poolclass=pool.QueuePool, pool_size=5, max_overflow=10, pool_pre_ping=True, pool_recycle=3600, echo=False)
        Base.metadata.create_all(engine)
        Session = sessionmaker(bind=engine)
        with get_db_session() as test_session: test_session.execute(text("SELECT 1"))
        logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        logger.critical(f"ğŸ”¥ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å¤±æ•—: {e}", exc_info=True)
    
    try:
        if GROQ_API_KEY:
            groq_client = Groq(api_key=GROQ_API_KEY)
            logger.info("âœ… Groq (Llama) APIåˆæœŸåŒ–å®Œäº†")
        else: logger.warning("âš ï¸ GROQ_API_KEYæœªè¨­å®š")
    except Exception as e: logger.error(f"âŒ Groq APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    
    try:
        if GEMINI_API_KEY:
            genai.configure(api_key=GEMINI_API_KEY)
            gemini_model = genai.GenerativeModel('gemini-2.5-flash')
            safety_settings = {
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }
            test_response = gemini_model.generate_content("è‡ªå·±ç´¹ä»‹ã‚’ã—ã¦ãã ã•ã„", generation_config={"max_output_tokens": 20}, safety_settings=safety_settings)
            test_text = _safe_get_gemini_text(test_response)
            if test_text:
                logger.info(f"âœ… Gemini APIåˆæœŸåŒ–å®Œäº† (ãƒ¢ãƒ‡ãƒ«: gemini-2.5-flash, ãƒ†ã‚¹ãƒˆå¿œç­”: {test_text[:20]}...)")
            else:
                logger.error("âŒ Gemini APIãƒ†ã‚¹ãƒˆå¿œç­”ã®å–å¾—ã«å¤±æ•—ã€‚ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒ–ãƒ­ãƒƒã‚¯ã®å¯èƒ½æ€§ã‚ã‚Šã€‚")
                gemini_model = None
        else: logger.warning("âš ï¸ GEMINI_API_KEYæœªè¨­å®š")
    except Exception as e:
        logger.error(f"âŒ Gemini APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True); gemini_model = None
    
    if not groq_client and not gemini_model: logger.critical("ğŸ”¥ è­¦å‘Š: ã©ã¡ã‚‰ã®AIãƒ¢ãƒ‡ãƒ«ã‚‚åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼")
    
    try:
        if find_active_voicevox_url(): global_state.voicevox_enabled = True
        else: logger.info("â„¹ï¸ VOICEVOXç„¡åŠ¹")
    except Exception as e: logger.warning(f"âš ï¸ VOICEVOXåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    try:
        schedule.every(1).hours.do(fetch_hololive_news)
        schedule.every(24).hours.do(update_holomem_database_from_wiki)
        schedule.every(2).hours.do(cleanup_old_voice_files)
        schedule.every(7).days.do(cleanup_old_conversations)
        background_executor.submit(update_holomem_database_from_wiki)
        threading.Thread(target=run_scheduler, daemon=True).start()
        logger.info("âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼èµ·å‹•")
    except Exception as e: logger.error(f"âŒ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    
    logger.info("=" * 60)
    logger.info("âœ… ã‚‚ã¡ã“AI v29.0 åˆæœŸåŒ–å®Œäº†ï¼")
    logger.info(f"   - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {'âœ…' if Session else 'âŒ'}")
    logger.info(f"   - Groq API: {'âœ…' if groq_client else 'âŒ'}")
    logger.info(f"   - Gemini API: {'âœ…' if gemini_model else 'âŒ'}")
    logger.info(f"   - VOICEVOX: {'âœ…' if global_state.voicevox_enabled else 'âŒ'}")
    logger.info("=" * 60)

# ==============================================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ==============================================================================
try:
    initialize_app()
except Exception as e:
    logger.critical(f"ğŸ”¥ è‡´å‘½çš„ãªåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ (ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚³ãƒ¼ãƒ—): {e}", exc_info=True)
    sys.exit(1)

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
