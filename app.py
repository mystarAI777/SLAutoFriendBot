#
# Mochiko AI - Version 3.1 (æ¤œç´¢æ©Ÿèƒ½å®Œå…¨å®Ÿè£… + æ–‡å­—åŒ–ã‘å¯¾ç­–)
#

import sys
import os
import requests
import logging
import time
import threading
import json
import re
import random
import uuid
import hashlib
from datetime import datetime, timedelta, timezone
import unicodedata

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Text, text
from sqlalchemy.orm import declarative_base, sessionmaker
from urllib.parse import quote_plus, urljoin
from bs4 import BeautifulSoup
from groq import Groq
import google.generativeai as genai
from concurrent.futures import ThreadPoolExecutor

# --- åŸºæœ¬è¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Flask ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ– ---
app = Flask(__name__)
CORS(app)
app.config['JSON_AS_ASCII'] = False
app.config['JSONIFY_MIMETYPE'] = 'application/json; charset=utf-8'

# --- å®šæ•° ---
VOICE_DIR = '/tmp/voices'
SERVER_URL = "https://slautofriendbot.onrender.com"
HOLOMEM_KEYWORDS = [
    'ã¨ãã®ãã‚‰', 'ãƒ­ãƒœå­ã•ã‚“', 'ã•ãã‚‰ã¿ã“', 'æ˜Ÿè¡—ã™ã„ã›ã„', 'AZKi', 'å¤œç©ºãƒ¡ãƒ«',
    'ã‚¢ã‚­ãƒ»ãƒ­ãƒ¼ã‚¼ãƒ³ã‚¿ãƒ¼ãƒ«', 'èµ¤äº•ã¯ã‚ã¨', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å¤è‰²ã¾ã¤ã‚Š', 'æ¹Šã‚ãã‚',
    'ç´«å’²ã‚·ã‚ªãƒ³', 'ç™¾é¬¼ã‚ã‚„ã‚', 'ç™’æœˆã¡ã‚‡ã“', 'å¤§ç©ºã‚¹ãƒãƒ«', 'å¤§ç¥ãƒŸã‚ª', 'çŒ«åˆãŠã‹ã‚†',
    'æˆŒç¥ã“ã‚ã­', 'å…ç”°ãºã“ã‚‰', 'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢', 'ç™½éŠ€ãƒã‚¨ãƒ«', 'å®é˜ãƒãƒªãƒ³', 'å¤©éŸ³ã‹ãªãŸ',
    'è§’å·»ã‚ãŸã‚', 'å¸¸é—‡ãƒˆãƒ¯', 'å§«æ£®ãƒ«ãƒ¼ãƒŠ', 'é›ªèŠ±ãƒ©ãƒŸã‚£', 'æ¡ƒéˆ´ã­ã­', 'ç…ç™½ã¼ãŸã‚“',
    'å°¾ä¸¸ãƒãƒ«ã‚«', 'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹', 'é·¹å¶ºãƒ«ã‚¤', 'åšè¡£ã“ã‚ˆã‚Š', 'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±',
    'é¢¨çœŸã„ã‚ã¯', 'æ£®ã‚«ãƒªã‚ªãƒš', 'å°é³¥éŠã‚­ã‚¢ãƒ©', 'ä¸€ä¼Šé‚£å°“æ –', 'ãŒã†ã‚‹ãƒ»ãã‚‰',
    'ãƒ¯ãƒˆã‚½ãƒ³ãƒ»ã‚¢ãƒ¡ãƒªã‚¢', 'IRyS', 'ã‚»ãƒ¬ã‚¹ãƒ»ãƒ•ã‚¡ã‚¦ãƒŠ', 'ã‚ªãƒ¼ãƒ­ãƒ»ã‚¯ãƒ­ãƒ‹ãƒ¼', 'ä¸ƒè©©ãƒ ãƒ¡ã‚¤',
    'ãƒã‚³ã‚¹ãƒ»ãƒ™ãƒ¼ãƒ«ã‚º', 'ã‚·ã‚ªãƒªãƒ»ãƒãƒ´ã‚§ãƒ©', 'å¤çŸ³ãƒ“ã‚¸ãƒ¥ãƒ¼', 'ãƒãƒªãƒƒã‚µãƒ»ãƒ¬ã‚¤ãƒ´ãƒ³ã‚¯ãƒ­ãƒ•ãƒˆ',
    'ãƒ•ãƒ¯ãƒ¯ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ãƒ¢ã‚³ã‚³ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ã‚¢ãƒ¦ãƒ³ãƒ€ãƒ»ãƒªã‚¹', 'ãƒ ãƒ¼ãƒŠãƒ»ãƒ›ã‚·ãƒãƒ´ã‚¡',
    'ã‚¢ã‚¤ãƒ©ãƒ‹ãƒ»ã‚¤ã‚ªãƒ•ã‚£ãƒ•ãƒ†ã‚£ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¤ã‚¸ãƒ¼ãƒ»ã‚ªãƒªãƒ¼', 'ã‚¢ãƒ¼ãƒ‹ãƒ£ãƒ»ãƒ¡ãƒ«ãƒ•ã‚£ãƒƒã‚µ',
    'ãƒ‘ãƒ´ã‚©ãƒªã‚¢ãƒ»ãƒ¬ã‚¤ãƒ', 'ç«å¨é’', 'éŸ³ä¹ƒç€¬å¥', 'ä¸€æ¡è‰ã€…è¯', 'å„’çƒé¢¨äº­ã‚‰ã§ã‚“',
    'è½Ÿã¯ã˜ã‚', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'ãƒ›ãƒ­ãƒ¡ãƒ³', 'hololive', 'YAGOO', 'æ½¤ç¾½ã‚‹ã—ã‚', 'æ¡ç”Ÿã‚³ã‚³', 'é­”ä¹ƒã‚¢ãƒ­ã‚¨', 'ä¹åä¹ä½å‘½'
]
SPECIALIZED_SITES = {
    'Blender': {'base_url': 'https://docs.blender.org/manual/ja/latest/', 'keywords': ['Blender', 'ãƒ–ãƒ¬ãƒ³ãƒ€ãƒ¼']},
    'CGãƒ‹ãƒ¥ãƒ¼ã‚¹': {'base_url': 'https://modelinghappy.com/', 'keywords': ['CGãƒ‹ãƒ¥ãƒ¼ã‚¹', '3DCG', 'CG']},
    'è„³ç§‘å­¦ãƒ»å¿ƒç†å­¦': {'base_url': 'https://nazology.kusuguru.co.jp/', 'keywords': ['è„³ç§‘å­¦', 'å¿ƒç†å­¦']},
    'ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•': {'base_url': 'https://community.secondlife.com/news/', 'keywords': ['ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•', 'SL']},
    'ã‚¢ãƒ‹ãƒ¡': {'base_url': 'https://animedb.jp/', 'keywords': ['ã‚¢ãƒ‹ãƒ¡', 'anime']}
}

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° & Executor ---
background_executor = ThreadPoolExecutor(max_workers=5)
groq_client = None
gemini_model = None
Base = declarative_base()

# --- ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•° èª­ã¿è¾¼ã¿ ---
def get_secret(name):
    secret_file_path = f"/etc/secrets/{name}"
    if os.path.exists(secret_file_path):
        with open(secret_file_path, 'r', encoding='utf-8') as f:
            return f.read().strip()
    return os.environ.get(name)

DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./test.db'
GROQ_API_KEY = get_secret('GROQ_API_KEY')
GEMINI_API_KEY = get_secret('GEMINI_API_KEY')

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« ---
class UserMemory(Base):
    __tablename__ = 'user_memories'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)

class ConversationHistory(Base):
    __tablename__ = 'conversation_history'
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_uuid = Column(String(255), nullable=False, index=True)
    role = Column(String(10), nullable=False)
    content = Column(Text, nullable=False)
    timestamp = Column(DateTime, default=datetime.utcnow)

class BackgroundTask(Base):
    __tablename__ = 'background_tasks'
    id = Column(Integer, primary_key=True)
    task_id = Column(String(255), unique=True, nullable=False)
    user_uuid = Column(String(255), nullable=False, index=True)
    query = Column(Text, nullable=False)
    result = Column(Text)
    status = Column(String(20), default='pending')
    created_at = Column(DateTime, default=datetime.utcnow)
    completed_at = Column(DateTime)

class UserPsychology(Base):
    __tablename__ = 'user_psychology'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    conversation_style = Column(String(100))
    emotional_tendency = Column(String(100))
    favorite_topics = Column(Text)
    confidence = Column(Integer, default=0)

# --- AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– ---
def initialize_gemini_client():
    global gemini_model
    try:
        if GEMINI_API_KEY and len(GEMINI_API_KEY) > 20:
            genai.configure(api_key=GEMINI_API_KEY)
            gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')
            logger.info("âœ… Gemini 2.0 Flash Exp client initialized.")
        else:
            logger.warning("âš ï¸ GEMINI_API_KEY not set or invalid. Gemini disabled.")
    except Exception as e:
        logger.error(f"âŒ Gemini client initialization failed: {e}")

def initialize_groq_client():
    global groq_client
    try:
        if GROQ_API_KEY and len(GROQ_API_KEY) > 20:
            groq_client = Groq(api_key=GROQ_API_KEY)
            logger.info("âœ… Llama 3.3 70B (Groq) client initialized.")
        else:
            logger.warning("âš ï¸ GROQ_API_KEY not set or invalid. Llama disabled.")
    except Exception as e:
        logger.error(f"âŒ Groq client initialization failed: {e}")

# --- AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã— ---
def call_gemini(prompt, history=None, system_context=""):
    if not gemini_model:
        return None
    try:
        full_prompt = f"{system_context}\n\n[PAST CONVERSATION]\n{history or ''}\n\n[CURRENT PROMPT]\n{prompt}"
        response = gemini_model.generate_content(full_prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"âŒ Gemini API error: {e}")
        return None

def call_llama_advanced(prompt, history=None, system_prompt=None):
    if not groq_client:
        return None
    try:
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        if history:
            messages.extend([
                {"role": "user" if msg.role == "user" else "assistant", "content": msg.content}
                for msg in history[-5:]
            ])
        messages.append({"role": "user", "content": prompt})
        
        completion = groq_client.chat.completions.create(
            messages=messages,
            model="llama-3.3-70b-versatile",
            temperature=0.7,
            max_tokens=800
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"âŒ Llama API error: {e}")
        return None

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
def clean_text(text):
    if not text:
        return ""
    return re.sub(r'\s+', ' ', text).strip()

def is_short_response(message):
    return len(message.strip()) <= 5

def is_explicit_search_request(message):
    return any(keyword in message for keyword in ['èª¿ã¹ã¦', 'æ¤œç´¢ã—ã¦'])

def detect_specialized_topic(message):
    for topic, config in SPECIALIZED_SITES.items():
        if any(keyword.lower() in message.lower() for keyword in config['keywords']):
            return topic
    return None

def should_search(message):
    if is_short_response(message):
        return False
    if is_explicit_search_request(message):
        return True
    if detect_specialized_topic(message) or is_hololive_request(message):
        return True
    search_patterns = [r'ã¨ã¯', r'ã«ã¤ã„ã¦', r'æ•™ãˆã¦', r'èª°', r'ä½•', r'ãªãœ', r'è©³ã—ã']
    return any(re.search(pattern, message) for pattern in search_patterns)

def is_hololive_request(message):
    return any(keyword in message for keyword in HOLOMEM_KEYWORDS)

def get_user_psychology(user_uuid):
    session = Session()
    try:
        psychology = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
        if not psychology:
            return None
        return {
            'conversation_style': psychology.conversation_style,
            'emotional_tendency': psychology.emotional_tendency,
            'favorite_topics': json.loads(psychology.favorite_topics or '[]'),
            'confidence': psychology.confidence
        }
    finally:
        session.close()

# --- ğŸ” æ¤œç´¢æ©Ÿèƒ½ã®å®Œå…¨å®Ÿè£… ---
def scrape_google_search(query, max_results=5):
    """Googleæ¤œç´¢ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    results = []
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        url = f"https://www.google.com/search?q={quote_plus(query)}&hl=ja"
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            for g in soup.find_all('div', class_='g')[:max_results]:
                title_elem = g.find('h3')
                snippet_elem = g.find('div', class_=['VwiC3b', 'yXK7lf'])
                
                if title_elem and snippet_elem:
                    results.append({
                        'title': clean_text(title_elem.get_text()),
                        'snippet': clean_text(snippet_elem.get_text())
                    })
        
        logger.info(f"ğŸ” Google search found {len(results)} results for: {query}")
    except Exception as e:
        logger.error(f"âŒ Google search error: {e}")
    
    return results

def scrape_specialized_site(topic, query):
    """å°‚é–€ã‚µã‚¤ãƒˆã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    config = SPECIALIZED_SITES.get(topic)
    if not config:
        return []
    
    results = []
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(config['base_url'], headers=headers, timeout=10)
        response.encoding = 'utf-8'
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # ã‚µã‚¤ãƒˆã”ã¨ã®æ§‹é€ ã«å¿œã˜ã¦ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            articles = soup.find_all(['article', 'div'], class_=re.compile(r'post|article|entry'))[:3]
            
            for article in articles:
                title_elem = article.find(['h1', 'h2', 'h3', 'a'])
                text_elem = article.find(['p', 'div'], class_=re.compile(r'content|excerpt|summary'))
                
                if title_elem:
                    results.append({
                        'title': clean_text(title_elem.get_text()),
                        'snippet': clean_text(text_elem.get_text()) if text_elem else ''
                    })
        
        logger.info(f"ğŸ¯ Specialized site ({topic}) found {len(results)} results")
    except Exception as e:
        logger.error(f"âŒ Specialized site scraping error: {e}")
    
    return results

def perform_web_search(query, specialized_topic=None):
    """çµ±åˆæ¤œç´¢å®Ÿè¡Œ"""
    all_results = []
    
    # å°‚é–€ã‚µã‚¤ãƒˆå„ªå…ˆ
    if specialized_topic:
        all_results.extend(scrape_specialized_site(specialized_topic, query))
    
    # Googleæ¤œç´¢ï¼ˆå°‚é–€ã‚µã‚¤ãƒˆã§çµæœãŒå°‘ãªã„å ´åˆã¯è¿½åŠ ï¼‰
    if len(all_results) < 3:
        all_results.extend(scrape_google_search(query, max_results=5))
    
    return all_results[:5]  # æœ€å¤§5ä»¶

# --- ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ ---
def generate_ai_response(user_data, message, history, reference_info=""):
    use_llama = len(reference_info) > 100 or any(keyword in message for keyword in ['åˆ†æ', 'è©³ã—ã', 'èª¬æ˜'])
    
    psychology = get_user_psychology(user_data['uuid'])
    system_prompt_parts = [
        f"ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†ã‚®ãƒ£ãƒ«AIã§ã™ã€‚{user_data['name']}ã•ã‚“ã¨è©±ã—ã¦ã„ã¾ã™ã€‚",
        "ä¸€äººç§°ã¯ã€Œã‚ã¦ãƒã—ã€ã€èªå°¾ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œçš„ãªï¼Ÿã€ã€å£ç™–ã¯ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã†ã‘ã‚‹ã€ã€‚"
    ]
    if psychology and psychology.get('confidence', 0) > 50:
        system_prompt_parts.append(f"ç›¸æ‰‹ã¯{psychology['conversation_style']}ãªä¼šè©±ã‚’å¥½ã¿ã¾ã™ã€‚")
    if reference_info:
        system_prompt_parts.append(f"\nã€å‚è€ƒæƒ…å ±ã€‘\n{reference_info}")
    
    system_prompt = "\n".join(system_prompt_parts)

    response = None
    if use_llama:
        logger.info("ğŸ§  Using Llama 3.3 70B for detailed response.")
        response = call_llama_advanced(message, history, system_prompt)
    
    if not response:
        logger.info("ğŸš€ Using Gemini 2.0 Flash for fast response.")
        history_text = "\n".join([f"{h.role}: {h.content}" for h in history])
        response = call_gemini(message, history_text, system_prompt)

    return response or "ã”ã‚ã‚“ã€ã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªã„ã‚„â€¦ï¼"

def background_deep_search(task_id, query, history):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢ã®å®Ÿè¡Œï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    session = Session()
    try:
        # â‘  ä¼šè©±å±¥æ­´ã‚’ä½¿ã£ã¦æ–‡è„ˆç†è§£
        contextual_query = query
        if history and any(kw in query for kw in ['ãã‚Œ', 'ã‚ã‚Œ', 'ãã®ä¸­ã§', 'ã‚‚ã£ã¨è©³ã—ã', 'è©³ã—ã']):
            logger.info("ğŸ§  Generating contextual search query from history...")
            history_text = "\n".join([
                f"{'ãƒ¦ãƒ¼ã‚¶ãƒ¼' if h.role=='user' else 'ã‚‚ã¡ã“'}: {h.content}"
                for h in history[-5:]
            ])
            prompt = f'''ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã‚’å‚è€ƒã«ã€æœ€å¾Œã®è³ªå•ã‚’è‡ªå·±å®Œçµã—ãŸGoogleæ¤œç´¢ã‚¯ã‚¨ãƒªã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚
æ¤œç´¢ã‚¯ã‚¨ãƒªã ã‘ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚ä½™è¨ˆãªæ–‡ç« ã¯ä¸è¦ã§ã™ã€‚

[ä¼šè©±å±¥æ­´]
{history_text}

[æœ€å¾Œã®è³ªå•]
"{query}"

[å¤‰æ›å¾Œã®æ¤œç´¢ã‚¯ã‚¨ãƒª]:'''
            
            generated_query = call_gemini(prompt)
            if generated_query:
                contextual_query = clean_text(generated_query).replace('"', '').replace('ã€Œ', '').replace('ã€', '')
                logger.info(f"âœ… Contextual query generated: '{contextual_query}'")

        # â‘¡ å°‚é–€ãƒˆãƒ”ãƒƒã‚¯æ¤œå‡º
        specialized_topic = detect_specialized_topic(contextual_query)
        if specialized_topic:
            logger.info(f"ğŸ¯ Detected specialized topic: {specialized_topic}")

        # â‘¢ Webæ¤œç´¢å®Ÿè¡Œ
        search_results = perform_web_search(contextual_query, specialized_topic)

        # â‘£ æ¤œç´¢çµæœã®å‡¦ç†
        if not search_results:
            search_result = f"ã€Œ{contextual_query}ã€ã«ã¤ã„ã¦èª¿ã¹ãŸã‘ã©ã€æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚ˆâ€¦ï¼ã‚‚ã†å°‘ã—å…·ä½“çš„ã«èã„ã¦ãã‚Œã‚‹ï¼Ÿ"
        else:
            summary_text = "\n\n".join([
                f"ã€{res['title']}ã€‘\n{res['snippet']}"
                for res in search_results
            ])
            
            # â‘¤ AIè¦ç´„ç”Ÿæˆï¼ˆLlamaä½¿ç”¨ï¼‰
            logger.info("ğŸ§  Generating AI summary with Llama...")
            search_result = call_llama_advanced(
                f"ã€Œ{contextual_query}ã€ã«ã¤ã„ã¦èª¿ã¹ã¦ããŸã‚ˆï¼ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚‚ã¡ã“é¢¨ã«ã¾ã¨ã‚ã¦æ•™ãˆã¦ã€‚",
                history,
                f"ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã§ã™ã€‚ä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’åŸºã«ã€ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚\n\n{summary_text}"
            )
            
            if not search_result:
                search_result = f"èª¿ã¹ã¦ããŸã‚ˆï¼\n\n{summary_text[:500]}...\n\nã£ã¦æ„Ÿã˜ã˜ã‚ƒã‚“ï¼"

        # â‘¥ ã‚¿ã‚¹ã‚¯å®Œäº†ã‚’ä¿å­˜
        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task:
            task.result = search_result
            task.status = 'completed'
            task.completed_at = datetime.utcnow()
            session.commit()
            logger.info(f"âœ… Task {task_id} completed successfully")

    except Exception as e:
        logger.error(f"âŒ Background search failed for task {task_id}: {e}", exc_info=True)
        try:
            task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
            if task:
                task.result = "ã”ã‚ã‚“ã€æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦ã‚‚ã†ä¸€å›è©¦ã—ã¦ã¿ã¦ï¼"
                task.status = 'failed'
                task.completed_at = datetime.utcnow()
                session.commit()
        except:
            pass
    finally:
        session.close()

def start_background_search(user_uuid, query, history):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢ã®é–‹å§‹"""
    session = Session()
    try:
        task_id = str(uuid.uuid4())
        task = BackgroundTask(task_id=task_id, user_uuid=user_uuid, query=query)
        session.add(task)
        session.commit()
        
        # å±¥æ­´ã‚’æ¸¡ã—ã¦ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
        background_executor.submit(background_deep_search, task_id, query, history)
        logger.info(f"ğŸš€ Background search started: {task_id}")
        return task_id
    except Exception as e:
        logger.error(f"âŒ Failed to start background search: {e}")
        session.rollback()
        return None
    finally:
        session.close()

# --- Flask ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    session = Session()
    try:
        data = request.json
        user_uuid = data.get('uuid')
        user_name = data.get('name')
        message = data.get('message')

        if not user_uuid or not message:
            return jsonify({"type": "text", "message": "å¿…è¦ãªæƒ…å ±ãŒä¸è¶³ã—ã¦ã‚‹ã‚ˆï¼"}), 400

        user_data = {'uuid': user_uuid, 'name': user_name or 'ãƒ¦ãƒ¼ã‚¶ãƒ¼'}
        history = session.query(ConversationHistory)\
            .filter_by(user_uuid=user_uuid)\
            .order_by(ConversationHistory.timestamp.desc())\
            .limit(10).all()
        history.reverse()  # å¤ã„é †ã«ä¸¦ã¹æ›¿ãˆ

        response_data = {}
        
        # æ¤œç´¢ãŒå¿…è¦ã‹åˆ¤å®š
        if should_search(message):
            logger.info(f"ğŸ” Search triggered for: {message}")
            task_id = start_background_search(user_uuid, message, history)
            if task_id:
                response_data = {
                    "type": "search_started",
                    "task_id": task_id,
                    "message": "ãŠã£ã‘ãƒ¼ã€èª¿ã¹ã¦ã¿ã‚‹ã­ï¼ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã¦ï¼"
                }
            else:
                response_data = {
                    "type": "text",
                    "message": "ã”ã‚ã‚“ã€ä»Šæ¤œç´¢æ©Ÿèƒ½ãŒã†ã¾ãå‹•ã„ã¦ãªã„ã¿ãŸã„â€¦æ™®é€šã«ç­”ãˆã‚‹ã­ï¼"
                }
                ai_text = generate_ai_response(user_data, message, history)
                response_data["message"] = ai_text
        else:
            # é€šå¸¸ã®ä¼šè©±
            ai_text = generate_ai_response(user_data, message, history)
            response_data = {"type": "text", "message": ai_text}

        # ä¼šè©±å±¥æ­´ã‚’ä¿å­˜
        session.add(ConversationHistory(user_uuid=user_uuid, role='user', content=message))
        if response_data.get("message"):
            session.add(ConversationHistory(
                user_uuid=user_uuid,
                role='assistant',
                content=response_data["message"]
            ))
        session.commit()

        return jsonify(response_data)

    except Exception as e:
        logger.error(f"âŒ Error in /chat_lsl: {e}", exc_info=True)
        return jsonify({
            "type": "text",
            "message": "ã”ã‚ã‚“ã€ã‚µãƒ¼ãƒãƒ¼ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦"
        }), 500
    finally:
        session.close()

@app.route('/check_task', methods=['POST'])
def check_task():
    """ã‚¿ã‚¹ã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    session = Session()
    try:
        data = request.json
        task_id = data.get('task_id')
        
        if not task_id:
            return jsonify({'status': 'error', 'message': 'task_idãŒå¿…è¦ã§ã™'}), 400

        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()

        if not task:
            return jsonify({'status': 'not_found'}), 404

        if task.status == 'completed':
            result = task.result
            # å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã‚’å‰Šé™¤
            session.delete(task)
            session.commit()
            return jsonify({'status': 'completed', 'message': result})
        elif task.status == 'failed':
            result = task.result
            session.delete(task)
            session.commit()
            return jsonify({'status': 'completed', 'message': result})
        else:
            return jsonify({'status': 'pending'})

    except Exception as e:
        logger.error(f"âŒ Error in /check_task: {e}", exc_info=True)
        return jsonify({'status': 'error', 'message': 'ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼'}), 500
    finally:
        session.close()

@app.route('/health', methods=['GET'])
def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return jsonify({
        'status': 'healthy',
        'gemini': gemini_model is not None,
        'llama': groq_client is not None
    })

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ– ---
def initialize_app():
    global engine, Session
    logger.info("=" * 30 + " INITIALIZING MOCHIKO AI " + "=" * 30)
    
    initialize_gemini_client()
    initialize_groq_client()
    
    try:
        engine = create_engine(
            DATABASE_URL,
            connect_args={'check_same_thread': False} if 'sqlite' in DATABASE_URL else {},
            echo=False
        )
        Base.metadata.create_all(engine)
        Session = sessionmaker(bind=engine)
        logger.info("âœ… Database initialized successfully.")
    except Exception as e:
        logger.critical(f"ğŸ”¥ Database initialization failed: {e}")
        sys.exit(1)
    
    logger.info("=" * 30 + " INITIALIZATION COMPLETE " + "=" * 30)

# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ ---
if __name__ == '__main__':
    initialize_app()
    app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 8080)), debug=False)
else:
    # Production server (gunicorn)
    initialize_app()
