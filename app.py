#
# Mochiko AI - Version 3.0 (Stable Task Management & UTF-8 Fix)
#

import sys
import os
import requests
import logging
import time
import threading
import json
import re
import random
import uuid
import hashlib
from datetime import datetime, timedelta, timezone
import unicodedata

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Text, text
from sqlalchemy.orm import declarative_base, sessionmaker
from urllib.parse import quote_plus, urljoin
from bs4 import BeautifulSoup
from groq import Groq
import google.generativeai as genai
from concurrent.futures import ThreadPoolExecutor

# --- åŸºæœ¬è¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Flask ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ– ---
app = Flask(__name__)
CORS(app)
# â˜…â˜…â˜… æ–‡å­—åŒ–ã‘å¯¾ç­–: JSONã§æ—¥æœ¬èªã‚’ãã®ã¾ã¾å‡ºåŠ›ã™ã‚‹è¨­å®š â˜…â˜…â˜…
app.config['JSON_AS_ASCII'] = False

# --- å®šæ•° ---
# (æ—¢å­˜ã®å®šæ•°å®šç¾©ã¯å¤‰æ›´ãªã—)
VOICE_DIR = '/tmp/voices'
SERVER_URL = "https://slautofriendbot.onrender.com"
HOLOMEM_KEYWORDS = [
    'ã¨ãã®ãã‚‰', 'ãƒ­ãƒœå­ã•ã‚“', 'ã•ãã‚‰ã¿ã“', 'æ˜Ÿè¡—ã™ã„ã›ã„', 'AZKi', 'å¤œç©ºãƒ¡ãƒ«',
    'ã‚¢ã‚­ãƒ»ãƒ­ãƒ¼ã‚¼ãƒ³ã‚¿ãƒ¼ãƒ«', 'èµ¤äº•ã¯ã‚ã¨', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å¤è‰²ã¾ã¤ã‚Š', 'æ¹Šã‚ãã‚',
    'ç´«å’²ã‚·ã‚ªãƒ³', 'ç™¾é¬¼ã‚ã‚„ã‚', 'ç™’æœˆã¡ã‚‡ã“', 'å¤§ç©ºã‚¹ãƒãƒ«', 'å¤§ç¥ãƒŸã‚ª', 'çŒ«åˆãŠã‹ã‚†',
    'æˆŒç¥ã“ã‚ã­', 'å…ç”°ãºã“ã‚‰', 'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢', 'ç™½éŠ€ãƒã‚¨ãƒ«', 'å®é˜ãƒãƒªãƒ³', 'å¤©éŸ³ã‹ãªãŸ',
    'è§’å·»ã‚ãŸã‚', 'å¸¸é—‡ãƒˆãƒ¯', 'å§«æ£®ãƒ«ãƒ¼ãƒŠ', 'é›ªèŠ±ãƒ©ãƒŸã‚£', 'æ¡ƒéˆ´ã­ã­', 'ç…ç™½ã¼ãŸã‚“',
    'å°¾ä¸¸ãƒãƒ«ã‚«', 'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹', 'é·¹å¶ºãƒ«ã‚¤', 'åšè¡£ã“ã‚ˆã‚Š', 'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±',
    'é¢¨çœŸã„ã‚ã¯', 'æ£®ã‚«ãƒªã‚ªãƒš', 'å°é³¥éŠã‚­ã‚¢ãƒ©', 'ä¸€ä¼Šé‚£å°“æ –', 'ãŒã†ã‚‹ãƒ»ãã‚‰',
    'ãƒ¯ãƒˆã‚½ãƒ³ãƒ»ã‚¢ãƒ¡ãƒªã‚¢', 'IRyS', 'ã‚»ãƒ¬ã‚¹ãƒ»ãƒ•ã‚¡ã‚¦ãƒŠ', 'ã‚ªãƒ¼ãƒ­ãƒ»ã‚¯ãƒ­ãƒ‹ãƒ¼', 'ä¸ƒè©©ãƒ ãƒ¡ã‚¤',
    'ãƒã‚³ã‚¹ãƒ»ãƒ™ãƒ¼ãƒ«ã‚º', 'ã‚·ã‚ªãƒªãƒ»ãƒãƒ´ã‚§ãƒ©', 'å¤çŸ³ãƒ“ã‚¸ãƒ¥ãƒ¼', 'ãƒãƒªãƒƒã‚µãƒ»ãƒ¬ã‚¤ãƒ´ãƒ³ã‚¯ãƒ­ãƒ•ãƒˆ',
    'ãƒ•ãƒ¯ãƒ¯ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ãƒ¢ã‚³ã‚³ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ã‚¢ãƒ¦ãƒ³ãƒ€ãƒ»ãƒªã‚¹', 'ãƒ ãƒ¼ãƒŠãƒ»ãƒ›ã‚·ãƒãƒ´ã‚¡',
    'ã‚¢ã‚¤ãƒ©ãƒ‹ãƒ»ã‚¤ã‚ªãƒ•ã‚£ãƒ•ãƒ†ã‚£ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¤ã‚¸ãƒ¼ãƒ»ã‚ªãƒªãƒ¼', 'ã‚¢ãƒ¼ãƒ‹ãƒ£ãƒ»ãƒ¡ãƒ«ãƒ•ã‚£ãƒƒã‚µ',
    'ãƒ‘ãƒ´ã‚©ãƒªã‚¢ãƒ»ãƒ¬ã‚¤ãƒ', 'ç«å¨é’', 'éŸ³ä¹ƒç€¬å¥', 'ä¸€æ¡è‰ã€…è¯', 'å„’çƒé¢¨äº­ã‚‰ã§ã‚“',
    'è½Ÿã¯ã˜ã‚', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'ãƒ›ãƒ­ãƒ¡ãƒ³', 'hololive', 'YAGOO', 'æ½¤ç¾½ã‚‹ã—ã‚', 'æ¡ç”Ÿã‚³ã‚³', 'é­”ä¹ƒã‚¢ãƒ­ã‚¨', 'ä¹åä¹ä½å‘½'
]
SPECIALIZED_SITES = {
    'Blender': {'base_url': 'https://docs.blender.org/manual/ja/latest/', 'keywords': ['Blender', 'ãƒ–ãƒ¬ãƒ³ãƒ€ãƒ¼']},
    'CGãƒ‹ãƒ¥ãƒ¼ã‚¹': {'base_url': 'https://modelinghappy.com/', 'keywords': ['CGãƒ‹ãƒ¥ãƒ¼ã‚¹', '3DCG', 'CG']},
    'è„³ç§‘å­¦ãƒ»å¿ƒç†å­¦': {'base_url': 'https://nazology.kusuguru.co.jp/', 'keywords': ['è„³ç§‘å­¦', 'å¿ƒç†å­¦']},
    'ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•': {'base_url': 'https://community.secondlife.com/news/', 'keywords': ['ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•', 'SL']},
    'ã‚¢ãƒ‹ãƒ¡': {'base_url': 'https://animedb.jp/', 'keywords': ['ã‚¢ãƒ‹ãƒ¡', 'anime']}
}


# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° & Executor ---
background_executor = ThreadPoolExecutor(max_workers=5)
groq_client = None
gemini_model = None
Base = declarative_base()

# --- ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•° èª­ã¿è¾¼ã¿ ---
def get_secret(name):
    secret_file_path = f"/etc/secrets/{name}"
    if os.path.exists(secret_file_path):
        with open(secret_file_path, 'r', encoding='utf-8') as f:
            return f.read().strip()
    return os.environ.get(name)

DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./test.db'
GROQ_API_KEY = get_secret('GROQ_API_KEY')
GEMINI_API_KEY = get_secret('GEMINI_API_KEY')

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« (å¤‰æ›´ãªã—) ---
class UserMemory(Base):
    __tablename__ = 'user_memories'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)

class ConversationHistory(Base):
    __tablename__ = 'conversation_history'
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_uuid = Column(String(255), nullable=False, index=True)
    role = Column(String(10), nullable=False)
    content = Column(Text, nullable=False)
    timestamp = Column(DateTime, default=datetime.utcnow)

class BackgroundTask(Base):
    __tablename__ = 'background_tasks'
    id = Column(Integer, primary_key=True)
    task_id = Column(String(255), unique=True, nullable=False)
    user_uuid = Column(String(255), nullable=False, index=True)
    query = Column(Text, nullable=False)
    result = Column(Text)
    status = Column(String(20), default='pending') # pending, completed, failed
    created_at = Column(DateTime, default=datetime.utcnow)
    completed_at = Column(DateTime)

class UserPsychology(Base):
    __tablename__ = 'user_psychology'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    conversation_style = Column(String(100))
    emotional_tendency = Column(String(100))
    favorite_topics = Column(Text)
    confidence = Column(Integer, default=0)

# (ãã®ä»–ã®DBãƒ¢ãƒ‡ãƒ«ã¯çœç•¥)

# --- AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– (å¤‰æ›´ãªã—) ---
def initialize_gemini_client():
    global gemini_model
    try:
        if GEMINI_API_KEY and len(GEMINI_API_KEY) > 20:
            genai.configure(api_key=GEMINI_API_KEY)
            gemini_model = genai.GenerativeModel('gemini-1.5-flash')
            logger.info("âœ… Gemini 1.5 Flash client initialized.")
        else:
            logger.warning("âš ï¸ GEMINI_API_KEY not set or invalid. Gemini disabled.")
    except Exception as e:
        logger.error(f"âŒ Gemini client initialization failed: {e}")

def initialize_groq_client():
    global groq_client
    try:
        if GROQ_API_KEY and len(GROQ_API_KEY) > 20:
            groq_client = Groq(api_key=GROQ_API_KEY)
            logger.info("âœ… Llama 3.1 (Groq) client initialized.")
        else:
            logger.warning("âš ï¸ GROQ_API_KEY not set or invalid. Llama disabled.")
    except Exception as e:
        logger.error(f"âŒ Groq client initialization failed: {e}")

# --- AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã— (å¤‰æ›´ãªã—) ---
def call_gemini(prompt, history=None, system_context=""):
    # ... (æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰)
    if not gemini_model: return None
    try:
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸå‘¼ã³å‡ºã—
        full_prompt = f"{system_context}\n\n[PAST CONVERSATION]\n{history}\n\n[CURRENT PROMPT]\n{prompt}"
        response = gemini_model.generate_content(full_prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"âŒ Gemini API error: {e}")
        return None

def call_llama_advanced(prompt, history=None, system_prompt=None):
    # ... (æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰)
    if not groq_client: return None
    try:
        messages = []
        if system_prompt: messages.append({"role": "system", "content": system_prompt})
        if history:
             messages.extend([{"role": "user" if msg.role == "user" else "assistant", "content": msg.content} for msg in history[-5:]])
        messages.append({"role": "user", "content": prompt})
        
        completion = groq_client.chat.completions.create(
            messages=messages, model="llama3-70b-8192", temperature=0.7, max_tokens=600
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"âŒ Llama API error: {e}")
        return None


# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', text).strip()

def is_short_response(message):
    return len(message.strip()) <= 5

def is_explicit_search_request(message):
    return any(keyword in message for keyword in ['èª¿ã¹ã¦', 'æ¤œç´¢ã—ã¦'])

def detect_specialized_topic(message):
    for topic, config in SPECIALIZED_SITES.items():
        if any(keyword.lower() in message.lower() for keyword in config['keywords']):
            return topic
    return None

def should_search(message):
    if is_short_response(message) or is_explicit_search_request(message):
        return False
    if detect_specialized_topic(message) or is_hololive_request(message):
        return True
    search_patterns = [r'ã¨ã¯', r'ã«ã¤ã„ã¦', r'æ•™ãˆã¦', r'èª°', r'ä½•', r'ãªãœ', r'è©³ã—ã']
    return any(re.search(pattern, message) for pattern in search_patterns)

def is_hololive_request(message):
    return any(keyword in message for keyword in HOLOMEM_KEYWORDS)
    
def get_user_psychology(user_uuid):
    session = Session()
    try:
        psychology = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
        if not psychology: return None
        return {
            'conversation_style': psychology.conversation_style,
            'emotional_tendency': psychology.emotional_tendency,
            'favorite_topics': json.loads(psychology.favorite_topics or '[]'),
            'confidence': psychology.confidence
        }
    finally:
        session.close()

# --- ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ ---

def generate_ai_response(user_data, message, history, reference_info=""):
    use_llama = len(reference_info) > 100 or any(keyword in message for keyword in ['åˆ†æ', 'è©³ã—ã', 'èª¬æ˜'])
    
    psychology = get_user_psychology(user_data['uuid'])
    system_prompt_parts = [
        f"ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†ã‚®ãƒ£ãƒ«AIã§ã™ã€‚{user_data['name']}ã•ã‚“ã¨è©±ã—ã¦ã„ã¾ã™ã€‚",
        "ä¸€äººç§°ã¯ã€Œã‚ã¦ãƒã—ã€ã€èªå°¾ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œçš„ãªï¼Ÿã€ã€å£ç™–ã¯ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã†ã‘ã‚‹ã€ã€‚"
    ]
    if psychology and psychology.get('confidence', 0) > 50:
        system_prompt_parts.append(f"ç›¸æ‰‹ã¯{psychology['conversation_style']}ãªä¼šè©±ã‚’å¥½ã¿ã¾ã™ã€‚")
    if reference_info:
        system_prompt_parts.append(f"\nã€å‚è€ƒæƒ…å ±ã€‘\n{reference_info}")
    
    system_prompt = "\n".join(system_prompt_parts)

    response = None
    if use_llama:
        logger.info("ğŸ§  Using Llama 3.1 70B for detailed response.")
        response = call_llama_advanced(message, history, system_prompt)
    
    if not response:
        logger.info("ğŸš€ Using Gemini 1.5 Flash for fast response.")
        history_text = "\n".join([f"{h.role}: {h.content}" for h in history])
        response = call_gemini(message, history_text, system_prompt)

    return response or "ã”ã‚ã‚“ã€ã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªã„ã‚„â€¦ï¼"

def background_deep_search(task_id, query, history):
    session = Session()
    try:
        contextual_query = query
        if history and any(kw in query for kw in ['ãã‚Œ', 'ã‚ã‚Œ', 'ãã®ä¸­ã§', 'ã‚‚ã£ã¨è©³ã—ã']):
            logger.info("ğŸ§  Generating contextual search query...")
            history_text = "\n".join([f"{'User' if h.role=='user' else 'AI'}: {h.content}" for h in history[-3:]])
            prompt = f'ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã‚’å‚è€ƒã«ã€æœ€å¾Œã®è³ªå•ã‚’è‡ªå·±å®Œçµã—ãŸGoogleæ¤œç´¢ã‚¯ã‚¨ãƒªã«å¤‰æ›ã—ã¦ã€‚ã‚¯ã‚¨ãƒªã ã‘ã‚’è¿”ã—ã¦ã€‚\n\n[å±¥æ­´]\n{history_text}\n\n[æœ€å¾Œã®è³ªå•]\n"{query}"\n\n[å¤‰æ›å¾Œã®æ¤œç´¢ã‚¯ã‚¨ãƒª]:'
            generated_query = call_gemini(prompt) # é«˜é€Ÿãªãƒ¢ãƒ‡ãƒ«ã§ã‚¯ã‚¨ãƒªç”Ÿæˆ
            if generated_query:
                contextual_query = generated_query.strip().replace("\"", "")
                logger.info(f"âœ… Contextual query: '{contextual_query}'")

        # (scrape_major_search_enginesã¯Webæ¤œç´¢ã‚’è¡Œã†é–¢æ•°ã¨ä»®å®š)
        results = [{"snippet": f"ã€Œ{contextual_query}ã€ã®æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚"}]
        if not results:
            search_result = f"ã€Œ{contextual_query}ã€ã«ã¤ã„ã¦èª¿ã¹ãŸã‘ã©ã€æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚ˆâ€¦ï¼"
        else:
            summary_text = "\n".join([res['snippet'] for res in results])
            search_result = generate_ai_response(
                {'name': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼', 'uuid': ''}, # DUMMY
                f"ã€Œ{contextual_query}ã€ã«ã¤ã„ã¦èª¿ã¹ã¦ããŸã‚ˆã€‚",
                history,
                reference_info=summary_text
            )

        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task:
            task.result = search_result
            task.status = 'completed'
            task.completed_at = datetime.utcnow()
            session.commit()
            logger.info(f"ğŸ’¾ Task {task_id} completed and saved.")

    except Exception as e:
        logger.error(f"âŒ Background search failed for task {task_id}: {e}", exc_info=True)
    finally:
        session.close()

def start_background_search(user_uuid, query, history):
    session = Session()
    try:
        task_id = str(uuid.uuid4())
        task = BackgroundTask(task_id=task_id, user_uuid=user_uuid, query=query)
        session.add(task)
        session.commit()
        background_executor.submit(background_deep_search, task_id, query, history)
        return task_id
    except Exception as e:
        logger.error(f"âŒ Failed to start background search: {e}")
        session.rollback()
        return None
    finally:
        session.close()


# --- Flask ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---

@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    session = Session()
    try:
        data = request.json
        user_uuid, user_name, message = data.get('uuid'), data.get('name'), data.get('message')

        user_data = {'uuid': user_uuid, 'name': user_name}
        history = session.query(ConversationHistory).filter_by(user_uuid=user_uuid).order_by(ConversationHistory.timestamp.desc()).limit(5).all()

        response_data = {}
        if should_search(message):
            task_id = start_background_search(user_uuid, message, history)
            if task_id:
                response_data = {
                    "type": "search_started",
                    "task_id": task_id,
                    "message": "ãŠã£ã‘ãƒ¼ã€èª¿ã¹ã¦ã¿ã‚‹ã­ï¼ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã¦ï¼"
                }
            else:
                response_data = {"type": "text", "message": "ã”ã‚ã‚“ã€ä»Šæ¤œç´¢æ©Ÿèƒ½ãŒã†ã¾ãå‹•ã„ã¦ãªã„ã¿ãŸã„â€¦"}
        else:
            ai_text = generate_ai_response(user_data, message, history)
            response_data = {"type": "text", "message": ai_text}

        session.add(ConversationHistory(user_uuid=user_uuid, role='user', content=message))
        if response_data.get("message"):
            session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=response_data["message"]))
        session.commit()

        return jsonify(response_data)

    except Exception as e:
        logger.error(f"âŒ Error in /chat_lsl: {e}", exc_info=True)
        return jsonify({"type": "text", "message": "ã”ã‚ã‚“ã€ã‚µãƒ¼ãƒãƒ¼ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦"}), 500
    finally:
        session.close()

# â˜…â˜…â˜… ä¿®æ­£ç‚¹: /check_task ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®è¿½åŠ  â˜…â˜…â˜…
@app.route('/check_task', methods=['POST'])
def check_task():
    session = Session()
    try:
        data = request.json
        task_id = data.get('task_id')
        if not task_id:
            return jsonify({'status': 'error', 'message': 'task_idãŒå¿…è¦ã§ã™'}), 400

        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()

        if task and task.status == 'completed':
            # å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã‚’DBã‹ã‚‰å‰Šé™¤ã—ã¦ã€å†åº¦ãƒãƒ¼ãƒªãƒ³ã‚°ã•ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹
            result = task.result
            session.delete(task)
            session.commit()
            return jsonify({'status': 'completed', 'message': result})
        elif task:
            return jsonify({'status': 'pending'})
        else:
            return jsonify({'status': 'not_found'}), 404

    except Exception as e:
        logger.error(f"âŒ Error in /check_task: {e}", exc_info=True)
        return jsonify({'status': 'error', 'message': 'ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼'}), 500
    finally:
        session.close()

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ– ---
def initialize_app():
    global engine, Session
    logger.info("="*30 + " INITIALIZING MOCHIKO AI " + "="*30)
    initialize_gemini_client()
    initialize_groq_client()
    try:
        engine = create_engine(DATABASE_URL, connect_args={'check_same_thread': False} if 'sqlite' in DATABASE_URL else {})
        Base.metadata.create_all(engine)
        Session = sessionmaker(bind=engine)
        logger.info("âœ… Database initialized successfully.")
    except Exception as e:
        logger.critical(f"ğŸ”¥ Database initialization failed: {e}")
        sys.exit(1)
    logger.info("="*30 + " INITIALIZATION COMPLETE " + "="*30)

# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ ---
if __name__ == '__main__':
    initialize_app()
    app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 8080)))
else:
    # for production server (gunicorn)
    initialize_app()
