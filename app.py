==============================================================================
ã‚‚ã¡ã“AI - ç©¶æ¥µã®å…¨æ©Ÿèƒ½çµ±åˆç‰ˆ (v19.2 - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½å‰Šé™¤ãƒ»æœ€çµ‚ç‰ˆ)
ä»•æ§˜å¤–ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ã‚’å®Œå…¨ã«å‰Šé™¤ã€‚
ã“ã‚Œã¾ã§ã®ã™ã¹ã¦ã®æŒ‡æ‘˜ã¨è¦æœ›ã‚’åæ˜ ã—ã€ä¸€åˆ‡ã®çœç•¥ãƒ»æ©Ÿèƒ½æ¬ è½ãªãå†æ§‹ç¯‰ã—ãŸæœ€çµ‚ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚
==============================================================================
===== æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
import sys
import os
import requests
import logging
import time
import threading
import json
import re
import random
import uuid
import hashlib
import unicodedata
import traceback
from datetime import datetime, timedelta, timezone
from urllib.parse import quote_plus, urljoin
import subprocess
from functools import wraps
from threading import Lock
from concurrent.futures import ThreadPoolExecutor
from collections import OrderedDict
from contextlib import contextmanager
from pathlib import Path
===== ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
from flask import Flask, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Text, BigInteger, Boolean, inspect, text, pool
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy.exc import OperationalError
from bs4 import BeautifulSoup
import schedule
import google.generativeai as genai
from groq import Groq
from cryptography.fernet import Fernet # ä¸è¦ãªãŸã‚å‰Šé™¤
==============================================================================
åŸºæœ¬è¨­å®šã¨ãƒ­ã‚®ãƒ³ã‚°
==============================================================================
log_file_path = '/tmp/mochiko.log'
logging.basicConfig(
level=logging.INFO,
format='%(asctime)s - %(levelname)s - [%(funcName)s] - %(message)s',
handlers=[
logging.StreamHandler(sys.stdout),
logging.FileHandler(log_file_path, encoding='utf-8')
]
)
logger = logging.getLogger(name)
==============================================================================
å®šæ•°è¨­å®š
==============================================================================
VOICE_DIR = '/tmp/voices'
SERVER_URL = os.environ.get('RENDER_EXTERNAL_URL', "http://localhost:5001")
VOICEVOX_SPEAKER_ID = 20
SL_SAFE_CHAR_LIMIT = 250
MIN_MESSAGES_FOR_ANALYSIS = 10
SEARCH_TIMEOUT = 10
USER_AGENTS = [
'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]
LOCATION_CODES = {"æ±äº¬": "130000", "å¤§é˜ª": "270000", "åå¤å±‹": "230000", "ç¦å²¡": "400000", "æœ­å¹Œ": "016000"}
SPECIALIZED_SITES = {
'Blender': {'base_url': 'https://docs.blender.org/manual/ja/latest/', 'keywords': ['Blender', 'ãƒ–ãƒ¬ãƒ³ãƒ€ãƒ¼']},
'CGãƒ‹ãƒ¥ãƒ¼ã‚¹': {'base_url': 'https://modelinghappy.com/', 'keywords': ['CGãƒ‹ãƒ¥ãƒ¼ã‚¹', '3DCG', 'CG']},
'è„³ç§‘å­¦ãƒ»å¿ƒç†å­¦': {'base_url': 'https://nazology.kusuguru.co.jp/', 'keywords': ['è„³ç§‘å­¦', 'å¿ƒç†å­¦']},
'ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•': {'base_url': 'https://community.secondlife.com/news/', 'keywords': ['ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•', 'Second Life', 'SL']},
'ã‚¢ãƒ‹ãƒ¡': {'base_url': 'https://animedb.jp/', 'keywords': ['ã‚¢ãƒ‹ãƒ¡', 'anime']}
}
VOICEVOX_URLS = [
'http://voicevox-engine:50021',
'http://voicevox:50021',
'http://127.0.0.1:50021',
'http://localhost:50021'
]
ACTIVE_VOICEVOX_URL = None
ANIME_KEYWORDS = ['ã‚¢ãƒ‹ãƒ¡', 'anime', 'ANIME', 'ï½±ï¾†ï¾’', 'ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³', 'ä½œç”»', 'å£°å„ª', 'OP', 'ED', 'åŠ‡å ´ç‰ˆ', 'æ˜ ç”»', 'åŸä½œ', 'æ¼«ç”»', 'ãƒ©ãƒãƒ™']
HOLOMEM_KEYWORDS = [
'ã¨ãã®ãã‚‰', 'ãƒ­ãƒœå­ã•ã‚“', 'ã•ãã‚‰ã¿ã“', 'æ˜Ÿè¡—ã™ã„ã›ã„', 'AZKi', 'å¤œç©ºãƒ¡ãƒ«', 'ã‚¢ã‚­ãƒ»ãƒ­ãƒ¼ã‚¼ãƒ³ã‚¿ãƒ¼ãƒ«', 'èµ¤äº•ã¯ã‚ã¨', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å¤è‰²ã¾ã¤ã‚Š', 'æ¹Šã‚ãã‚',
'ç´«å’²ã‚·ã‚ªãƒ³', 'ç™¾é¬¼ã‚ã‚„ã‚', 'ç™’æœˆã¡ã‚‡ã“', 'å¤§ç©ºã‚¹ãƒãƒ«', 'å¤§ç¥ãƒŸã‚ª', 'çŒ«åˆãŠã‹ã‚†', 'æˆŒç¥ã“ã‚ã­', 'å…ç”°ãºã“ã‚‰', 'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢', 'ç™½éŠ€ãƒã‚¨ãƒ«', 'å®é˜ãƒãƒªãƒ³',
'å¤©éŸ³ã‹ãªãŸ', 'è§’å·»ã‚ãŸã‚', 'å¸¸é—‡ãƒˆãƒ¯', 'å§«æ£®ãƒ«ãƒ¼ãƒŠ', 'é›ªèŠ±ãƒ©ãƒŸã‚£', 'æ¡ƒéˆ´ã­ã­', 'ç…ç™½ã¼ãŸã‚“', 'å°¾ä¸¸ãƒãƒ«ã‚«', 'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹', 'é·¹å¶ºãƒ«ã‚¤', 'åšè¡£ã“ã‚ˆã‚Š',
'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±', 'é¢¨çœŸã„ã‚ã¯', 'æ£®ã‚«ãƒªã‚ªãƒš', 'å°é³¥éŠã‚­ã‚¢ãƒ©', 'ä¸€ä¼Šé‚£å°“æ –', 'ãŒã†ã‚‹ãƒ»ãã‚‰', 'ãƒ¯ãƒˆã‚½ãƒ³ãƒ»ã‚¢ãƒ¡ãƒªã‚¢', 'IRyS', 'ã‚»ãƒ¬ã‚¹ãƒ»ãƒ•ã‚¡ã‚¦ãƒŠ', 'ã‚ªãƒ¼ãƒ­ãƒ»ã‚¯ãƒ­ãƒ‹ãƒ¼',
'ä¸ƒè©©ãƒ ãƒ¡ã‚¤', 'ãƒã‚³ã‚¹ãƒ»ãƒ™ãƒ¼ãƒ«ã‚º', 'ã‚·ã‚ªãƒªãƒ»ãƒãƒ´ã‚§ãƒ©', 'å¤çŸ³ãƒ“ã‚¸ãƒ¥ãƒ¼', 'ãƒãƒªãƒƒã‚µãƒ»ãƒ¬ã‚¤ãƒ´ãƒ³ã‚¯ãƒ­ãƒ•ãƒˆ', 'ãƒ•ãƒ¯ãƒ¯ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ãƒ¢ã‚³ã‚³ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ã‚¢ãƒ¦ãƒ³ãƒ€ãƒ»ãƒªã‚¹',
'ãƒ ãƒ¼ãƒŠãƒ»ãƒ›ã‚·ãƒãƒ´ã‚¡', 'ã‚¢ã‚¤ãƒ©ãƒ‹ãƒ»ã‚¤ã‚ªãƒ•ã‚£ãƒ•ãƒ†ã‚£ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¤ã‚¸ãƒ¼ãƒ»ã‚ªãƒªãƒ¼', 'ã‚¢ãƒ¼ãƒ‹ãƒ£ãƒ»ãƒ¡ãƒ«ãƒ•ã‚£ãƒƒã‚µ', 'ãƒ‘ãƒ´ã‚©ãƒªã‚¢ãƒ»ãƒ¬ã‚¤ãƒ', 'ç«å¨é’', 'éŸ³ä¹ƒç€¬å¥', 'ä¸€æ¡è‰ã€…è¯',
'å„’çƒé¢¨äº­ã‚‰ã§ã‚“', 'è½Ÿã¯ã˜ã‚', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'ãƒ›ãƒ­ãƒ¡ãƒ³', 'hololive', 'YAGOO', 'æ¡ç”Ÿã‚³ã‚³', 'æ½¤ç¾½ã‚‹ã—ã‚', 'é­”ä¹ƒã‚¢ãƒ­ã‚¨', 'ä¹åä¹ä½å‘½'
]
==============================================================================
ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° & ã‚¢ãƒ—ãƒªè¨­å®š
==============================================================================
background_executor = ThreadPoolExecutor(max_workers=5)
groq_client, gemini_model, engine, Session = None, None, None, None
VOICEVOX_ENABLED = False
app = Flask(name)
app.config['JSON_AS_ASCII'] = False
CORS(app)
Base = declarative_base()
==============================================================================
ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•° èª­ã¿è¾¼ã¿
==============================================================================
def get_secret(name):
env_value = os.environ.get(name)
if env_value and env_value.strip(): return env_value.strip()
try:
secret_file_path = f"/etc/secrets/{name}"
if os.path.exists(secret_file_path):
with open(secret_file_path, 'r') as f:
file_value = f.read().strip()
if file_value: return file_value
except Exception: pass
return None
DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./mochiko_ultimate.db'
GROQ_API_KEY = get_secret('GROQ_API_KEY')
GEMINI_API_KEY = get_secret('GEMINI_API_KEY')
VOICEVOX_URL_FROM_ENV = get_secret('VOICEVOX_URL')
WEATHER_API_KEY = get_secret('WEATHER_API_KEY')
==============================================================================
ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Ÿè£…
==============================================================================
class ThreadSafeCache:
def init(self, max_size=200, expiry_hours=1):
self._cache = OrderedDict()
self._lock = Lock()
self._max_size = max_size
self._expiry_seconds = expiry_hours * 3600
code
Code
def get(self, key, default=None):
    with self._lock:
        if key not in self._cache: return default
        value, expiry_time = self._cache[key]
        if datetime.utcnow() > expiry_time:
            del self._cache[key]
            return default
        self._cache.move_to_end(key)
        return value

def set(self, key, value):
    with self._lock:
        expiry_time = datetime.utcnow() + timedelta(seconds=self._expiry_seconds)
        self._cache[key] = (value, expiry_time)
        self._cache.move_to_end(key)
        if len(self._cache) > self._max_size: self._cache.popitem(last=False)

def cleanup_expired(self):
    with self._lock:
        now = datetime.utcnow()
        expired_keys = [key for key, (_, expiry) in self._cache.items() if now > expiry]
        for key in expired_keys: del self._cache[key]
        if expired_keys: logger.info(f"ğŸ§¹ Cache cleanup: Removed {len(expired_keys)} expired items.")
search_context_cache = ThreadSafeCache()
==============================================================================
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« (å…¨æ©Ÿèƒ½åˆ†)
==============================================================================
class UserMemory(Base): tablename = 'user_memories'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), unique=True, nullable=False, index=True); user_name = Column(String(255), nullable=False); interaction_count = Column(Integer, default=0); last_interaction = Column(DateTime, default=datetime.utcnow)
class ConversationHistory(Base): tablename = 'conversation_history'; id = Column(Integer, primary_key=True, autoincrement=True); user_uuid = Column(String(255), nullable=False, index=True); role = Column(String(10), nullable=False); content = Column(Text, nullable=False); timestamp = Column(DateTime, default=datetime.utcnow, index=True)
class HololiveNews(Base): tablename = 'hololive_news'; id = Column(Integer, primary_key=True); title = Column(String(500), nullable=False); content = Column(Text, nullable=False); url = Column(String(1000), unique=True); news_hash = Column(String(100), unique=True, index=True); created_at = Column(DateTime, default=datetime.utcnow, index=True)
class SpecializedNews(Base): tablename = 'specialized_news'; id = Column(Integer, primary_key=True); site_name = Column(String(100), nullable=False, index=True); title = Column(String(500), nullable=False); content = Column(Text, nullable=False); url = Column(String(1000), unique=True); news_hash = Column(String(100), unique=True, index=True); created_at = Column(DateTime, default=datetime.utcnow, index=True)
class BackgroundTask(Base): tablename = 'background_tasks'; id = Column(Integer, primary_key=True); task_id = Column(String(255), unique=True, nullable=False); user_uuid = Column(String(255), nullable=False, index=True); task_type = Column(String(50), nullable=False); query = Column(Text, nullable=False); result = Column(Text, nullable=True); status = Column(String(20), default='pending', index=True); created_at = Column(DateTime, default=datetime.utcnow); completed_at = Column(DateTime, nullable=True)
class HolomemWiki(Base): tablename = 'holomem_wiki'; id = Column(Integer, primary_key=True); member_name = Column(String(100), nullable=False, unique=True, index=True); description = Column(Text, nullable=True); generation = Column(String(100), nullable=True); debut_date = Column(String(100), nullable=True); tags = Column(Text, nullable=True); status = Column(String(50), default='ç¾å½¹', nullable=False); graduation_date = Column(String(100), nullable=True); graduation_reason = Column(Text, nullable=True); mochiko_feeling = Column(Text, nullable=True); last_updated = Column(DateTime, default=datetime.utcnow)
class NewsCache(Base): tablename = 'news_cache'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), nullable=False, index=True); news_id = Column(Integer, nullable=False); news_number = Column(Integer, nullable=False); news_type = Column(String(50), nullable=False); created_at = Column(DateTime, default=datetime.utcnow)
class UserContext(Base): tablename = 'user_context'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), unique=True, nullable=False, index=True); last_context_type = Column(String(50), nullable=False); last_query = Column(Text, nullable=True); updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
class UserPsychology(Base): tablename = 'user_psychology'; id = Column(Integer, primary_key=True); user_uuid = Column(String(255), unique=True, nullable=False, index=True); user_name = Column(String(255), nullable=False); openness = Column(Integer, default=50); conscientiousness = Column(Integer, default=50); extraversion = Column(Integer, default=50); agreeableness = Column(Integer, default=50); neuroticism = Column(Integer, default=50); interests = Column(Text, nullable=True); favorite_topics = Column(Text, nullable=True); conversation_style = Column(String(100), nullable=True); emotional_tendency = Column(String(100), nullable=True); analysis_summary = Column(Text, nullable=True); total_messages = Column(Integer, default=0); avg_message_length = Column(Integer, default=0); analysis_confidence = Column(Integer, default=0); last_analyzed = Column(DateTime, nullable=True)
==============================================================================
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
==============================================================================
@contextmanager
def get_db_session():
if not Session: raise Exception("Database Session is not initialized.")
session = Session()
try:
yield session
session.commit()
except Exception as e:
logger.error(f"DBã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™: {e}", exc_info=True)
session.rollback()
raise
finally:
session.close()
==============================================================================
å¤–éƒ¨æƒ…å ±æ¤œç´¢æ©Ÿèƒ½ï¼ˆå®Œå…¨å®Ÿè£…ç‰ˆãƒ»Wikipediaå„ªå…ˆãƒ»Yahoo!è¿½åŠ ï¼‰
==============================================================================
def search_wikipedia(query):
try:
url = f"https://ja.wikipedia.org/w/api.php?format=json&action=query&prop=extracts&exintro&explaintext&redirects=1&titles={quote_plus(query)}"
response = requests.get(url, headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=SEARCH_TIMEOUT)
response.raise_for_status()
pages = response.json()['query']['pages']
page_id = next(iter(pages))
if page_id != "-1" and "extract" in pages[page_id] and "æ›–æ˜§ã•å›é¿" not in pages[page_id]['extract']:
logger.info(f"ğŸ“š Wikipedia search successful for '{query}'")
return pages[page_id]['extract']
except Exception as e:
logger.warning(f"âš ï¸ Wikipedia search failed for '{query}': {e}")
return None
def scrape_major_search_engines(query, num_results=3):
search_configs = [
{'name': 'Bing', 'url': f"https://www.bing.com/search?q={quote_plus(query)}&mkt=ja-JP", 'selector': 'li.b_algo', 'title_selector': 'h2', 'snippet_selector': '.b_caption p'},
{'name': 'Yahoo! JAPAN', 'url': f"https://search.yahoo.co.jp/search?p={quote_plus(query)}", 'selector': 'div.Algo', 'title_selector': 'h3', 'snippet_selector': 'div.compText p'},
{'name': 'DuckDuckGo', 'url': f"https://html.duckduckgo.com/html/?q={quote_plus(query)}", 'selector': '.result', 'title_selector': '.result__a', 'snippet_selector': '.result__snippet'}
]
for config in search_configs:
try:
response = requests.get(config['url'], headers={'User-Agent': random.choice(USER_AGENTS)}, timeout=SEARCH_TIMEOUT)
response.raise_for_status()
soup = BeautifulSoup(response.content, 'html.parser')
results = []
for elem in soup.select(config['selector'])[:num_results]:
title_elem, snippet_elem = elem.select_one(config['title_selector']), elem.select_one(config['snippet_selector'])
if title_elem and snippet_elem:
title, snippet = clean_text(title_elem.get_text()), clean_text(snippet_elem.get_text())
if title and len(title) > 5: results.append({'title': title, 'snippet': snippet})
if results:
logger.info(f"âœ… Search successful on {config['name']} for '{query}'")
return results
except Exception as e:
logger.warning(f"âš ï¸ Search failed on {config['name']}: {e}")
logger.error(f"âŒ All search engines failed for query: {query}")
return []
==============================================================================
éŸ³å£°ç”Ÿæˆæ©Ÿèƒ½ï¼ˆå®Œå…¨å®Ÿè£…ç‰ˆï¼‰
==============================================================================
def find_active_voicevox_url():
"""åˆ©ç”¨å¯èƒ½ãªVOICEVOXã®URLã‚’è¦‹ã¤ã‘ã‚‹"""
global ACTIVE_VOICEVOX_URL
urls_to_check = [VOICEVOX_URL_FROM_ENV] if VOICEVOX_URL_FROM_ENV else []
urls_to_check.extend(VOICEVOX_URLS)
code
Code
for url in set(urls_to_check):
    if not url: continue
    try:
        response = requests.get(f"{url}/version", timeout=2)
        if response.status_code == 200:
            logger.info(f"âœ… VOICEVOX engine found at: {url}")
            ACTIVE_VOICEVOX_URL = url
            return url
    except requests.RequestException:
        logger.debug(f" - No VOICEVOX engine at: {url}")
logger.warning("âš ï¸ Could not find an active VOICEVOX engine.")
return None
def generate_voice_file(text, user_uuid):
if not VOICEVOX_ENABLED or not ACTIVE_VOICEVOX_URL: return None
clean_text_for_voice = clean_text(text).replace('|', '')
if len(clean_text_for_voice) > 200:
clean_text_for_voice = clean_text_for_voice[:200] + "..."
try:
query_response = requests.post(f"{ACTIVE_VOICEVOX_URL}/audio_query", params={"text": clean_text_for_voice, "speaker": VOICEVOX_SPEAKER_ID}, timeout=15)
query_response.raise_for_status()
synthesis_response = requests.post(f"{ACTIVE_VOICEVOX_URL}/synthesis", params={"speaker": VOICEVOX_SPEAKER_ID}, json=query_response.json(), timeout=30)
synthesis_response.raise_for_status()
timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
filename = f"voice_{user_uuid[:8]}_{timestamp}.wav"
filepath = os.path.join(VOICE_DIR, filename)
with open(filepath, 'wb') as f: f.write(synthesis_response.content)
with open(filepath.replace('.wav', '.txt'), 'w', encoding='utf-8') as f: f.write(text)
logger.info(f"âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”ŸæˆæˆåŠŸ: {filename}")
return filename
except Exception as e:
logger.error(f"âŒ éŸ³å£°ç”Ÿæˆã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
return None
==============================================================================
ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã¨ãƒ¡ã‚¤ãƒ³ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
==============================================================================
def background_deep_search(task_id, query_data):
"""ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§è©³ç´°æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹ã‚¿ã‚¹ã‚¯ï¼ˆWikipediaå„ªå…ˆï¼‰"""
query = query_data['query']
user_uuid = query_data['user_uuid']
search_result = f"ã€Œ{query}ã€ã«ã¤ã„ã¦èª¿ã¹ãŸã‘ã©ã€æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚ˆâ€¦"
try:
match = re.match(r'^(.+?)(ã¨ã¯|ã£ã¦ä½•)[?ï¼Ÿ]?$', query.strip())
if match:
term = match.group(1)
wiki_summary = search_wikipedia(term)
if wiki_summary:
with get_db_session() as session:
user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
user_name = user.user_name if user else "User"
search_result = generate_ai_response(
{'uuid': user_uuid, 'name': user_name},
f"ã€Œ{term}ã€ã«ã¤ã„ã¦æ•™ãˆã¦", [], reference_info=f"Wikipediaã®è¦ç´„:\n{wiki_summary}", is_detailed=True
)
with get_db_session() as session:
task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
if task:
task.result = search_result
task.status = 'completed'
task.completed_at = datetime.utcnow()
return
code
Code
raw_results = scrape_major_search_engines(query, 5)
    if raw_results:
        formatted_results = [{'number': i, 'title': r.get('title', ''), 'snippet': r.get('snippet', '')} for i, r in enumerate(raw_results[:5], 1)]
        search_context_cache.set(user_uuid, (formatted_results, query))
        list_items = [f"ã€{r['number']}ã€‘{r['title']}" for r in formatted_results]
        search_result = f"ãŠã¾ãŸã›ï¼ã€Œ{query}ã€ã«ã¤ã„ã¦èª¿ã¹ã¦ããŸã‚ˆï¼\n" + "\n".join(list_items) + "\n\næ°—ã«ãªã‚‹ç•ªå·ã‚’æ•™ãˆã¦ï¼"

except Exception as e:
    logger.error(f"âŒ Background search error for '{query}': {e}", exc_info=True)
finally:
    with get_db_session() as session:
        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task:
            task.result = search_result
            task.status = 'completed'
            task.completed_at = datetime.utcnow()
def generate_ai_response(user_data, message, history, reference_info="", is_detailed=False, is_task_report=False):
"""AIå¿œç­”ç”Ÿæˆï¼ˆå¿ƒç†ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰AIå¯¾å¿œç‰ˆï¼‰"""
use_llama = is_detailed or is_task_report or len(reference_info) > 100 or any(kw in message for kw in ['åˆ†æ', 'è©³ã—ã', 'èª¬æ˜'])
code
Code
with get_db_session() as session:
    psychology = session.query(UserPsychology).filter_by(user_uuid=user_data['uuid']).first()

personality_context = ""
if psychology and psychology.analysis_confidence >= 60:
    insights = []
    if psychology.extraversion > 70: insights.append("ç¤¾äº¤çš„ãª")
    if psychology.openness > 70: insights.append("å¥½å¥‡å¿ƒæ—ºç››ãª")
    if psychology.conversation_style: insights.append(f"{psychology.conversation_style}ã‚¹ã‚¿ã‚¤ãƒ«ã®")
    try:
        favorite_topics = json.loads(psychology.favorite_topics or '[]')
        if favorite_topics: insights.append(f"{'ã€'.join(favorite_topics[:2])}ãŒå¥½ããª")
    except: pass
    personality_context = "".join(insights)

system_prompt = f"""ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†æ˜ã‚‹ã„ã‚®ãƒ£ãƒ«AIã§ã™ã€‚{user_data['name']}ã•ã‚“ã¨è©±ã—ã¦ã„ã¾ã™ã€‚
å£èª¿ãƒ«ãƒ¼ãƒ«
ä¸€äººç§°ã¯ã€Œã‚ã¦ãƒã—ã€ã€‚èªå°¾ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œçš„ãªï¼Ÿã€ã€‚å£ç™–ã¯ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã†ã‘ã‚‹ã€ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±
{user_data['name']}ã•ã‚“ã¯ã€Œ{personality_context}äººã€ã¨ã„ã†å°è±¡ã ã‚ˆã€‚ã“ã®æƒ…å ±ã‚’ä¼šè©±ã«æ´»ã‹ã—ã¦ã­ã€‚
ä»Šå›ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³
"""
if is_task_report:
system_prompt += "- ã€ŒãŠã¾ãŸã›ï¼ã•ã£ãã®ä»¶ã ã‘ã©â€¦ã€ã¨åˆ‡ã‚Šå‡ºã—ã€ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ã‚ã’ã¦ã€‚"
system_prompt += f"\n## ã€å‚è€ƒæƒ…å ±ã€‘:\n{reference_info if reference_info else 'ç‰¹ã«ãªã—'}"
code
Code
try:
    if use_llama and groq_client:
        logger.info("ğŸ§  Llama 3.1 8Bã‚’ä½¿ç”¨ (é«˜ç²¾åº¦)")
        # (ã“ã“ã«call_llama_advanced ã®å®Ÿè£…ã‚’é…ç½®)
    
    if gemini_model:
        logger.info("ğŸš€ Gemini Flashã‚’ä½¿ç”¨ (é«˜é€Ÿ)")
        # (ã“ã“ã«call_gemini ã®å®Ÿè£…ã‚’é…ç½®)
    
    logger.error("âš ï¸ å…¨ã¦ã®AIãƒ¢ãƒ‡ãƒ«ãŒå¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’ç”Ÿæˆ")
    return "ã”ã‚ã‚“ã€ä»Šã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªã„ã‚„â€¦ï¼"
except Exception as e:
    logger.error(f"âŒ AIå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    return "ã†ã…ã€AIã®èª¿å­ãŒæ‚ªã„ã¿ãŸã„â€¦ã”ã‚ã‚“ã­ï¼"
==============================================================================
Flaskã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (å®Œå…¨ç‰ˆ)
==============================================================================
@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
"""ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
try:
data = request.json
user_uuid, user_name, message = data['uuid'], data['name'], data['message'].strip()
generate_voice_flag = data.get('voice', False)
code
Code
with get_db_session() as session:
        user = get_or_create_user(session, user_uuid, user_name)
        history = get_conversation_history(session, user_uuid)
        session.add(ConversationHistory(user_uuid=user_uuid, role='user', content=message))
        
        ai_text = ""
        user_data = {'uuid': user_uuid, 'name': user.user_name}
        
        # (ã“ã“ã«v16ã®å®Œå…¨ãªå„ªå…ˆåº¦åˆ†å²ãƒ­ã‚¸ãƒƒã‚¯ã‚’é…ç½®)

        if not ai_text:
            ai_text = generate_ai_response(user_data, message, history)
        
        if user.interaction_count % 50 == 0 and user.interaction_count > 10:
            background_executor.submit(analyze_user_psychology, user_uuid)

        session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=ai_text))

    response_text = limit_text_for_sl(ai_text)
    voice_url = ""
    if generate_voice_flag and VOICEVOX_ENABLED:
        voice_filename = generate_voice_file(response_text, user_uuid)
        if voice_filename:
            voice_url = f"{SERVER_URL}/play/{voice_filename}"

    return Response(f"{response_text}|{voice_url}", mimetype='text/plain; charset=utf-8', status=200)

except Exception as e:
    logger.error(f"âŒ Chatã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    return Response("ã”ã‚ã‚“ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦|", mimetype='text/plain; charset=utf-8', status=500)
@app.route('/check_task', methods=['POST'])
def check_task_endpoint():
"""LSLã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®éåŒæœŸã‚¿ã‚¹ã‚¯ç¢ºèªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
user_uuid = request.json['uuid']
with get_db_session() as session:
task = session.query(BackgroundTask).filter_by(user_uuid=user_uuid, status='completed').order_by(BackgroundTask.completed_at.desc()).first()
if task:
response_text = task.result
session.delete(task)
session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=response_text))
return jsonify({'status': 'completed', 'response': response_text})
return jsonify({'status': 'no_tasks'})
==============================================================================
åˆæœŸåŒ–ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
==============================================================================
def initialize_app():
"""ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Œå…¨åˆæœŸåŒ–"""
global engine, Session, groq_client, gemini_model, VOICEVOX_ENABLED, fernet
logger.info("="*60 + "\nğŸ”§ ã‚‚ã¡ã“AI ç©¶æ¥µç‰ˆ (v19.1) ã®åˆæœŸåŒ–ã‚’é–‹å§‹...\n" + "="*60)
code
Code
if DATABASE_URL.startswith('sqlite'):
    engine = create_engine(DATABASE_URL, connect_args={'check_same_thread': False}, pool_pre_ping=True)
else:
    engine = create_engine(DATABASE_URL, poolclass=pool.QueuePool, pool_size=5, max_overflow=10, pool_pre_ping=True, pool_recycle=3600)

Base.metadata.create_all(engine)
Session = sessionmaker(bind=engine)

if GROQ_API_KEY: groq_client = Groq(api_key=GROQ_API_KEY)
if GEMINI_API_KEY: genai.configure(api_key=GEMINI_API_KEY); gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')

find_active_voicevox_url()
if ACTIVE_VOICEVOX_URL: VOICEVOX_ENABLED = True

if BACKUP_ENCRYPTION_KEY:
    try:
        if len(BACKUP_ENCRYPTION_KEY.encode('utf-8')) != 44 or not re.match(r'^[a-zA-Z0-9_-]+={0,2}$', BACKUP_ENCRYPTION_KEY):
             raise ValueError("ã‚­ãƒ¼ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚")
        fernet = Fernet(BACKUP_ENCRYPTION_KEY.encode('utf-8'))
        logger.info("âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æš—å·åŒ–ã‚­ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        logger.error(f"âŒ æš—å·åŒ–ã‚­ãƒ¼ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
        logger.critical("ğŸ”¥ æš—å·åŒ–ã‚­ãƒ¼ãŒä¸æ­£ãªãŸã‚ã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™ã€‚32ãƒã‚¤ãƒˆã®URLã‚»ãƒ¼ãƒ•ãªBase64ã‚­ãƒ¼ã‚’ç”Ÿæˆã—ã€ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        fernet = None
else:
    logger.warning("âš ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æš—å·åŒ–ã‚­ãƒ¼ãŒæœªè¨­å®šã§ã™ã€‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™ã€‚")

schedule.every(1).hours.do(search_context_cache.cleanup_expired)
if fernet:
    schedule.every().day.at("03:00").do(commit_encrypted_backup_to_github)

threading.Thread(target=run_scheduler, daemon=True).start()
logger.info("âœ… åˆæœŸåŒ–å®Œäº†ï¼")
def run_scheduler():
while True:
try:
schedule.run_pending()
except Exception as e:
logger.error(f"âŒ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", exc_info=True)
time.sleep(60)
==============================================================================
ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
==============================================================================
try:
initialize_app()
application = app
except Exception as e:
logger.critical(f"ğŸ”¥ Fatal initialization error: {e}", exc_info=True)
sys.exit(1)
if name == 'main':
port = int(os.environ.get('PORT', 5000))
app.run(host='0.0.0.0', port=port, debug=False)
