# ==============================================================================
# ã‚‚ã¡ã“AI - å…¨æ©Ÿèƒ½çµ±åˆç‰ˆ (v31.0 - Bug Fix & Improvement Edition)
#
# å¤‰æ›´ç‚¹ (v30.0 -> v31.0):
# 1. å¿ƒç†åˆ†æçµæœã®DBä¿å­˜å‡¦ç†ã‚’å®Ÿè£…
# 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢æ•°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å•é¡Œã‚’ä¿®æ­£ï¼ˆè¾æ›¸ã§è¿”ã™ã‚ˆã†ã«å¤‰æ›´ï¼‰
# 3. ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã‚’æ”¹å–„
# 4. Groqãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ç®¡ç†ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã«æ”¹å–„
# 5. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ã‚’è¿½åŠ 
# 6. ä¾‹å¤–å‡¦ç†ã®å¼·åŒ–ã¨ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®æ”¹å–„
# 7. ä¼šè©±å±¥æ­´å–å¾—ã®åŠ¹ç‡åŒ–
# 8. ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãƒªã‚»ãƒƒãƒˆãƒ­ã‚¸ãƒƒã‚¯ã‚’æ”¹å–„
# ==============================================================================

# ===== æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
import sys
import os
import requests
import logging
import time
import json
import re
import random
import uuid
import hashlib
import unicodedata
import traceback
import threading
import atexit
import glob
from html import escape
from datetime import datetime, timedelta, timezone
from urllib.parse import quote_plus, urljoin, urlparse
from functools import wraps, lru_cache
from threading import Lock, RLock
from concurrent.futures import ThreadPoolExecutor
from collections import OrderedDict, defaultdict
from contextlib import contextmanager
from dataclasses import dataclass, field
from typing import Optional, Dict, List, Any

# ===== ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =====
from flask import Flask, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Text, Boolean, Index, text
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy import pool
from bs4 import BeautifulSoup
import schedule
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from groq import Groq

# ==============================================================================
# åŸºæœ¬è¨­å®šã¨ãƒ­ã‚®ãƒ³ã‚°
# ==============================================================================
log_file_path = '/tmp/mochiko.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(funcName)s:%(lineno)d] - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(log_file_path, encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ==============================================================================
# å®šæ•°è¨­å®š & ãƒ¢ãƒ‡ãƒ«è¨­å®š
# ==============================================================================
VOICE_DIR = '/tmp/voices'
os.makedirs(VOICE_DIR, exist_ok=True)

SERVER_URL = os.environ.get('RENDER_EXTERNAL_URL', "http://localhost:5000")
VOICEVOX_SPEAKER_ID = 20
SL_SAFE_CHAR_LIMIT = 250
MIN_MESSAGES_FOR_ANALYSIS = 10
SEARCH_TIMEOUT = 15
VOICE_FILE_MAX_AGE_HOURS = 24  # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿æŒæ™‚é–“

# Groqã§ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆï¼ˆå„ªå…ˆåº¦é †ï¼‰
GROQ_MODELS = [
    "llama-3.3-70b-versatile",
    "llama-3.1-70b-versatile",
    "llama-3.1-8b-instant",
    "mixtral-8x7b-32768",
    "gemma2-9b-it"
]

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36'
]

LOCATION_CODES = {
    "æ±äº¬": "130000", "å¤§é˜ª": "270000", "åå¤å±‹": "230000",
    "ç¦å²¡": "400000", "æœ­å¹Œ": "016000"
}

SPECIALIZED_SITES = {
    'Blender': {'base_url': 'https://docs.blender.org/manual/ja/latest/', 'keywords': ['Blender', 'ãƒ–ãƒ¬ãƒ³ãƒ€ãƒ¼']},
    'CGãƒ‹ãƒ¥ãƒ¼ã‚¹': {'base_url': 'https://modelinghappy.com/', 'keywords': ['CGãƒ‹ãƒ¥ãƒ¼ã‚¹', '3DCG', 'CGæ¥­ç•Œ']},
    'è„³ç§‘å­¦ãƒ»å¿ƒç†å­¦': {'base_url': 'https://nazology.kusuguru.co.jp/', 'keywords': ['è„³ç§‘å­¦', 'å¿ƒç†å­¦', 'èªçŸ¥ç§‘å­¦']},
    'ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•': {'base_url': 'https://community.secondlife.com/news/', 'keywords': ['ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•', 'Second Life', 'SL']},
    'ã‚¢ãƒ‹ãƒ¡': {'base_url': 'https://animedb.jp/', 'keywords': ['ã‚¢ãƒ‹ãƒ¡', 'anime', 'ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³', 'å£°å„ª']}
}

HOLOMEM_KEYWORDS = [
    'ã¨ãã®ãã‚‰', 'ãƒ­ãƒœå­ã•ã‚“', 'ã•ãã‚‰ã¿ã“', 'ã¿ã“ã¡', 'æ˜Ÿè¡—ã™ã„ã›ã„', 'ã™ã„ã¡ã‚ƒã‚“',
    'AZKi', 'å¤œç©ºãƒ¡ãƒ«', 'ã‚¢ã‚­ãƒ»ãƒ­ãƒ¼ã‚¼ãƒ³ã‚¿ãƒ¼ãƒ«', 'èµ¤äº•ã¯ã‚ã¨', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å¤è‰²ã¾ã¤ã‚Š',
    'æ¹Šã‚ãã‚', 'ç´«å’²ã‚·ã‚ªãƒ³', 'ç™¾é¬¼ã‚ã‚„ã‚', 'ç™’æœˆã¡ã‚‡ã“', 'å¤§ç©ºã‚¹ãƒãƒ«', 'å¤§ç¥ãƒŸã‚ª',
    'çŒ«åˆãŠã‹ã‚†', 'ãŠã‹ã‚†ã‚“', 'æˆŒç¥ã“ã‚ã­', 'ã“ã‚ã•ã‚“', 'å…ç”°ãºã“ã‚‰', 'ãºã“ãƒ¼ã‚‰',
    'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢', 'ç™½éŠ€ãƒã‚¨ãƒ«', 'å®é˜ãƒãƒªãƒ³', 'èˆ¹é•·', 'å¤©éŸ³ã‹ãªãŸ', 'è§’å·»ã‚ãŸã‚',
    'å¸¸é—˜ãƒˆãƒ¯', 'å§«æ£®ãƒ«ãƒ¼ãƒŠ', 'é›ªèŠ±ãƒ©ãƒŸã‚£', 'æ¡ƒéˆ´ã­ã­', 'ç…ç™½ã¼ãŸã‚“', 'å°¾ä¸¸ãƒãƒ«ã‚«',
    'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹', 'é·¹å¶ºãƒ«ã‚¤', 'åšè¡£ã“ã‚ˆã‚Š', 'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±', 'é¢¨çœŸã„ã‚ã¯',
    'æ£®ã‚«ãƒªã‚ªãƒš', 'å°é³¥éŠã‚­ã‚¢ãƒ©', 'ä¸€ä¼Šé‚£å°“æ –', 'ãŒã†ã‚‹ãƒ»ãã‚‰', 'ã‚µãƒ¡ã¡ã‚ƒã‚“',
    'ãƒ¯ãƒˆã‚½ãƒ³ãƒ»ã‚¢ãƒ¡ãƒªã‚¢', 'IRyS', 'ã‚»ãƒ¬ã‚¹ãƒ»ãƒ•ã‚¡ã‚¦ãƒŠ', 'ã‚ªãƒ¼ãƒ­ãƒ»ã‚¯ãƒ­ãƒ‹ãƒ¼', 'ä¸ƒè©©ãƒ ãƒ¡ã‚¤',
    'ãƒã‚³ã‚¹ãƒ»ãƒ™ãƒ¼ãƒ«ã‚º', 'ã‚·ã‚ªãƒªãƒ»ãƒãƒ´ã‚§ãƒ©', 'å¤çŸ³ãƒ“ã‚¸ãƒ¥ãƒ¼', 'ãƒãƒªãƒƒã‚µãƒ»ãƒ¬ã‚¤ãƒ´ãƒ³ã‚¯ãƒ­ãƒ•ãƒˆ',
    'ãƒ•ãƒ¯ãƒ¯ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ãƒ¢ã‚³ã‚³ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ã‚¢ãƒ¦ãƒ³ãƒ€ãƒ»ãƒªã‚¹', 'ãƒ ãƒ¼ãƒŠãƒ»ãƒ›ã‚·ãƒãƒ´ã‚¡',
    'ã‚¢ã‚¤ãƒ©ãƒ‹ãƒ»ã‚¤ã‚ªãƒ•ã‚£ãƒ•ãƒ†ã‚£ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¤ã‚¸ãƒ¼ãƒ»ã‚ªãƒªãƒ¼', 'ã‚¢ãƒ¼ãƒ‹ãƒ£ãƒ»ãƒ¡ãƒ«ãƒ•ã‚£ãƒƒã‚µ',
    'ãƒ‘ãƒ´ã‚©ãƒªã‚¢ãƒ»ãƒ¬ã‚¤ãƒ', 'ç«å¨é’', 'éŸ³ä¹ƒç€¬å¥', 'ä¸€æ¡è‰ã€…è¯', 'å„’çƒé¢¨äº­ã‚‰ã§ã‚“',
    'è½Ÿã¯ã˜ã‚', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'ãƒ›ãƒ­ãƒ¡ãƒ³', 'hololive', 'YAGOO', 'æ¡ç”Ÿã‚³ã‚³',
    'æ½¤ç¾½ã‚‹ã—ã‚', 'é­”ä¹ƒã‚¢ãƒ­ã‚¨', 'ä¹åä¹ä½å‘½'
]

ANIME_KEYWORDS = ['ã‚¢ãƒ‹ãƒ¡', 'anime', 'ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³', 'ä½œç”»', 'å£°å„ª', 'OP', 'ED', 'åŠ‡å ´ç‰ˆ', 'æ˜ ç”»', 'åŸä½œ', 'æ¼«ç”»', 'ãƒ©ãƒãƒ™']

VOICEVOX_URLS = [
    'http://voicevox-engine:50021', 'http://voicevox:50021',
    'http://127.0.0.1:50021', 'http://localhost:50021'
]

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ï¼ˆå‹å®‰å…¨æ€§å‘ä¸Šï¼‰
# ==============================================================================
@dataclass
class GroqModelStatus:
    is_limited: bool = False
    reset_time: Optional[datetime] = None
    last_error: Optional[str] = None

@dataclass
class UserData:
    uuid: str
    name: str
    interaction_count: int

# ==============================================================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ç®¡ç†ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•æ”¹å–„ç‰ˆï¼‰
# ==============================================================================
class GlobalState:
    def __init__(self):
        self._lock = RLock()
        self._voicevox_enabled = False
        self._active_voicevox_url = None

    @property
    def voicevox_enabled(self) -> bool:
        with self._lock:
            return self._voicevox_enabled

    @voicevox_enabled.setter
    def voicevox_enabled(self, value: bool):
        with self._lock:
            self._voicevox_enabled = value

    @property
    def active_voicevox_url(self) -> Optional[str]:
        with self._lock:
            return self._active_voicevox_url

    @active_voicevox_url.setter
    def active_voicevox_url(self, value: Optional[str]):
        with self._lock:
            self._active_voicevox_url = value


class GroqModelManager:
    """Groqãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã«ç®¡ç†"""
    
    def __init__(self, models: List[str]):
        self._lock = RLock()
        self._status: Dict[str, GroqModelStatus] = {
            model: GroqModelStatus() for model in models
        }
        self._models = models

    def is_available(self, model: str) -> bool:
        with self._lock:
            status = self._status.get(model)
            if not status:
                return False
            if not status.is_limited:
                return True
            if status.reset_time and datetime.utcnow() >= status.reset_time:
                status.is_limited = False
                status.reset_time = None
                status.last_error = None
                logger.info(f"âœ… {model} ã®åˆ¶é™ãŒè§£é™¤ã•ã‚Œã¾ã—ãŸ")
                return True
            return False

    def mark_limited(self, model: str, wait_minutes: int = 5, error_msg: str = ""):
        with self._lock:
            if model in self._status:
                self._status[model].is_limited = True
                self._status[model].reset_time = datetime.utcnow() + timedelta(minutes=wait_minutes)
                self._status[model].last_error = error_msg
                logger.warning(f"âš ï¸ {model} ã‚’{wait_minutes}åˆ†é–“åˆ¶é™")

    def get_status_report(self) -> str:
        with self._lock:
            lines = ["ğŸ¦™ Groq ãƒ¢ãƒ‡ãƒ«ç¨¼åƒçŠ¶æ³:"]
            for model in self._models:
                status = self._status[model]
                if status.is_limited:
                    reset = status.reset_time
                    if reset:
                        jst = (reset + timedelta(hours=9)).strftime('%H:%M:%S')
                        lines.append(f"  âŒ {model}: åˆ¶é™ä¸­ (è§£é™¤äºˆå®š: {jst})")
                    else:
                        lines.append(f"  âŒ {model}: åˆ¶é™ä¸­")
                else:
                    lines.append(f"  âœ… {model}: OK")
            return "\n".join(lines)

    def get_available_models(self) -> List[str]:
        with self._lock:
            return [m for m in self._models if self.is_available(m)]


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
global_state = GlobalState()
groq_model_manager = GroqModelManager(GROQ_MODELS)
background_executor = ThreadPoolExecutor(max_workers=5)

# AI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
groq_client: Optional[Groq] = None
gemini_model = None
engine = None
Session = None

# Flask ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
app = Flask(__name__)
application = app
app.config['JSON_AS_ASCII'] = False
CORS(app)
Base = declarative_base()

# ==============================================================================
# ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•° èª­ã¿è¾¼ã¿
# ==============================================================================
def get_secret(name: str) -> Optional[str]:
    env_value = os.environ.get(name)
    if env_value and env_value.strip():
        return env_value.strip()
    try:
        secret_file_path = f"/etc/secrets/{name}"
        if os.path.exists(secret_file_path):
            with open(secret_file_path, 'r') as f:
                file_value = f.read().strip()
                if file_value:
                    return file_value
    except Exception:
        pass
    return None

DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./mochiko_ultimate.db'
GROQ_API_KEY = get_secret('GROQ_API_KEY')
GEMINI_API_KEY = get_secret('GEMINI_API_KEY')
VOICEVOX_URL_FROM_ENV = get_secret('VOICEVOX_URL')
WEATHER_API_KEY = get_secret('WEATHER_API_KEY')

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
# ==============================================================================
class UserMemory(Base):
    __tablename__ = 'user_memories'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    interaction_count = Column(Integer, default=0)
    last_interaction = Column(DateTime, default=datetime.utcnow)


class ConversationHistory(Base):
    __tablename__ = 'conversation_history'
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_uuid = Column(String(255), nullable=False, index=True)
    role = Column(String(10), nullable=False)
    content = Column(Text, nullable=False)
    timestamp = Column(DateTime, default=datetime.utcnow, index=True)
    __table_args__ = (
        Index('idx_user_timestamp', 'user_uuid', 'timestamp'),
    )


class UserPsychology(Base):
    __tablename__ = 'user_psychology'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False, index=True)
    user_name = Column(String(255), nullable=False)
    openness = Column(Integer, default=50)
    conscientiousness = Column(Integer, default=50)
    extraversion = Column(Integer, default=50)
    agreeableness = Column(Integer, default=50)
    neuroticism = Column(Integer, default=50)
    interests = Column(Text, nullable=True)
    favorite_topics = Column(Text, nullable=True)
    conversation_style = Column(String(100), nullable=True)
    emotional_tendency = Column(String(100), nullable=True)
    analysis_summary = Column(Text, nullable=True)
    total_messages = Column(Integer, default=0)
    avg_message_length = Column(Integer, default=0)
    analysis_confidence = Column(Integer, default=0)
    last_analyzed = Column(DateTime, nullable=True)


class BackgroundTask(Base):
    __tablename__ = 'background_tasks'
    id = Column(Integer, primary_key=True)
    task_id = Column(String(255), unique=True, nullable=False)
    user_uuid = Column(String(255), nullable=False, index=True)
    task_type = Column(String(50), nullable=False)
    query = Column(Text, nullable=False)
    result = Column(Text, nullable=True)
    status = Column(String(20), default='pending', index=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    completed_at = Column(DateTime, nullable=True)


class HolomemWiki(Base):
    __tablename__ = 'holomem_wiki'
    id = Column(Integer, primary_key=True)
    member_name = Column(String(100), nullable=False, unique=True, index=True)
    description = Column(Text, nullable=True)
    generation = Column(String(100), nullable=True)
    debut_date = Column(String(100), nullable=True)
    tags = Column(Text, nullable=True)
    status = Column(String(50), default='ç¾å½¹', nullable=False)
    graduation_date = Column(String(100), nullable=True)
    graduation_reason = Column(Text, nullable=True)
    mochiko_feeling = Column(Text, nullable=True)
    last_updated = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)


class HololiveNews(Base):
    __tablename__ = 'hololive_news'
    id = Column(Integer, primary_key=True)
    title = Column(String(500), nullable=False)
    content = Column(Text, nullable=False)
    url = Column(String(1000), unique=True)
    news_hash = Column(String(100), unique=True, index=True)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)

# ==============================================================================
# ä¾‹å¤–ã‚¯ãƒ©ã‚¹
# ==============================================================================
class MochikoException(Exception):
    """ã‚‚ã¡ã“AIåŸºåº•ä¾‹å¤–"""
    pass

class AIModelException(MochikoException):
    """AIãƒ¢ãƒ‡ãƒ«é–¢é€£ã®ä¾‹å¤–"""
    pass

class DatabaseException(MochikoException):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–¢é€£ã®ä¾‹å¤–"""
    pass

class RateLimitException(MochikoException):
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä¾‹å¤–"""
    pass

# ==============================================================================
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ & ãƒ¬ãƒ¼ãƒˆåˆ¶é™
# ==============================================================================
class RateLimiter:
    def __init__(self, max_requests: int, time_window: timedelta):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests: Dict[str, List[datetime]] = defaultdict(list)
        self._lock = threading.Lock()

    def is_allowed(self, user_id: str) -> bool:
        with self._lock:
            now = datetime.utcnow()
            cutoff = now - self.time_window
            self.requests[user_id] = [
                req_time for req_time in self.requests[user_id]
                if req_time > cutoff
            ]
            if len(self.requests[user_id]) >= self.max_requests:
                return False
            self.requests[user_id].append(now)
            return True

    def cleanup_old_entries(self):
        """å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        with self._lock:
            now = datetime.utcnow()
            cutoff = now - self.time_window
            empty_users = []
            for user_id, times in self.requests.items():
                self.requests[user_id] = [t for t in times if t > cutoff]
                if not self.requests[user_id]:
                    empty_users.append(user_id)
            for user_id in empty_users:
                del self.requests[user_id]


chat_rate_limiter = RateLimiter(max_requests=10, time_window=timedelta(minutes=1))


def sanitize_user_input(text: str, max_length: int = 1000) -> str:
    if not text:
        return ""
    text = text[:max_length]
    text = escape(text)
    dangerous_patterns = [
        r'<script[^>]*>.*?</script>',
        r'javascript:',
        r'on\w+\s*=',
    ]
    for pattern in dangerous_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.DOTALL)
    return text.strip()


def mask_uuid(uuid_str: str) -> str:
    if len(uuid_str) > 8:
        return f"{uuid_str[:4]}****{uuid_str[-4:]}"
    return "****"

# ==============================================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# ==============================================================================
@contextmanager
def get_db_session():
    if not Session:
        logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹SessionãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        raise DatabaseException("Database Session is not initialized.")
    session = Session()
    try:
        yield session
        session.commit()
    except Exception as e:
        logger.error(f"âŒ DBã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        session.rollback()
        raise DatabaseException(f"DB operation failed: {e}")
    finally:
        session.close()

# ==============================================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ==============================================================================
def create_json_response(data: Any, status: int = 200) -> Response:
    return Response(
        json.dumps(data, ensure_ascii=False),
        mimetype='application/json; charset=utf-8',
        status=status
    )


def clean_text(text: str) -> str:
    if not text:
        return ""
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def limit_text_for_sl(text: str, max_length: int = SL_SAFE_CHAR_LIMIT) -> str:
    if len(text) > max_length:
        return text[:max_length - 3] + "..."
    return text


def get_japan_time() -> str:
    jst = timezone(timedelta(hours=9))
    now = datetime.now(jst)
    return f"ä»Šã®æ—¥æœ¬ã®æ™‚é–“ã¯ã€{now.strftime('%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚%Måˆ†')}ã ã‚ˆï¼"


def is_time_request(message: str) -> bool:
    keywords = ['ä»Šä½•æ™‚', 'æ™‚åˆ»', 'ä½•æ™‚', 'ãªã‚“ã˜']
    return any(kw in message for kw in keywords)


def is_weather_request(message: str) -> bool:
    keywords = ['ä»Šæ—¥ã®å¤©æ°—', 'æ˜æ—¥ã®å¤©æ°—', 'å¤©æ°—äºˆå ±', 'å¤©æ°—ã¯']
    return any(kw in message for kw in keywords)


def is_hololive_request(message: str) -> bool:
    return any(kw in message for kw in HOLOMEM_KEYWORDS)


def is_anime_request(message: str) -> bool:
    return any(kw in message for kw in ANIME_KEYWORDS)


def detect_specialized_topic(message: str) -> Optional[str]:
    for topic, config in SPECIALIZED_SITES.items():
        if any(kw in message for kw in config['keywords']):
            return topic
    return None


def is_explicit_search_request(message: str) -> bool:
    keywords = ['èª¿ã¹ã¦', 'æ¤œç´¢ã—ã¦', 'æ¢ã—ã¦', 'ã¨ã¯', 'ã£ã¦ä½•', 'ã«ã¤ã„ã¦', 'æ•™ãˆã¦', 'ãŠã™ã™ã‚']
    return any(kw in message for kw in keywords)


def is_short_response(message: str) -> bool:
    normalized = message.strip().lower()
    short_responses = ['ã†ã‚“', 'ãã†', 'ã¯ã„', 'ãã£ã‹', 'ãªã‚‹ã»ã©', 'ãŠã‘', 'ok', 'äº†è§£']
    return len(normalized) <= 5 or normalized in short_responses


def extract_location(message: str) -> str:
    for location in LOCATION_CODES.keys():
        if location in message:
            return location
    return "æ±äº¬"


def detect_db_correction_request(message: str) -> Optional[Dict]:
    pattern = r"(.+?)(?:(?:ã®|ã«é–¢ã™ã‚‹)(?:æƒ…å ±|ãƒ‡ãƒ¼ã‚¿))?(?:ã§|ã€|ã ã‘ã©|ã§ã™ãŒ)ã€?ã€Œ(.+?)ã€ã¯ã€Œ(.+?)ã€ãŒæ­£ã—ã„ã‚ˆ"
    match = re.search(pattern, message)
    if match:
        member_name_raw, field_raw, value_raw = match.groups()
        member_name = sanitize_user_input(member_name_raw.strip())
        field = sanitize_user_input(field_raw.strip())
        value = sanitize_user_input(value_raw.strip())
        
        field_map = {
            'èª¬æ˜': 'description',
            'ãƒ‡ãƒ“ãƒ¥ãƒ¼æ—¥': 'debut_date',
            'æœŸ': 'generation',
            'ã‚¿ã‚°': 'tags',
            'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹': 'status',
            'å’æ¥­æ—¥': 'graduation_date',
            'ã‚‚ã¡ã“ã®æ°—æŒã¡': 'mochiko_feeling'
        }
        
        if member_name in HOLOMEM_KEYWORDS and field in field_map:
            return {
                'member_name': member_name,
                'field': field,
                'value': value,
                'db_field': field_map[field]
            }
    return None


def is_holomem_name_only_request_safe(message: str) -> Optional[str]:
    msg_stripped = sanitize_user_input(message.strip(), max_length=50)
    if len(msg_stripped) > 20:
        return None
    for name in HOLOMEM_KEYWORDS:
        if name == msg_stripped:
            return name
    return None

# ==============================================================================
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†
# ==============================================================================
def get_or_create_user(session, user_uuid: str, user_name: str) -> UserData:
    user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
    if user:
        user.interaction_count += 1
        user.last_interaction = datetime.utcnow()
        if user.user_name != user_name:
            user.user_name = user_name
    else:
        user = UserMemory(
            user_uuid=user_uuid,
            user_name=user_name,
            interaction_count=1
        )
        session.add(user)
        logger.info(f"âœ¨ æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ: {user_name} (UUID: {mask_uuid(user_uuid)})")
    
    return UserData(
        uuid=user.user_uuid,
        name=user.user_name,
        interaction_count=user.interaction_count
    )


def get_conversation_history(session, user_uuid: str, limit: int = 10) -> List[Dict]:
    history_records = (
        session.query(ConversationHistory)
        .filter_by(user_uuid=user_uuid)
        .order_by(ConversationHistory.timestamp.desc())
        .limit(limit)
        .all()
    )
    return [{'role': h.role, 'content': h.content} for h in reversed(history_records)]

# ==============================================================================
# ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆä¿®æ­£ç‰ˆ: è¾æ›¸ã§è¿”ã™ï¼‰
# ==============================================================================
_holomem_cache: Dict[str, Dict] = {}
_holomem_cache_lock = threading.Lock()
_holomem_cache_ttl = timedelta(minutes=30)
_holomem_cache_timestamps: Dict[str, datetime] = {}


def get_holomem_info_cached(member_name: str) -> Optional[Dict]:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãã§ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±ã‚’å–å¾—ï¼ˆè¾æ›¸ã§è¿”ã™ï¼‰"""
    with _holomem_cache_lock:
        now = datetime.utcnow()
        if member_name in _holomem_cache:
            cached_time = _holomem_cache_timestamps.get(member_name)
            if cached_time and (now - cached_time) < _holomem_cache_ttl:
                return _holomem_cache[member_name]
    
    with get_db_session() as session:
        wiki = session.query(HolomemWiki).filter_by(member_name=member_name).first()
        if wiki:
            data = {
                'member_name': wiki.member_name,
                'description': wiki.description,
                'generation': wiki.generation,
                'debut_date': wiki.debut_date,
                'tags': wiki.tags,
                'status': wiki.status,
                'graduation_date': wiki.graduation_date,
                'graduation_reason': wiki.graduation_reason,
                'mochiko_feeling': wiki.mochiko_feeling
            }
            with _holomem_cache_lock:
                _holomem_cache[member_name] = data
                _holomem_cache_timestamps[member_name] = datetime.utcnow()
            return data
    return None


def clear_holomem_cache(member_name: Optional[str] = None):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
    with _holomem_cache_lock:
        if member_name:
            _holomem_cache.pop(member_name, None)
            _holomem_cache_timestamps.pop(member_name, None)
        else:
            _holomem_cache.clear()
            _holomem_cache_timestamps.clear()

# ==============================================================================
# AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—é–¢æ•°
# ==============================================================================
def _safe_get_gemini_text(response) -> Optional[str]:
    try:
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'content') and candidate.content.parts:
                return candidate.content.parts[0].text
    except (IndexError, AttributeError) as e:
        logger.warning(f"âš ï¸ Geminiå¿œç­”è§£æã‚¨ãƒ©ãƒ¼: {e}")
        if hasattr(response, 'prompt_feedback'):
            logger.warning(f"  ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {response.prompt_feedback}")
    except Exception as e:
        logger.error(f"âŒ Geminiå¿œç­”å‡¦ç†ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
    return None


def call_gemini(system_prompt: str, message: str, history: List[Dict]) -> Optional[str]:
    if not gemini_model:
        return None
    try:
        full_prompt = f"{system_prompt}\n\nã€ä¼šè©±å±¥æ­´ã€‘\n"
        for h in history[-5:]:  # ç›´è¿‘5ä»¶ã«åˆ¶é™
            role = 'ãƒ¦ãƒ¼ã‚¶ãƒ¼' if h['role'] == 'user' else 'ã‚‚ã¡ã“'
            full_prompt += f"{role}: {h['content']}\n"
        full_prompt += f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼: {message}\nã‚‚ã¡ã“:"

        response = gemini_model.generate_content(
            full_prompt,
            generation_config={"temperature": 0.8, "max_output_tokens": 300}
        )
        text = _safe_get_gemini_text(response)

        if text:
            logger.debug("Geminiå¿œç­”æˆåŠŸ")
            return text.strip()
        return None
    except Exception as e:
        error_str = str(e).lower()
        if 'quota' in error_str or 'rate' in error_str:
            logger.warning(f"âš ï¸ Gemini ãƒ¬ãƒ¼ãƒˆåˆ¶é™: {e}")
        elif 'api key' in error_str:
            logger.error(f"âŒ Gemini APIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            logger.warning(f"âš ï¸ Gemini APIã‚¨ãƒ©ãƒ¼: {e}")
        return None


def call_groq(system_prompt: str, message: str, history: List[Dict], max_tokens: int = 800) -> Optional[str]:
    if not groq_client:
        return None

    messages = [{"role": "system", "content": system_prompt}]
    for h in history[-5:]:  # ç›´è¿‘5ä»¶ã«åˆ¶é™
        messages.append({"role": h['role'], "content": h['content']})
    messages.append({"role": "user", "content": message})

    available_models = groq_model_manager.get_available_models()
    if not available_models:
        logger.error("âŒ åˆ©ç”¨å¯èƒ½ãªGroqãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return None

    last_error = None
    for model_name in available_models:
        try:
            response = groq_client.chat.completions.create(
                model=model_name,
                messages=messages,
                temperature=0.8,
                max_tokens=max_tokens
            )
            logger.info(f"âœ… GroqæˆåŠŸ (ãƒ¢ãƒ‡ãƒ«: {model_name})")
            return response.choices[0].message.content.strip()

        except Exception as e:
            last_error = e
            error_str = str(e)

            if "Rate limit" in error_str or "429" in error_str:
                wait_minutes = 5
                wait_match = re.search(r'try again in (\d+)m?(\d*)s?', error_str)
                if wait_match:
                    mins = int(wait_match.group(1)) if wait_match.group(1) else 0
                    wait_minutes = max(mins + 1, 2)
                groq_model_manager.mark_limited(model_name, wait_minutes, error_str[:100])
                continue

            logger.error(f"âŒ Groqã‚¨ãƒ©ãƒ¼ ({model_name}): {e}")
            continue

    logger.error(f"âŒ å…¨Groqãƒ¢ãƒ‡ãƒ«ãŒå¤±æ•—: {last_error}")
    return None

# ==============================================================================
# å¿ƒç†åˆ†æï¼ˆä¿®æ­£ç‰ˆ: DBä¿å­˜å®Ÿè£…ï¼‰
# ==============================================================================
def analyze_user_psychology(user_uuid: str) -> bool:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿ƒç†åˆ†æã‚’å®Ÿè¡Œã—DBã«ä¿å­˜"""
    try:
        with get_db_session() as session:
            history = (
                session.query(ConversationHistory)
                .filter_by(user_uuid=user_uuid, role='user')
                .order_by(ConversationHistory.timestamp.desc())
                .limit(100)
                .all()
            )

            if len(history) < MIN_MESSAGES_FOR_ANALYSIS:
                logger.info(f"åˆ†æã‚¹ã‚­ãƒƒãƒ—: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ä¸è¶³ ({len(history)}/{MIN_MESSAGES_FOR_ANALYSIS})")
                return False

            user = session.query(UserMemory).filter_by(user_uuid=user_uuid).first()
            user_name = user.user_name if user else "Unknown"

            messages_text = "\n".join([f"- {h.content}" for h in reversed(history)])[:2000]
            
            analysis_prompt = f"""ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€Œ{user_name}ã€ã®ç™ºè¨€å±¥æ­´ã‚’åˆ†æã—ã€æ€§æ ¼ç‰¹æ€§ã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ç™ºè¨€å±¥æ­´:
{messages_text}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆæ•°å€¤ã¯0-100ï¼‰:
{{
    "openness": 50,
    "conscientiousness": 50,
    "extraversion": 50,
    "agreeableness": 50,
    "neuroticism": 50,
    "interests": ["èˆˆå‘³1", "èˆˆå‘³2"],
    "favorite_topics": ["è©±é¡Œ1", "è©±é¡Œ2"],
    "conversation_style": "ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼",
    "emotional_tendency": "ãƒã‚¸ãƒ†ã‚£ãƒ–",
    "analysis_summary": "åˆ†æã‚µãƒãƒªãƒ¼",
    "confidence": 70
}}"""

            system = "ã‚ãªãŸã¯å¿ƒç†å­¦ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‹ã‚‰æ€§æ ¼ã‚’åˆ†æã—ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
            
            response_text = call_gemini(system, analysis_prompt, [])
            if not response_text:
                response_text = call_groq(system, analysis_prompt, [], max_tokens=1024)

            if not response_text:
                logger.warning("å¿ƒç†åˆ†æ: AIå¿œç­”ãªã—")
                return False

            json_match = re.search(r'\{[^{}]*\}', response_text, re.DOTALL)
            if not json_match:
                logger.warning(f"å¿ƒç†åˆ†æ: JSONæŠ½å‡ºå¤±æ•—")
                return False

            try:
                analysis = json.loads(json_match.group())
            except json.JSONDecodeError as e:
                logger.warning(f"å¿ƒç†åˆ†æ: JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
                return False

            psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
            if not psych:
                psych = UserPsychology(user_uuid=user_uuid, user_name=user_name)
                session.add(psych)

            psych.openness = analysis.get('openness', 50)
            psych.conscientiousness = analysis.get('conscientiousness', 50)
            psych.extraversion = analysis.get('extraversion', 50)
            psych.agreeableness = analysis.get('agreeableness', 50)
            psych.neuroticism = analysis.get('neuroticism', 50)
            psych.interests = json.dumps(analysis.get('interests', []), ensure_ascii=False)
            psych.favorite_topics = json.dumps(analysis.get('favorite_topics', []), ensure_ascii=False)
            psych.conversation_style = analysis.get('conversation_style', '')
            psych.emotional_tendency = analysis.get('emotional_tendency', '')
            psych.analysis_summary = analysis.get('analysis_summary', '')
            psych.analysis_confidence = analysis.get('confidence', 50)
            psych.total_messages = len(history)
            psych.avg_message_length = sum(len(h.content) for h in history) // len(history)
            psych.last_analyzed = datetime.utcnow()

            logger.info(f"âœ… å¿ƒç†åˆ†æå®Œäº†ãƒ»ä¿å­˜: {user_name} (ä¿¡é ¼åº¦: {psych.analysis_confidence}%)")
            return True

    except Exception as e:
        logger.error(f"âŒ å¿ƒç†åˆ†æã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False


def get_psychology_insight(session, user_uuid: str) -> str:
    """å¿ƒç†åˆ†æã‹ã‚‰ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’å–å¾—"""
    psych = session.query(UserPsychology).filter_by(user_uuid=user_uuid).first()
    if not psych or (psych.analysis_confidence or 0) < 60:
        return ""

    insights = []
    if (psych.extraversion or 50) > 70:
        insights.append("ç¤¾äº¤çš„ãª")
    elif (psych.extraversion or 50) < 30:
        insights.append("å†…å‘çš„ãª")
    
    if (psych.openness or 50) > 70:
        insights.append("å¥½å¥‡å¿ƒæ—ºç››ãª")
    
    if (psych.agreeableness or 50) > 70:
        insights.append("å”èª¿æ€§ã®é«˜ã„")

    try:
        if psych.favorite_topics:
            topics = json.loads(psych.favorite_topics)
            if topics:
                insights.append(f"{'ã€'.join(topics[:2])}ãŒå¥½ããª")
    except (json.JSONDecodeError, TypeError):
        pass

    return "".join(insights)

# ==============================================================================
# å¤©æ°—æƒ…å ±
# ==============================================================================
def get_weather_forecast(location: str) -> str:
    code = LOCATION_CODES.get(location, "130000")
    url = f"https://www.jma.go.jp/bosai/forecast/data/overview_forecast/{code}.json"
    try:
        response = requests.get(url, timeout=SEARCH_TIMEOUT)
        response.raise_for_status()
        data = response.json()
        area = data.get('targetArea', location)
        text = clean_text(data.get('text', ''))
        return f"ä»Šã®{area}ã®å¤©æ°—ã¯ã­ã€ã€Œ{text}ã€ã£ã¦æ„Ÿã˜ã ã‚ˆï¼"
    except requests.Timeout:
        logger.warning("å¤©æ°—API: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        return "ã”ã‚ã‚“ï¼å¤©æ°—æƒ…å ±ã®å–å¾—ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¡ã‚ƒã£ãŸâ€¦"
    except requests.RequestException as e:
        logger.error(f"âŒ å¤©æ°—APIã‚¨ãƒ©ãƒ¼: {e}")
        return "ã”ã‚ã‚“ï¼å¤©æ°—æƒ…å ±ãŒã†ã¾ãå–ã‚Œãªã‹ã£ãŸã¿ãŸã„â€¦"
    except Exception as e:
        logger.error(f"âŒ å¤©æ°—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return "å¤©æ°—æƒ…å ±ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦"

# ==============================================================================
# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯
# ==============================================================================
def background_db_correction(task_id: str, correction_data: Dict):
    """DBã®ä¿®æ­£ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ"""
    result = f"ã€Œ{correction_data['member_name']}ã€ã®æƒ…å ±ä¿®æ­£ã€å¤±æ•—ã—ã¡ã‚ƒã£ãŸâ€¦ã€‚"
    try:
        with get_db_session() as session:
            wiki = session.query(HolomemWiki).filter_by(
                member_name=correction_data['member_name']
            ).first()
            
            if wiki:
                db_field = correction_data.get('db_field')
                if db_field and hasattr(wiki, db_field):
                    setattr(wiki, db_field, correction_data['value'])
                    clear_holomem_cache(correction_data['member_name'])
                    result = f"ãŠã£ã‘ãƒ¼ï¼ã€Œ{correction_data['member_name']}ã€ã®{correction_data['field']}ã‚’æ›´æ–°ã—ã¨ã„ãŸã‚ˆï¼"
                    logger.info(f"âœ… DBä¿®æ­£å®Œäº†: {correction_data['member_name']}.{db_field}")
            else:
                result = f"ã€Œ{correction_data['member_name']}ã€ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚„â€¦"

            task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
            if task:
                task.result = result
                task.status = 'completed'
                task.completed_at = datetime.utcnow()

    except Exception as e:
        logger.error(f"âŒ DBä¿®æ­£ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        try:
            with get_db_session() as session:
                task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
                if task:
                    task.result = result
                    task.status = 'failed'
                    task.completed_at = datetime.utcnow()
        except Exception:
            pass


def scrape_major_search_engines(query: str, num_results: int = 3, site_filter: Optional[str] = None) -> List[Dict]:
    """æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    search_query = f"{query} site:{site_filter}" if site_filter else query
    
    engines = [
        {
            'name': 'Google',
            'url': f"https://www.google.com/search?q={quote_plus(search_query)}&hl=ja&num={num_results+2}",
            'selector': 'div.g',
            'title_sel': 'h3',
            'snippet_sel': 'div.VwiC3b'
        },
        {
            'name': 'Bing',
            'url': f"https://www.bing.com/search?q={quote_plus(search_query)}",
            'selector': 'li.b_algo',
            'title_sel': 'h2',
            'snippet_sel': 'p'
        }
    ]

    for engine in engines:
        try:
            headers = {'User-Agent': random.choice(USER_AGENTS)}
            response = requests.get(engine['url'], headers=headers, timeout=SEARCH_TIMEOUT)
            if response.status_code != 200:
                continue

            soup = BeautifulSoup(response.content, 'html.parser')
            results = []

            for elem in soup.select(engine['selector'])[:num_results]:
                title_elem = elem.select_one(engine['title_sel'])
                snippet_elem = elem.select_one(engine['snippet_sel'])
                if title_elem and snippet_elem:
                    results.append({
                        'title': clean_text(title_elem.text),
                        'snippet': clean_text(snippet_elem.text)
                    })

            if results:
                logger.info(f"âœ… {engine['name']}ã‹ã‚‰{len(results)}ä»¶å–å¾—")
                return results

        except requests.Timeout:
            logger.warning(f"{engine['name']}: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        except Exception as e:
            logger.warning(f"{engine['name']}æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            continue

    return []


def background_deep_search(task_id: str, query_data: Dict):
    """è©³ç´°æ¤œç´¢ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ"""
    query = query_data.get('query', '')
    user_data_dict = query_data.get('user_data', {})
    search_result_text = f"ã€Œ{query}ã€ã«ã¤ã„ã¦èª¿ã¹ãŸã‘ã©ã€è‰¯ã„æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚„â€¦"

    try:
        results = scrape_major_search_engines(query, 5)
        
        if results:
            formatted_info = "ã€æ¤œç´¢çµæœã€‘\n" + "\n".join([
                f"ãƒ»{r['title']}: {r['snippet']}" for r in results
            ])

            user_data = UserData(
                uuid=user_data_dict.get('uuid', ''),
                name=user_data_dict.get('name', 'Guest'),
                interaction_count=user_data_dict.get('interaction_count', 0)
            )

            with get_db_session() as session:
                history = get_conversation_history(session, user_data.uuid)

            search_result_text = generate_ai_response_safe(
                user_data,
                f"{query}ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦",
                history,
                reference_info=formatted_info,
                is_detailed=True
            )

    except Exception as e:
        logger.error(f"âŒ æ¤œç´¢ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

    try:
        with get_db_session() as session:
            task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
            if task:
                task.result = search_result_text
                task.status = 'completed'
                task.completed_at = datetime.utcnow()
    except Exception as e:
        logger.error(f"âŒ ã‚¿ã‚¹ã‚¯æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

# ==============================================================================
# AIå¿œç­”ç”Ÿæˆ
# ==============================================================================
def generate_ai_response(
    user_data: UserData,
    message: str,
    history: List[Dict],
    reference_info: str = "",
    is_detailed: bool = False
) -> str:
    """AIå¿œç­”ã‚’ç”Ÿæˆ"""
    
    with get_db_session() as session:
        personality_context = get_psychology_insight(session, user_data.uuid)

    system_prompt = f"""ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†ã‚®ãƒ£ãƒ«AIã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€Œ{user_data.name}ã€ã¨ä¼šè©±ä¸­ã€‚

# ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š
- ä¸€äººç§°: ã€Œã‚ã¦ãƒã—ã€
- èªå°¾: ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œçš„ãªï¼Ÿã€ã€Œã€œã ã—ã€
- æ€§æ ¼: æ˜ã‚‹ãå…ƒæ°—ã€ã¡ã‚‡ã£ã¨ãŠãƒã‚«ã ã‘ã©æ„›å¬ŒãŒã‚ã‚‹
- çµµæ–‡å­—ã¯æ§ãˆã‚ã«

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å°è±¡: {personality_context if personality_context else 'åˆå¯¾é¢ã¾ãŸã¯åˆ†æä¸­'}

# å‚è€ƒæƒ…å ±:
{reference_info if reference_info else 'ãªã—'}

# æ³¨æ„
- çŸ­ãè¦ªã—ã¿ã‚„ã™ã„è¿”ç­”ã‚’å¿ƒãŒã‘ã¦
- é›£ã—ã„è¨€è‘‰ã¯é¿ã‘ã¦ã€ã‚®ãƒ£ãƒ«ã£ã½ãè¨€ã„æ›ãˆã¦
"""

    response = None

    # 1. Geminiå„ªå…ˆ
    if gemini_model:
        logger.debug("ğŸš€ Geminiä½¿ç”¨")
        response = call_gemini(system_prompt, message, history)

    # 2. Groqãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if not response and groq_client:
        logger.debug("ğŸ¦™ Groqã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
        max_tokens = 1200 if is_detailed else 800
        response = call_groq(system_prompt, message, history, max_tokens=max_tokens)

    if not response:
        logger.error("âŒ ã™ã¹ã¦ã®AIãƒ¢ãƒ‡ãƒ«ãŒå¿œç­”ã«å¤±æ•—")
        raise AIModelException("All AI models failed to respond")

    return response


def generate_ai_response_safe(
    user_data: UserData,
    message: str,
    history: List[Dict],
    **kwargs
) -> str:
    """å®‰å…¨ãªAIå¿œç­”ç”Ÿæˆï¼ˆä¾‹å¤–ã‚’ã‚­ãƒ£ãƒƒãƒï¼‰"""
    try:
        response = generate_ai_response(user_data, message, history, **kwargs)
        if not response or response.strip() == "":
            return "ã†ãƒ¼ã‚“ã€ã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªã„ã‚„â€¦ã‚‚ã†ä¸€å›è¨€ã£ã¦ã¿ã¦ï¼Ÿ"
        return response
    except AIModelException:
        return "ã”ã‚ã‚“ã€ä»Šã‚ã¦ãƒã—ã®é ­ãŒã†ã¾ãåƒã‹ãªã„ã¿ãŸã„â€¦ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã‹ã‚‰ã¾ãŸè©±ã—ã‹ã‘ã¦ï¼Ÿ"
    except Exception as e:
        logger.critical(f"ğŸ”¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¡ã‚ƒã£ãŸâ€¦ã”ã‚ã‚“ã­ï¼"

# ==============================================================================
# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
# ==============================================================================
def find_active_voicevox_url() -> Optional[str]:
    """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªVOICEVOX URLã‚’æ¤œç´¢"""
    urls_to_check = []
    if VOICEVOX_URL_FROM_ENV:
        urls_to_check.append(VOICEVOX_URL_FROM_ENV)
    urls_to_check.extend(VOICEVOX_URLS)

    for url in set(urls_to_check):
        if not url:
            continue
        try:
            resp = requests.get(f"{url}/version", timeout=2)
            if resp.status_code == 200:
                logger.info(f"âœ… VOICEVOXç™ºè¦‹: {url}")
                global_state.active_voicevox_url = url
                return url
        except Exception:
            pass
    return None


def generate_voice_file(text: str, user_uuid: str) -> Optional[str]:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    if not global_state.voicevox_enabled or not global_state.active_voicevox_url:
        return None

    try:
        url = global_state.active_voicevox_url
        text_limited = text[:200]

        query_resp = requests.post(
            f"{url}/audio_query",
            params={"text": text_limited, "speaker": VOICEVOX_SPEAKER_ID},
            timeout=10
        )
        query_resp.raise_for_status()
        query = query_resp.json()

        synth_resp = requests.post(
            f"{url}/synthesis",
            params={"speaker": VOICEVOX_SPEAKER_ID},
            json=query,
            timeout=20
        )
        synth_resp.raise_for_status()

        filename = f"voice_{user_uuid[:8]}_{int(time.time())}.wav"
        filepath = os.path.join(VOICE_DIR, filename)
        
        with open(filepath, 'wb') as f:
            f.write(synth_resp.content)

        logger.debug(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ: {filename}")
        return filename

    except requests.Timeout:
        logger.warning("VOICEVOX: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
    except Exception as e:
        logger.error(f"âŒ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    return None


def cleanup_old_voice_files():
    """å¤ã„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    try:
        now = time.time()
        max_age_seconds = VOICE_FILE_MAX_AGE_HOURS * 3600
        deleted_count = 0

        for filepath in glob.glob(os.path.join(VOICE_DIR, "voice_*.wav")):
            try:
                file_age = now - os.path.getmtime(filepath)
                if file_age > max_age_seconds:
                    os.remove(filepath)
                    deleted_count += 1
            except OSError:
                pass

        if deleted_count > 0:
            logger.info(f"ğŸ§¹ å¤ã„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«{deleted_count}ä»¶ã‚’å‰Šé™¤")

    except Exception as e:
        logger.error(f"âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

# ==============================================================================
# Flask ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ==============================================================================
@app.route('/health', methods=['GET'])
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return create_json_response({
        'status': 'ok',
        'timestamp': datetime.utcnow().isoformat(),
        'gemini': gemini_model is not None,
        'groq': groq_client is not None,
        'voicevox': global_state.voicevox_enabled
    })


@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    """ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        data = request.json
        if not data or 'uuid' not in data or 'message' not in data:
            return Response(
                "å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¶³|",
                mimetype='text/plain; charset=utf-8',
                status=400
            )

        user_uuid = sanitize_user_input(data['uuid'])
        user_name = sanitize_user_input(data.get('name', 'Guest'))
        message = sanitize_user_input(data['message'])
        generate_voice_flag = data.get('voice', False)

        if not chat_rate_limiter.is_allowed(user_uuid):
            return Response(
                "ã¡ã‚‡ã£ã¨å¾…ã£ã¦ï¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ã‚Šã™ãï½ï¼|",
                mimetype='text/plain; charset=utf-8',
                status=429
            )

        # === ç‰¹æ®Šã‚³ãƒãƒ³ãƒ‰: æ®‹ãƒˆãƒ¼ã‚¯ãƒ³ ===
        if message.strip() == "æ®‹ãƒˆãƒ¼ã‚¯ãƒ³":
            status_msg = "ã€AIã‚¨ãƒ³ã‚¸ãƒ³çŠ¶æ…‹ã€‘\n"
            status_msg += f"ğŸ¦ Gemini: {'ç¨¼åƒä¸­' if gemini_model else 'åœæ­¢ä¸­'}\n"
            status_msg += groq_model_manager.get_status_report()
            
            available = groq_model_manager.get_available_models()
            if not available and not gemini_model:
                status_msg += "\n\nâš ï¸ å…¨ã‚¨ãƒ³ã‚¸ãƒ³åœæ­¢ä¸­â€¦ã¡ã‚‡ã£ã¨ä¼‘æ†©ã•ã›ã¦â€¦"
            
            return Response(
                f"{status_msg}|",
                mimetype='text/plain; charset=utf-8',
                status=200
            )

        # === é€šå¸¸ä¼šè©±å‡¦ç† ===
        ai_text = ""
        is_task_started = False

        with get_db_session() as session:
            user_data = get_or_create_user(session, user_uuid, user_name)
            history = get_conversation_history(session, user_uuid)

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
            session.add(ConversationHistory(
                user_uuid=user_uuid,
                role='user',
                content=message
            ))

            # DBä¿®æ­£ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
            correction = detect_db_correction_request(message)
            if correction:
                task_id = f"db_fix_{user_uuid}_{int(time.time())}"
                task = BackgroundTask(
                    task_id=task_id,
                    user_uuid=user_uuid,
                    task_type='db_correction',
                    query=json.dumps(correction, ensure_ascii=False)
                )
                session.add(task)
                background_executor.submit(background_db_correction, task_id, correction)
                ai_text = f"ã¾ã˜ï¼ï¼Ÿã€Œ{correction['member_name']}ã€ã®æƒ…å ±ã€ç›´ã—ã¨ãã­ï¼"
                is_task_started = True

            # æ™‚åˆ»ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            if not ai_text and is_time_request(message):
                ai_text = get_japan_time()

            # å¤©æ°—ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            if not ai_text and is_weather_request(message):
                ai_text = get_weather_forecast(extract_location(message))

            # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            if not ai_text and is_explicit_search_request(message):
                task_id = f"search_{user_uuid}_{int(time.time())}"
                query_data = {
                    'query': message,
                    'user_data': {
                        'uuid': user_data.uuid,
                        'name': user_data.name,
                        'interaction_count': user_data.interaction_count
                    }
                }
                task = BackgroundTask(
                    task_id=task_id,
                    user_uuid=user_uuid,
                    task_type='search',
                    query=json.dumps(query_data, ensure_ascii=False)
                )
                session.add(task)
                background_executor.submit(background_deep_search, task_id, query_data)
                ai_text = "ã‚ªãƒƒã‚±ãƒ¼ï¼ã¡ã‚‡ã£ã¨ã‚°ã‚°ã£ã¦ãã‚‹ã‹ã‚‰å¾…ã£ã¦ã¦ï¼"
                is_task_started = True

            # é€šå¸¸AIå¿œç­”
            if not ai_text:
                ai_text = generate_ai_response_safe(user_data, message, history)

            # AIå¿œç­”ã‚’ä¿å­˜ï¼ˆã‚¿ã‚¹ã‚¯é–‹å§‹æ™‚ä»¥å¤–ï¼‰
            if not is_task_started:
                session.add(ConversationHistory(
                    user_uuid=user_uuid,
                    role='assistant',
                    content=ai_text
                ))

            # å®šæœŸçš„ãªå¿ƒç†åˆ†æï¼ˆ100å›ã”ã¨ï¼‰
            if user_data.interaction_count % 100 == 0:
                background_executor.submit(analyze_user_psychology, user_uuid)

        # å¿œç­”æº–å‚™
        response_text = limit_text_for_sl(ai_text)
        voice_url = ""

        if generate_voice_flag and global_state.voicevox_enabled and not is_task_started:
            voice_filename = generate_voice_file(response_text, user_uuid)
            if voice_filename:
                voice_url = f"{SERVER_URL}/play/{voice_filename}"

        return Response(
            f"{response_text}|{voice_url}",
            mimetype='text/plain; charset=utf-8',
            status=200
        )

    except DatabaseException as e:
        logger.error(f"DBã‚¨ãƒ©ãƒ¼: {e}")
        return Response(
            "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦|",
            mimetype='text/plain; charset=utf-8',
            status=500
        )
    except Exception as e:
        logger.critical(f"ğŸ”¥ è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return Response(
            "ã”ã‚ã‚“ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼â€¦|",
            mimetype='text/plain; charset=utf-8',
            status=500
        )


@app.route('/check_task', methods=['POST'])
def check_task_endpoint():
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã®å®Œäº†ç¢ºèª"""
    try:
        data = request.json
        if not data or 'uuid' not in data:
            return create_json_response({'status': 'error', 'message': 'uuid required'}, 400)

        user_uuid = sanitize_user_input(data['uuid'])

        with get_db_session() as session:
            task = (
                session.query(BackgroundTask)
                .filter(
                    BackgroundTask.user_uuid == user_uuid,
                    BackgroundTask.status == 'completed'
                )
                .order_by(BackgroundTask.completed_at.desc())
                .first()
            )

            if task:
                result = task.result or ""
                session.delete(task)
                
                # çµæœã‚’ä¼šè©±å±¥æ­´ã«ä¿å­˜
                session.add(ConversationHistory(
                    user_uuid=user_uuid,
                    role='assistant',
                    content=result
                ))

                return create_json_response({
                    'status': 'completed',
                    'response': f"{limit_text_for_sl(result)}|"
                })

        return create_json_response({'status': 'no_tasks'})

    except DatabaseException as e:
        logger.error(f"ã‚¿ã‚¹ã‚¯ç¢ºèªDBã‚¨ãƒ©ãƒ¼: {e}")
        return create_json_response({'status': 'error', 'message': 'Database error'}, 500)
    except Exception as e:
        logger.error(f"ã‚¿ã‚¹ã‚¯ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return create_json_response({'status': 'error'}, 500)


@app.route('/play/<filename>', methods=['GET'])
def play_voice(filename: str):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å†ç”Ÿ"""
    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–ï¼‰
    if not re.match(r'^voice_[a-zA-Z0-9_]+\.wav
            , filename):
        return Response("Invalid filename", status=400)
    
    filepath = os.path.join(VOICE_DIR, filename)
    if not os.path.exists(filepath):
        return Response("File not found", status=404)
    
    return send_from_directory(VOICE_DIR, filename)


@app.route('/holomem/<member_name>', methods=['GET'])
def get_holomem_info(member_name: str):
    """ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±å–å¾—API"""
    try:
        member_name = sanitize_user_input(member_name, max_length=50)
        info = get_holomem_info_cached(member_name)
        
        if info:
            return create_json_response({'status': 'success', 'data': info})
        else:
            return create_json_response({'status': 'not_found'}, 404)
    except Exception as e:
        logger.error(f"ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return create_json_response({'status': 'error'}, 500)


@app.route('/stats', methods=['GET'])
def get_stats():
    """çµ±è¨ˆæƒ…å ±å–å¾—"""
    try:
        with get_db_session() as session:
            user_count = session.query(UserMemory).count()
            message_count = session.query(ConversationHistory).count()
            task_pending = session.query(BackgroundTask).filter_by(status='pending').count()

        return create_json_response({
            'status': 'ok',
            'users': user_count,
            'messages': message_count,
            'pending_tasks': task_pending,
            'gemini_active': gemini_model is not None,
            'groq_active': groq_client is not None,
            'groq_available_models': len(groq_model_manager.get_available_models()),
            'voicevox_active': global_state.voicevox_enabled
        })
    except Exception as e:
        logger.error(f"çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return create_json_response({'status': 'error'}, 500)

# ==============================================================================
# å®šæœŸã‚¿ã‚¹ã‚¯
# ==============================================================================
def run_scheduled_tasks():
    """å®šæœŸã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰"""
    while True:
        try:
            schedule.run_pending()
            time.sleep(60)
        except Exception as e:
            logger.error(f"å®šæœŸã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            time.sleep(60)


def setup_scheduled_tasks():
    """å®šæœŸã‚¿ã‚¹ã‚¯ã®è¨­å®š"""
    # 1æ™‚é–“ã”ã¨ã«å¤ã„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    schedule.every(1).hours.do(cleanup_old_voice_files)
    
    # 6æ™‚é–“ã”ã¨ã«ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    schedule.every(6).hours.do(chat_rate_limiter.cleanup_old_entries)
    
    # å®šæœŸã‚¿ã‚¹ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
    task_thread = threading.Thread(target=run_scheduled_tasks, daemon=True)
    task_thread.start()
    logger.info("ğŸ“… å®šæœŸã‚¿ã‚¹ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹")

# ==============================================================================
# åˆæœŸåŒ– & ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
# ==============================================================================
def initialize_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
    global engine, Session
    
    try:
        if DATABASE_URL.startswith('sqlite'):
            engine = create_engine(
                DATABASE_URL,
                pool_pre_ping=True,
                connect_args={'check_same_thread': False}
            )
        else:
            engine = create_engine(
                DATABASE_URL,
                pool_pre_ping=True,
                pool_size=5,
                max_overflow=10,
                pool_recycle=3600
            )
        
        Base.metadata.create_all(engine)
        Session = sessionmaker(bind=engine)
        logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")
        return True
    except Exception as e:
        logger.critical(f"ğŸ”¥ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å¤±æ•—: {e}", exc_info=True)
        return False


def initialize_ai_clients():
    """AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–"""
    global groq_client, gemini_model
    
    # GroqåˆæœŸåŒ–
    if GROQ_API_KEY:
        try:
            groq_client = Groq(api_key=GROQ_API_KEY)
            logger.info("âœ… Groqã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            logger.error(f"âŒ GroqåˆæœŸåŒ–å¤±æ•—: {e}")
            groq_client = None
    else:
        logger.warning("âš ï¸ GROQ_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    # GeminiåˆæœŸåŒ–
    if GEMINI_API_KEY:
        try:
            genai.configure(api_key=GEMINI_API_KEY)
            gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')
            logger.info("âœ… Geminiãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            logger.error(f"âŒ GeminiåˆæœŸåŒ–å¤±æ•—: {e}")
            gemini_model = None
    else:
        logger.warning("âš ï¸ GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")


def initialize_voicevox():
    """VOICEVOXåˆæœŸåŒ–"""
    url = find_active_voicevox_url()
    if url:
        global_state.voicevox_enabled = True
        logger.info(f"âœ… VOICEVOXæœ‰åŠ¹åŒ–: {url}")
    else:
        logger.info("â„¹ï¸ VOICEVOXã¯åˆ©ç”¨ä¸å¯")


def initialize_app():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã®åˆæœŸåŒ–"""
    logger.info("=" * 60)
    logger.info("ğŸ”§ ã‚‚ã¡ã“AI v31.0 åˆæœŸåŒ–é–‹å§‹")
    logger.info("=" * 60)

    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
    if not initialize_database():
        logger.critical("ğŸ”¥ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å¤±æ•— - èµ·å‹•ã‚’ä¸­æ­¢ã—ã¾ã™")
        return False

    # 2. AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
    initialize_ai_clients()

    # 3. VOICEVOX
    initialize_voicevox()

    # 4. å®šæœŸã‚¿ã‚¹ã‚¯
    setup_scheduled_tasks()

    # 5. èµ·å‹•æ™‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    cleanup_old_voice_files()

    # çŠ¶æ…‹ã‚µãƒãƒªãƒ¼
    logger.info("=" * 60)
    logger.info("ğŸ“Š åˆæœŸåŒ–å®Œäº†ã‚µãƒãƒªãƒ¼:")
    logger.info(f"  - Database: âœ…")
    logger.info(f"  - Gemini: {'âœ…' if gemini_model else 'âŒ'}")
    logger.info(f"  - Groq: {'âœ…' if groq_client else 'âŒ'}")
    logger.info(f"  - VOICEVOX: {'âœ…' if global_state.voicevox_enabled else 'âŒ'}")
    logger.info("=" * 60)

    return True


def cleanup_on_exit():
    """çµ‚äº†æ™‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    logger.info("ğŸ›‘ ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³å‡¦ç†é–‹å§‹...")
    
    try:
        background_executor.shutdown(wait=False)
        logger.info("  - ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿åœæ­¢")
    except Exception as e:
        logger.error(f"ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")

    try:
        if engine:
            engine.dispose()
            logger.info("  - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¯ãƒ­ãƒ¼ã‚º")
    except Exception as e:
        logger.error(f"DBæ¥ç¶šã‚¯ãƒ­ãƒ¼ã‚ºã‚¨ãƒ©ãƒ¼: {e}")

    logger.info("âœ… ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³å®Œäº†")


# çµ‚äº†æ™‚ãƒãƒ³ãƒ‰ãƒ©ç™»éŒ²
atexit.register(cleanup_on_exit)

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–å®Ÿè¡Œ
initialize_app()

# ==============================================================================
# ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
# ==============================================================================
if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug_mode = os.environ.get('DEBUG', 'false').lower() == 'true'
    
    logger.info(f"ğŸš€ ã‚µãƒ¼ãƒãƒ¼èµ·å‹•: port={port}, debug={debug_mode}")
    app.run(host='0.0.0.0', port=port, debug=debug_mode)
            
