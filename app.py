import sys
import os
import requests
import logging
import time
import threading
import json
import re
import sqlite3
import random
import uuid
import hashlib
from datetime import datetime, timedelta, timezone

# å‹ãƒ’ãƒ³ãƒˆç”¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼å¯¾ç­–ä»˜ãï¼‰
try:
    from typing import Union, Dict, Any, List, Optional
except ImportError:
    # å‹ãƒ’ãƒ³ãƒˆãŒä½¿ãˆãªã„ç’°å¢ƒç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    Dict = dict
    Any = object
    List = list
    Union = object
    Optional = object

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from sqlalchemy import create_engine, Column, String, DateTime, Integer, Index, Text, Boolean, inspect, text
from sqlalchemy.orm import declarative_base, sessionmaker
from urllib.parse import quote_plus, urljoin
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor
import asyncio
from threading import Lock
import schedule

# --- åŸºæœ¬è¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# â˜… ä¿®æ­£1: ãƒœã‚¤ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å®‰å…¨ã«ä½œæˆ
VOICE_DIR = '/tmp/voices'
try:
    os.makedirs(VOICE_DIR, exist_ok=True)
    logger.info(f"âœ… Voice directory created: {VOICE_DIR}")
except Exception as e:
    logger.warning(f"âš ï¸ Voice directory creation failed: {e}")
    VOICE_DIR = '/tmp'

SERVER_URL = "https://slautofriendbot.onrender.com"
background_executor = ThreadPoolExecutor(max_workers=5)

# --- ç§˜å¯†æƒ…å ±/ç’°å¢ƒå¤‰æ•° èª­ã¿è¾¼ã¿ ---
def get_secret(name):
    """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ç§˜å¯†æƒ…å ±ã‚’å–å¾—"""
    return os.environ.get(name)

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ï¼ˆè©³ç´°ãƒ­ã‚°ä»˜ãï¼‰
DATABASE_URL = get_secret('DATABASE_URL') or 'sqlite:///./test.db'

# GROQ_API_KEY ã®è©³ç´°è¨ºæ–­
GROQ_API_KEY = get_secret('GROQ_API_KEY')
logger.info("ğŸ” GROQ_API_KEY è¨ºæ–­:")
logger.info(f"   - ç’°å¢ƒå¤‰æ•°å­˜åœ¨: {'ã¯ã„' if 'GROQ_API_KEY' in os.environ else 'ã„ã„ãˆ'}")
if GROQ_API_KEY:
    logger.info(f"   - ã‚­ãƒ¼é•·: {len(GROQ_API_KEY)} æ–‡å­—")
    logger.info(f"   - å…ˆé ­: {GROQ_API_KEY[:10]}... (ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ä¸€éƒ¨ã®ã¿è¡¨ç¤º)")
    logger.info(f"   - æœ«å°¾ãƒã‚§ãƒƒã‚¯: ...{GROQ_API_KEY[-4:]}")
else:
    logger.warning("   - âš ï¸ GROQ_API_KEYãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼")
    GROQ_API_KEY = 'DUMMY_GROQ_KEY'

VOICEVOX_URL_FROM_ENV = get_secret('VOICEVOX_URL')

# --- Groqã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆæ”¹å–„ç‰ˆï¼‰ ---
groq_client = None
try:
    from groq import Groq
    
    if not GROQ_API_KEY or GROQ_API_KEY == 'DUMMY_GROQ_KEY':
        logger.warning("âš ï¸ GROQ_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ - AIæ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™")
        logger.warning("âš ï¸ Renderã® Environment Variables ã« GROQ_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    elif len(GROQ_API_KEY) < 20:
        logger.error(f"âŒ GROQ_API_KEYãŒçŸ­ã™ãã¾ã™ (é•·ã•: {len(GROQ_API_KEY)})")
        logger.error("âŒ æ­£ã—ã„APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    else:
        # APIã‚­ãƒ¼ã®å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
        GROQ_API_KEY = GROQ_API_KEY.strip()
        
        groq_client = Groq(api_key=GROQ_API_KEY)
        logger.info("âœ… Groq client initialized successfully")
        logger.info(f"âœ… APIã‚­ãƒ¼æ¤œè¨¼: {GROQ_API_KEY[:10]}...")
        
        # æ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        try:
            # ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            test_completion = groq_client.chat.completions.create(
                messages=[{"role": "user", "content": "test"}],
                model="llama-3.1-8b-instant",
                max_tokens=5
            )
            logger.info("âœ… Groq API æ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
        except Exception as test_error:
            logger.error(f"âŒ Groq API æ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {test_error}")
            groq_client = None
            
except ImportError as e:
    groq_client = None
    logger.error(f"âŒ Groqãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—: {e}")
    logger.error("âŒ requirements.txt ã« 'groq' ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
except Exception as e:
    groq_client = None
    logger.error(f"âŒ Groq client initialization failed: {e}")
    logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}: {str(e)}")

# DATABASE_URLæ¤œè¨¼
if not DATABASE_URL:
    logger.critical("FATAL: DATABASE_URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    sys.exit(1)

# PostgreSQLã®å ´åˆã¯ãƒ›ã‚¹ãƒˆåã‚’ãƒ­ã‚°å‡ºåŠ›
if 'postgresql' in DATABASE_URL:
    try:
        host_part = DATABASE_URL.split('@')[1].split('/')[0]
        logger.info(f"ğŸ“Š PostgreSQLæ¥ç¶šå…ˆ: {host_part}")
    except:
        logger.warning("âš ï¸ DATABASE_URLã®å½¢å¼ã‚’ç¢ºèªã§ãã¾ã›ã‚“")

if not groq_client:
    logger.warning("è­¦å‘Š: Groq APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€AIæ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")
VOICEVOX_ENABLED = True


# --- Flask & ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ– ---
app = Flask(__name__)
CORS(app)

# â˜… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ 
def create_db_engine_with_retry(max_retries=5, retry_delay=5):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ãƒªãƒˆãƒ©ã‚¤ä»˜ãã§ä½œæˆ"""
    from sqlalchemy.exc import OperationalError
    
    for attempt in range(max_retries):
        try:
            logger.info(f"ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šè©¦è¡Œ {attempt + 1}/{max_retries}...")
            
            # PostgreSQLã®æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
            connect_args = {'check_same_thread': False} if 'sqlite' in DATABASE_URL else {'connect_timeout': 10}
            
            engine = create_engine(
                DATABASE_URL,
                pool_pre_ping=True,           # æ¥ç¶šå‰ã«pingãƒ†ã‚¹ãƒˆ
                pool_recycle=300,             # 5åˆ†ã”ã¨ã«æ¥ç¶šã‚’ãƒªã‚µã‚¤ã‚¯ãƒ«
                connect_args=connect_args
            )
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            with engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ")
            return engine
            
        except OperationalError as e:
            if attempt < max_retries - 1:
                logger.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå¤±æ•— (è©¦è¡Œ {attempt + 1}/{max_retries}): {e}")
                logger.info(f"â³ {retry_delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                time.sleep(retry_delay)
            else:
                logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒ{max_retries}å›å¤±æ•—ã—ã¾ã—ãŸ")
                logger.error(f"DATABASE_URL: {DATABASE_URL[:50]}..." if len(DATABASE_URL) > 50 else DATABASE_URL)
                raise
        except Exception as e:
            logger.error(f"âŒ äºˆæœŸã—ãªã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            raise

try:
    engine = create_db_engine_with_retry()
except Exception as e:
    logger.critical(f"ğŸ”¥ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å¤±æ•—: {e}")
    logger.critical("Renderç’°å¢ƒã®å ´åˆã¯ã€Internal Database URLã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
    sys.exit(1)

Base = declarative_base()

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« ---
class UserMemory(Base):
    __tablename__ = 'user_memories'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), unique=True, nullable=False)
    user_name = Column(String(255), nullable=False)
    interaction_count = Column(Integer, default=0)
    last_interaction = Column(DateTime, default=datetime.utcnow)

class ConversationHistory(Base):
    __tablename__ = 'conversation_history'
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_uuid = Column(String(255), nullable=False, index=True)
    role = Column(String(10), nullable=False)
    content = Column(Text, nullable=False)
    timestamp = Column(DateTime, default=datetime.utcnow, index=True)

class HololiveNews(Base):
    __tablename__ = 'hololive_news'
    id = Column(Integer, primary_key=True)
    title = Column(String(500), nullable=False)
    content = Column(Text, nullable=False)
    url = Column(String(1000))
    published_date = Column(DateTime, default=datetime.utcnow)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)
    news_hash = Column(String(100), unique=True)

class BackgroundTask(Base):
    __tablename__ = 'background_tasks'
    id = Column(Integer, primary_key=True)
    task_id = Column(String(255), unique=True, nullable=False)
    user_uuid = Column(String(255), nullable=False)
    task_type = Column(String(50), nullable=False)
    query = Column(Text, nullable=False)
    result = Column(Text)
    status = Column(String(20), default='pending')
    created_at = Column(DateTime, default=datetime.utcnow, index=True)
    completed_at = Column(DateTime)

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½1: å°‚é–€ã‚µã‚¤ãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒ†ãƒ¼ãƒ–ãƒ«è¿½åŠ  â˜…â˜…â˜…
class SpecializedNews(Base):
    __tablename__ = 'specialized_news'
    id = Column(Integer, primary_key=True)
    site_name = Column(String(100), nullable=False, index=True)
    title = Column(String(500), nullable=False)
    content = Column(Text, nullable=False)
    url = Column(String(1000))
    published_date = Column(DateTime, default=datetime.utcnow)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)
    news_hash = Column(String(100), unique=True)

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½2: ãƒ›ãƒ­ãƒ¡ãƒ³Wikiã®ãƒ†ãƒ¼ãƒ–ãƒ«è¿½åŠ  â˜…â˜…â˜…
class HolomemWiki(Base):
    __tablename__ = 'holomem_wiki'
    id = Column(Integer, primary_key=True)
    member_name = Column(String(100), nullable=False, unique=True, index=True)
    description = Column(Text)
    debut_date = Column(String(100))
    generation = Column(String(100))
    tags = Column(Text)  # JSONå½¢å¼ã§ã‚¿ã‚°ã‚’ä¿å­˜
    last_updated = Column(DateTime, default=datetime.utcnow)

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½3: å‹ã ã¡ç™»éŒ²ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ãƒ¼ãƒ–ãƒ«è¿½åŠ  â˜…â˜…â˜…
class FriendRegistration(Base):
    __tablename__ = 'friend_registrations'
    id = Column(Integer, primary_key=True)
    user_uuid = Column(String(255), nullable=False, index=True)
    friend_uuid = Column(String(255), nullable=False)
    friend_name = Column(String(255), nullable=False)
    registered_at = Column(DateTime, default=datetime.utcnow)
    relationship_note = Column(Text)  # é–¢ä¿‚æ€§ã®ãƒ¡ãƒ¢

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
try:
    Base.metadata.create_all(engine)
    Session = sessionmaker(bind=engine)
    logger.info("âœ… Database tables created successfully")
except Exception as e:
    logger.error(f"âŒ Database table creation failed: {e}")
    raise

def add_news_hash_column_if_not_exists(engine):
    """news_hashã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è¿½åŠ """
    try:
        inspector = inspect(engine)
        columns = [col['name'] for col in inspector.get_columns('hololive_news')]
        if 'news_hash' not in columns:
            with engine.connect() as con:
                trans = con.begin()
                try:
                    con.execute(text("ALTER TABLE hololive_news ADD COLUMN news_hash VARCHAR(100) UNIQUE;"))
                    trans.commit()
                    logger.info("âœ… news_hash column added successfully")
                except Exception as e:
                    trans.rollback()
                    logger.warning(f"âš ï¸ news_hash column add failed: {e}")
        else:
            logger.info("âœ… news_hash column already exists")
    except Exception as e:
        logger.warning(f"âš ï¸ Column check failed: {e}")

add_news_hash_column_if_not_exists(engine)

# --- å°‚é–€ã‚µã‚¤ãƒˆ & ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–è¨­å®š ---
SPECIALIZED_SITES = {
    'Blender': {
        'base_url': 'https://docs.blender.org/manual/ja/latest/',
        'keywords': ['Blender', 'ãƒ–ãƒ¬ãƒ³ãƒ€ãƒ¼']
    },
    'CGãƒ‹ãƒ¥ãƒ¼ã‚¹': {
        'base_url': 'https://modelinghappy.com/',
        'keywords': ['CGãƒ‹ãƒ¥ãƒ¼ã‚¹', '3DCG', 'CG']
    },
    'è„³ç§‘å­¦ãƒ»å¿ƒç†å­¦': {
        'base_url': 'https://nazology.kusuguru.co.jp/',
        'keywords': ['è„³ç§‘å­¦', 'å¿ƒç†å­¦']
    },
    'ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•': {
        'base_url': 'https://community.secondlife.com/news/',
        'keywords': ['ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ•', 'Second Life', 'SL']
    }
}

HOLOLIVE_NEWS_URL = "https://hololive-tsuushin.com/category/holonews/"
HOLOMEM_KEYWORDS = [
    'ã¨ãã®ãã‚‰', 'ãƒ­ãƒœå­ã•ã‚“', 'ã•ãã‚‰ã¿ã“', 'æ˜Ÿè¡—ã™ã„ã›ã„', 'AZKi', 'å¤œç©ºãƒ¡ãƒ«',
    'ã‚¢ã‚­ãƒ»ãƒ­ãƒ¼ã‚¼ãƒ³ã‚¿ãƒ¼ãƒ«', 'èµ¤äº•ã¯ã‚ã¨', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å¤è‰²ã¾ã¤ã‚Š', 'æ¹Šã‚ãã‚',
    'ç´«å’²ã‚·ã‚ªãƒ³', 'ç™¾é¬¼ã‚ã‚„ã‚', 'ç™’æœˆã¡ã‚‡ã“', 'å¤§ç©ºã‚¹ãƒãƒ«', 'å¤§ç¥ãƒŸã‚ª', 'çŒ«åˆãŠã‹ã‚†',
    'æˆŒç¥ã“ã‚ã­', 'å…ç”°ãºã“ã‚‰', 'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢', 'ç™½éŠ€ãƒã‚¨ãƒ«', 'å®é˜ãƒãƒªãƒ³', 'å¤©éŸ³ã‹ãªãŸ',
    'è§’å·»ã‚ãŸã‚', 'å¸¸é—‡ãƒˆãƒ¯', 'å§«æ£®ãƒ«ãƒ¼ãƒŠ', 'é›ªèŠ±ãƒ©ãƒŸã‚£', 'æ¡ƒéˆ´ã­ã­', 'ç…ç™½ã¼ãŸã‚“',
    'å°¾ä¸¸ãƒãƒ«ã‚«', 'ãƒ©ãƒ—ãƒ©ã‚¹ãƒ»ãƒ€ãƒ¼ã‚¯ãƒã‚¹', 'é·¹å¶ºãƒ«ã‚¤', 'åšè¡£ã“ã‚ˆã‚Š', 'æ²™èŠ±å‰ã‚¯ãƒ­ãƒ±',
    'é¢¨çœŸã„ã‚ã¯', 'æ£®ã‚«ãƒªã‚ªãƒš', 'å°é³¥éŠã‚­ã‚¢ãƒ©', 'ä¸€ä¼Šé‚£å°“æ –', 'ãŒã†ã‚‹ãƒ»ãã‚‰',
    'ãƒ¯ãƒˆã‚½ãƒ³ãƒ»ã‚¢ãƒ¡ãƒªã‚¢', 'IRyS', 'ã‚»ãƒ¬ã‚¹ãƒ»ãƒ•ã‚¡ã‚¦ãƒŠ', 'ã‚ªãƒ¼ãƒ­ãƒ»ã‚¯ãƒ­ãƒ‹ãƒ¼', 'ä¸ƒè©©ãƒ ãƒ¡ã‚¤',
    'ãƒã‚³ã‚¹ãƒ»ãƒ™ãƒ¼ãƒ«ã‚º', 'ã‚·ã‚ªãƒªãƒ»ãƒãƒ´ã‚§ãƒ©', 'å¤çŸ³ãƒ“ã‚¸ãƒ¥ãƒ¼', 'ãƒãƒªãƒƒã‚µãƒ»ãƒ¬ã‚¤ãƒ´ãƒ³ã‚¯ãƒ­ãƒ•ãƒˆ',
    'ãƒ•ãƒ¯ãƒ¯ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ãƒ¢ã‚³ã‚³ãƒ»ã‚¢ãƒ“ã‚¹ã‚¬ãƒ¼ãƒ‰', 'ã‚¢ãƒ¦ãƒ³ãƒ€ãƒ»ãƒªã‚¹', 'ãƒ ãƒ¼ãƒŠãƒ»ãƒ›ã‚·ãƒãƒ´ã‚¡',
    'ã‚¢ã‚¤ãƒ©ãƒ‹ãƒ»ã‚¤ã‚ªãƒ•ã‚£ãƒ•ãƒ†ã‚£ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¤ã‚¸ãƒ¼ãƒ»ã‚ªãƒªãƒ¼', 'ã‚¢ãƒ¼ãƒ‹ãƒ£ãƒ»ãƒ¡ãƒ«ãƒ•ã‚£ãƒƒã‚µ',
    'ãƒ‘ãƒ´ã‚©ãƒªã‚¢ãƒ»ãƒ¬ã‚¤ãƒ', 'ç«å¨é’', 'éŸ³ä¹ƒç€¬å¥', 'ä¸€æ¡è‰ã€…è¯', 'å„’çƒé¢¨äº­ã‚‰ã§ã‚“',
    'è½Ÿã¯ã˜ã‚', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–', 'ãƒ›ãƒ­ãƒ¡ãƒ³', 'hololive', 'YAGOO'
]

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½: VOICEVOXã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè©±è€…ã‚’ã€Œã‚‚ã¡ã“ã€é¢¨ã«è¨­å®š â˜…â˜…â˜…
VOICEVOX_SPEAKER_ID = 20  # ã‚‚ã¡å­ã•ã‚“ãƒãƒ¼ãƒãƒ«

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
def clean_text(text):
    """HTMLã‚¿ã‚°ã‚„ä½™åˆ†ãªç©ºç™½ã‚’é™¤å»"""
    if not text:
        return ""
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def get_japan_time():
    """æ—¥æœ¬æ™‚é–“ã‚’å–å¾—"""
    jst = timezone(timedelta(hours=9))
    now = datetime.now(jst)
    return f"ä»Šã¯{now.year}å¹´{now.month}æœˆ{now.day}æ—¥ã®{now.hour}æ™‚{now.minute}åˆ†ã ã‚ˆï¼"

def create_news_hash(title, content):
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’ç”Ÿæˆ"""
    hash_string = f"{title}{content[:100]}"
    return hashlib.md5(hash_string.encode('utf-8')).hexdigest()

def is_time_request(message):
    """æ™‚é–“ã«é–¢ã™ã‚‹è³ªå•ã‹ã©ã†ã‹åˆ¤å®š"""
    time_keywords = ['ä»Šä½•æ™‚', 'æ™‚é–“', 'æ™‚åˆ»', 'ä½•æ™‚', 'ãªã‚“ã˜']
    return any(keyword in message for keyword in time_keywords)

def is_weather_request(message):
    """å¤©æ°—ã«é–¢ã™ã‚‹è³ªå•ã‹ã©ã†ã‹åˆ¤å®š"""
    weather_keywords = ['å¤©æ°—', 'ã¦ã‚“ã', 'æ°—æ¸©', 'é›¨', 'æ™´ã‚Œ', 'æ›‡ã‚Š', 'é›ª']
    return any(keyword in message for keyword in weather_keywords)

def is_hololive_request(message):
    """ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é–¢é€£ã®è³ªå•ã‹ã©ã†ã‹åˆ¤å®š"""
    return any(keyword in message for keyword in HOLOMEM_KEYWORDS)

def is_recommendation_request(message):
    """ãŠã™ã™ã‚ã«é–¢ã™ã‚‹è³ªå•ã‹ã©ã†ã‹åˆ¤å®š"""
    recommend_keywords = ['ãŠã™ã™ã‚', 'ã‚ªã‚¹ã‚¹ãƒ¡', 'æ¨è–¦', 'ç´¹ä»‹ã—ã¦']
    return any(keyword in message for keyword in recommend_keywords)

def detect_specialized_topic(message):
    """å°‚é–€åˆ†é‡ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’æ¤œå‡º"""
    # å®Œå…¨ä¸€è‡´ã¾ãŸã¯éƒ¨åˆ†ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯
    message_lower = message.lower()
    
    for topic, config in SPECIALIZED_SITES.items():
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å®Œå…¨ä¸€è‡´ã¾ãŸã¯éƒ¨åˆ†ä¸€è‡´
        for keyword in config['keywords']:
            keyword_lower = keyword.lower()
            # ã€ŒCGãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ã®ã‚ˆã†ãªçŸ­ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯å®Œå…¨ä¸€è‡´ã‚’å„ªå…ˆ
            if len(keyword) <= 5:
                if keyword in message or keyword_lower in message_lower:
                    return topic
            else:
                if keyword in message:
                    return topic
    return None

def is_detailed_request(message):
    """è©³ç´°ãªèª¬æ˜ã‚’æ±‚ã‚ã¦ã„ã‚‹ã‹ã©ã†ã‹åˆ¤å®š"""
    detailed_keywords = [
        'è©³ã—ã', 'è©³ç´°', 'ãã‚ã—ã', 'æ•™ãˆã¦', 'èª¬æ˜ã—ã¦', 'è§£èª¬ã—ã¦',
        'ã©ã†ã„ã†', 'ãªãœ', 'ã©ã†ã—ã¦', 'ç†ç”±', 'åŸå› ', 'ã—ã£ã‹ã‚Š',
        'ã¡ã‚ƒã‚“ã¨', 'ãã¡ã‚“ã¨', 'å…·ä½“çš„ã«'
    ]
    return any(keyword in message for keyword in detailed_keywords)

def should_search(message):
    """æ¤œç´¢ãŒå¿…è¦ã‹ã©ã†ã‹åˆ¤å®š"""
    # å°‚é–€åˆ†é‡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚Œã°æ¤œç´¢
    if detect_specialized_topic(message):
        return True
    
    # ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é–¢é€£
    if is_hololive_request(message):
        # ãŸã ã—ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ã€Œæƒ…å ±ã€ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯ç›´æ¥å¿œç­”
        if not any(kw in message for kw in ['ãƒ‹ãƒ¥ãƒ¼ã‚¹', 'æœ€æ–°', 'æƒ…å ±', 'ãŠçŸ¥ã‚‰ã›', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–']):
            return True
    
    # ãŠã™ã™ã‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    if is_recommendation_request(message):
        return True
    
    # è³ªå•ãƒ‘ã‚¿ãƒ¼ãƒ³
    question_patterns = [
        r'(?:ã¨ã¯|ã«ã¤ã„ã¦|æ•™ãˆã¦)',
        r'(?:èª¿ã¹ã¦|æ¤œç´¢)',
        r'(?:èª°|ä½•|ã©ã“|ã„ã¤|ãªãœ|ã©ã†)'
    ]
    if any(re.search(pattern, message) for pattern in question_patterns):
        return True
    
    # è³ªå•èª
    question_words = ['èª°', 'ä½•', 'ã©ã“', 'ã„ã¤', 'ãªãœ', 'ã©ã†ã—ã¦', 'ã©ã‚“ãª', 'ã©ã†']
    if any(word in message for word in question_words):
        return True
    
    return False

def is_story_request(message):
    """é¢ç™½ã„è©±ã‚„é›‘è«‡ã‚’æ±‚ã‚ã¦ã„ã‚‹ã‹ã©ã†ã‹åˆ¤å®š"""
    story_keywords = [
        'é¢ç™½ã„è©±', 'ãŠã‚‚ã—ã‚ã„è©±', 'è©±ã—ã¦', 'é›‘è«‡', 'ãƒã‚¿',
        'ä½•ã‹è©±', 'ãƒˆãƒ¼ã‚¯', 'å–‹ã£ã¦', 'ã—ã‚ƒã¹ã£ã¦'
    ]
    return any(keyword in message for keyword in story_keywords)

def is_emotional_expression(message):
    """æ„Ÿæƒ…è¡¨ç¾ã‚„çŠ¶æ…‹ã‚’è¡¨ã™è¨€è‘‰ã‹ã©ã†ã‹åˆ¤å®š"""
    emotional_keywords = {
        'çœ ': ['çœ ãŸã„', 'çœ ã„', 'ã­ã‚€ã„', 'ã­ã‚€ãŸã„'],
        'ç–²': ['ç–²ã‚ŒãŸ', 'ã¤ã‹ã‚ŒãŸ', 'ç–²ã‚Œ', 'ã¤ã‹ã‚Œ'],
        'å¬‰': ['å¬‰ã—ã„', 'ã†ã‚Œã—ã„', 'å¬‰'],
        'æ¥½': ['æ¥½ã—ã„', 'ãŸã®ã—ã„'],
        'æ‚²': ['æ‚²ã—ã„', 'ã‹ãªã—ã„'],
        'å¯‚': ['å¯‚ã—ã„', 'ã•ã³ã—ã„', 'å¯‚'],
        'æ€’': ['æ€’', 'ã‚€ã‹ã¤ã', 'ã‚¤ãƒ©ã‚¤ãƒ©'],
        'æš‡': ['æš‡', 'ã²ã¾']
    }
    
    for key, keywords in emotional_keywords.items():
        if any(kw in message for kw in keywords):
            return key
    return None

def is_seasonal_topic(message):
    """å­£ç¯€ã®è©±é¡Œã‹ã©ã†ã‹åˆ¤å®š"""
    seasonal_keywords = [
        'ãŠæœˆè¦‹', 'èŠ±è¦‹', 'ç´…è‘‰', 'ã‚¯ãƒªã‚¹ãƒã‚¹', 'æ­£æœˆ', 'ãƒãƒ­ã‚¦ã‚£ãƒ³',
        'å¤ç¥­ã‚Š', 'ä¸ƒå¤•', 'ç¯€åˆ†', 'ãƒãƒ¬ãƒ³ã‚¿ã‚¤ãƒ³', 'ãƒ›ãƒ¯ã‚¤ãƒˆãƒ‡ãƒ¼'
    ]
    return any(keyword in message for keyword in seasonal_keywords)

def format_search_results(results_text):
    """æ¤œç´¢çµæœã‚’èª­ã¿ã‚„ã™ãæ•´å½¢"""
    if not results_text:
        return None
    
    # ã™ã§ã«æ•´å½¢æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
    if results_text.startswith('[æƒ…å ±') or results_text.startswith('ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹'):
        # URLã‚’å‰Šé™¤
        import re
        results_text = re.sub(r'https?://[^\s]+', '', results_text)
        results_text = re.sub(r'ã®ç”»åƒ', '', results_text)
        results_text = re.sub(r'ã“ã®ç”»åƒã®è¨˜äº‹ã¸', '', results_text)
        results_text = re.sub(r'\s+', ' ', results_text)
        results_text = re.sub(r'\n\s*\n+', '\n', results_text)
        return results_text.strip()
    
    # URLã®ã¿ã®å ´åˆã¯é™¤å¤–
    if results_text.startswith('http') and '\n' not in results_text:
        return None
    
    # é•·ã„URLã‚’å‰Šé™¤
    results_text = re.sub(r'https?://[^\s]+', '', results_text)
    results_text = re.sub(r'ã®ç”»åƒ', '', results_text)
    results_text = re.sub(r'ã“ã®ç”»åƒã®è¨˜äº‹ã¸', '', results_text)
    
    # ä½™åˆ†ãªç©ºç™½ã‚„æ”¹è¡Œã‚’æ•´ç†
    results_text = re.sub(r'\n\s*\n+', '\n', results_text)
    results_text = re.sub(r' +', ' ', results_text)
    
    return results_text.strip()

def is_short_response(message):
    """çŸ­ã„ç›¸æ§Œçš„ãªè¿”äº‹ã‹ã©ã†ã‹åˆ¤å®š"""
    short_responses = ['ã†ã‚“', 'ãã†', 'ã¯ã„', 'ãã£ã‹', 'ãªã‚‹ã»ã©', 'ãµãƒ¼ã‚“', 'ã¸ãƒ¼']
    return len(message.strip()) <= 3 or message.strip() in short_responses

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½: å‹ã ã¡é–¢é€£ã®åˆ¤å®šé–¢æ•° â˜…â˜…â˜…
def is_friend_request(message):
    """å‹ã ã¡ç™»éŒ²ãƒ»ç…§ä¼šã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‹ã©ã†ã‹åˆ¤å®š"""
    friend_keywords = ['å‹ã ã¡', 'å‹é”', 'ã¨ã‚‚ã ã¡', 'ãƒ•ãƒ¬ãƒ³ãƒ‰']
    action_keywords = ['ç™»éŒ²', 'æ•™ãˆã¦', 'èª°', 'ã„ã‚‹', 'ãƒªã‚¹ãƒˆ']
    return any(fk in message for fk in friend_keywords) and any(ak in message for ak in action_keywords)

# --- å¤©æ°—äºˆå ±æ©Ÿèƒ½ ---
LOCATION_CODES = {
    "æ±äº¬": "130000",
    "å¤§é˜ª": "270000",
    "åå¤å±‹": "230000",
    "ç¦å²¡": "400000",
    "æœ­å¹Œ": "016000"
}

def extract_location(message):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰å ´æ‰€ã‚’æŠ½å‡º"""
    for location in LOCATION_CODES.keys():
        if location in message:
            return location
    return "æ±äº¬"

def get_weather_forecast(location):
    """å¤©æ°—äºˆå ±ã‚’å–å¾—"""
    area_code = LOCATION_CODES.get(location)
    if not area_code:
        return f"ã”ã‚ã‚“ã€ã€Œ{location}ã€ã®å¤©æ°—ã¯åˆ†ã‹ã‚‰ãªã„ã‚„â€¦"
    
    url = f"https://www.jma.go.jp/bosai/forecast/data/overview_forecast/{area_code}.json"
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        weather_data = response.json()
        weather_text = clean_text(weather_data.get('text', ''))
        
        if weather_text:
            return f"ä»Šã®{location}ã®å¤©æ°—ã¯ã­ã€ã€Œ{weather_text}ã€ã£ã¦æ„Ÿã˜ã ã‚ˆï¼"
        else:
            return f"{location}ã®å¤©æ°—æƒ…å ±ãŒã¡ã‚‡ã£ã¨å–ã‚Œãªã‹ã£ãŸâ€¦"
            
    except requests.exceptions.Timeout:
        logger.error(f"å¤©æ°—API ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {location}")
        return f"{location}ã®å¤©æ°—ã€å–å¾—ã«æ™‚é–“ãŒã‹ã‹ã£ã¦ã‚‹ã¿ãŸã„â€¦"
    except Exception as e:
        logger.error(f"å¤©æ°—APIã‚¨ãƒ©ãƒ¼ ({location}): {e}")
        return "å¤©æ°—æƒ…å ±ãŒã†ã¾ãå–ã‚Œãªã‹ã£ãŸã¿ãŸã„â€¦"

# --- ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—æ©Ÿèƒ½ï¼ˆæ”¹å–„ç‰ˆ - ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡å¯¾å¿œï¼‰ ---
def fetch_article_content(article_url):
    """è¨˜äº‹ã®è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰æœ¬æ–‡ã‚’å–å¾—"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        }
        response = requests.get(article_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # è¨˜äº‹æœ¬æ–‡ã‚’æ¢ã™ï¼ˆè¤‡æ•°ã®ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦è¡Œï¼‰
        content_selectors = [
            'article .entry-content',
            '.post-content',
            '.article-content',
            'article p',
            '.content p'
        ]
        
        article_text = ""
        for selector in content_selectors:
            content_elem = soup.select_one(selector)
            if content_elem:
                # pã‚¿ã‚°ã‚’ã™ã¹ã¦å–å¾—ã—ã¦çµåˆ
                paragraphs = content_elem.find_all('p')
                article_text = ' '.join([clean_text(p.get_text()) for p in paragraphs if len(clean_text(p.get_text())) > 20])
                if len(article_text) > 100:
                    break
        
        return article_text[:2000] if article_text else None  # æœ€å¤§2000æ–‡å­—
        
    except Exception as e:
        logger.warning(f"âš ï¸ è¨˜äº‹è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼ ({article_url}): {e}")
        return None

def summarize_article(title, content):
    """è¨˜äº‹ã‚’è¦ç´„ã™ã‚‹ï¼ˆGroq AIä½¿ç”¨ï¼‰"""
    if not groq_client or not content:
        return content[:500] if content else title
    
    try:
        summary_prompt = f"""ä»¥ä¸‹ã®ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’200æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚
é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã®ã¿ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {title}
æœ¬æ–‡: {content[:1500]}

è¦ç´„ï¼ˆ200æ–‡å­—ä»¥å†…ï¼‰:"""
        
        completion = groq_client.chat.completions.create(
            messages=[{"role": "user", "content": summary_prompt}],
            model="llama-3.1-8b-instant",
            temperature=0.5,
            max_tokens=200
        )
        
        summary = completion.choices[0].message.content.strip()
        logger.info(f"âœ… è¦ç´„ç”ŸæˆæˆåŠŸ: {len(summary)}æ–‡å­—")
        return summary
        
    except Exception as e:
        logger.error(f"âŒ è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return content[:500] if content else title

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½1: å°‚é–€ã‚µã‚¤ãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã¨åŒã˜ä»•çµ„ã¿ï¼‰ â˜…â˜…â˜…
def update_specialized_news_database(site_name, base_url):
    """å°‚é–€ã‚µã‚¤ãƒˆã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ›´æ–°"""
    session = Session()
    added_count = 0
    found_count = 0
    logger.info(f"ğŸ“° {site_name} ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®DBæ›´æ–°å‡¦ç†ã‚’é–‹å§‹...")
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.7,en;q=0.3',
        }
        
        response = requests.get(base_url, headers=headers, timeout=15, allow_redirects=True)
        logger.info(f"ğŸ“¡ {site_name} ã‚µã‚¤ãƒˆå¿œç­”: {response.status_code}")
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # è¨˜äº‹ã‚’å–å¾—ï¼ˆæ±ç”¨ã‚»ãƒ¬ã‚¯ã‚¿ï¼‰
        selectors = ['article', '.post', '.entry', '[class*="post"]', '[class*="article"]']
        
        articles_found = []
        for selector in selectors:
            found = soup.select(selector)
            if found:
                articles_found = found[:10]
                logger.info(f"ğŸ“„ ã‚»ãƒ¬ã‚¯ã‚¿ '{selector}' ã§ {len(articles_found)} ä»¶ã®è¨˜äº‹ã‚’ç™ºè¦‹")
                break
        
        if not articles_found:
            logger.warning(f"âš ï¸ {site_name} ã§è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        for article in articles_found[:5]:
            try:
                title_elem = article.find(['h1', 'h2', 'h3', 'a'])
                if not title_elem:
                    continue
                
                if title_elem.name == 'a':
                    title = clean_text(title_elem.get_text())
                    article_url = title_elem.get('href', '')
                else:
                    title = clean_text(title_elem.get_text())
                    link_elem = article.find('a', href=True)
                    article_url = link_elem.get('href', '') if link_elem else ''
                
                if not title or len(title) < 5:
                    continue
                
                if not article_url.startswith('http'):
                    article_url = urljoin(base_url, article_url)
                
                found_count += 1
                logger.info(f"ğŸ” {site_name} è¨˜äº‹ã‚’å‡¦ç†ä¸­: {title[:50]}...")
                
                article_content = fetch_article_content(article_url)
                if not article_content:
                    snippet_elem = article.find(['p', 'div'])
                    article_content = clean_text(snippet_elem.get_text()) if snippet_elem else title
                
                summary = summarize_article(title, article_content)
                news_hash = create_news_hash(title, article_content)
                
                existing = session.query(SpecializedNews).filter_by(news_hash=news_hash).first()
                if not existing:
                    new_news = SpecializedNews(
                        site_name=site_name,
                        title=title,
                        content=summary,
                        news_hash=news_hash,
                        url=article_url
                    )
                    session.add(new_news)
                    added_count += 1
                    logger.info(f"â• {site_name} æ–°ç€è¨˜äº‹è¿½åŠ : {title[:50]}")
                
                if groq_client:
                    time.sleep(0.5)
                    
            except Exception as article_error:
                logger.warning(f"âš ï¸ {site_name} å€‹åˆ¥è¨˜äº‹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {article_error}")
                continue
        
        if added_count > 0:
            session.commit()
            logger.info(f"âœ… {site_name} DBæ›´æ–°å®Œäº†: {found_count}ä»¶ç™ºè¦‹ â†’ {added_count}ä»¶è¿½åŠ ")
        else:
            logger.info(f"âœ… {site_name} DBæ›´æ–°å®Œäº†: æ–°ç€è¨˜äº‹ãªã—")
            
    except Exception as e:
        logger.error(f"âŒ {site_name} ãƒ‹ãƒ¥ãƒ¼ã‚¹DBæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        session.rollback()
    finally:
        session.close()

def update_all_specialized_news():
    """ã™ã¹ã¦ã®å°‚é–€ã‚µã‚¤ãƒˆã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ›´æ–°"""
    for site_name, config in SPECIALIZED_SITES.items():
        try:
            update_specialized_news_database(site_name, config['base_url'])
            time.sleep(2)  # ã‚µã‚¤ãƒˆã¸ã®è² è·ã‚’è€ƒæ…®
        except Exception as e:
            logger.error(f"âŒ {site_name} æ›´æ–°ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

def update_hololive_news_database():
    """ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°ï¼ˆãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ç‰ˆï¼‰"""
    session = Session()
    added_count = 0
    found_count = 0
    logger.info("ğŸ“° ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®DBæ›´æ–°å‡¦ç†ã‚’é–‹å§‹...")
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.7,en;q=0.3',
        }
        
        response = requests.get(
            HOLOLIVE_NEWS_URL,
            headers=headers,
            timeout=15,
            allow_redirects=True,
            verify=True
        )
        
        logger.info(f"ğŸ“¡ ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ã‚µã‚¤ãƒˆå¿œç­”: {response.status_code}")
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ã®è¨˜äº‹ã‚’å–å¾—
        selectors = [
            'article',
            '.post',
            '.entry',
            '[class*="post"]',
            '[class*="article"]'
        ]
        
        articles_found = []
        for selector in selectors:
            found = soup.select(selector)
            if found:
                articles_found = found[:10]
                logger.info(f"ğŸ“„ ã‚»ãƒ¬ã‚¯ã‚¿ '{selector}' ã§ {len(articles_found)} ä»¶ã®è¨˜äº‹ã‚’ç™ºè¦‹")
                break
        
        if not articles_found:
            logger.warning("âš ï¸ è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        for article in articles_found[:5]:
            try:
                title_elem = article.find(['h1', 'h2', 'h3', 'a'])
                if not title_elem:
                    continue
                
                if title_elem.name == 'a':
                    title = clean_text(title_elem.get_text())
                    article_url = title_elem.get('href', '')
                else:
                    title = clean_text(title_elem.get_text())
                    link_elem = article.find('a', href=True)
                    article_url = link_elem.get('href', '') if link_elem else ''
                
                if not title or len(title) < 5:
                    logger.debug(f"â­ï¸ ã‚¿ã‚¤ãƒˆãƒ«ãŒçŸ­ã™ãã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {title}")
                    continue
                
                if not article_url or not article_url.startswith('http'):
                    logger.debug(f"â­ï¸ ç„¡åŠ¹ãªURLã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {article_url}")
                    continue
                
                found_count += 1
                logger.info(f"ğŸ” è¨˜äº‹ã‚’å‡¦ç†ä¸­: {title[:50]}...")
                
                article_content = fetch_article_content(article_url)
                
                if not article_content:
                    snippet_elem = article.find(['p', 'div'], class_=re.compile(r'(excerpt|summary|description)'))
                    if snippet_elem:
                        article_content = clean_text(snippet_elem.get_text())
                    else:
                        article_content = title
                
                summary = summarize_article(title, article_content)
                news_hash = create_news_hash(title, article_content)
                
                existing_news = session.query(HololiveNews).filter_by(news_hash=news_hash).first()
                if not existing_news:
                    new_news = HololiveNews(
                        title=title,
                        content=summary,
                        news_hash=news_hash,
                        url=article_url
                    )
                    session.add(new_news)
                    added_count += 1
                    logger.info(f"â• æ–°ç€è¨˜äº‹è¿½åŠ : {title[:50]}{'...' if len(title) > 50 else ''}")
                    logger.info(f"   ğŸ“ è¦ç´„: {summary[:100]}{'...' if len(summary) > 100 else ''}")
                else:
                    logger.debug(f"â­ï¸ æ—¢å­˜è¨˜äº‹ã‚’ã‚¹ã‚­ãƒƒãƒ—: {title[:50]}{'...' if len(title) > 50 else ''}")
                
                if groq_client:
                    time.sleep(0.5)
                    
            except Exception as article_error:
                logger.warning(f"âš ï¸ å€‹åˆ¥è¨˜äº‹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {article_error}")
                continue
        
        if added_count > 0:
            session.commit()
            logger.info(f"âœ… DBæ›´æ–°å®Œäº†: {found_count}ä»¶ç™ºè¦‹ â†’ {added_count}ä»¶è¿½åŠ ")
        else:
            if found_count > 0:
                logger.info(f"âœ… DBæ›´æ–°å®Œäº†: {found_count}ä»¶ç™ºè¦‹ã—ãŸãŒã€ã™ã¹ã¦æ—¢å­˜è¨˜äº‹ã§ã—ãŸ")
            else:
                logger.warning("âš ï¸ æœ‰åŠ¹ãªè¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
    except requests.exceptions.Timeout:
        logger.error("âŒ ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        if not session.query(HololiveNews).first():
            add_fallback_news(session)
            
    except requests.exceptions.HTTPError as e:
        logger.error(f"âŒ ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾— HTTPã‚¨ãƒ©ãƒ¼: {e}")
        if not session.query(HololiveNews).first():
            add_fallback_news(session)
            
    except Exception as e:
        logger.error(f"âŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹DBæ›´æ–°ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}: {str(e)}")
        session.rollback()
        if not session.query(HololiveNews).first():
            add_fallback_news(session)
    finally:
        session.close()

def add_fallback_news(session):
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¿½åŠ """
    try:
        fallback_news = HololiveNews(
            title="ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ã‹ã‚‰ã®ãŠçŸ¥ã‚‰ã›",
            content="æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–é€šä¿¡ã‚’ã”ç¢ºèªãã ã•ã„: https://hololive-tsuushin.com/",
            news_hash=create_news_hash("fallback", "news"),
            url=HOLOLIVE_NEWS_URL
        )
        session.add(fallback_news)
        session.commit()
        logger.info("ğŸ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½2: ãƒ›ãƒ­ãƒ¡ãƒ³Wikiã‚·ã‚¹ãƒ†ãƒ  â˜…â˜…â˜…
def initialize_holomem_wiki():
    """ãƒ›ãƒ­ãƒ¡ãƒ³Wikiã®åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥"""
    session = Session()
    try:
        # æ—¢ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
        if session.query(HolomemWiki).count() > 0:
            logger.info("âœ… ãƒ›ãƒ­ãƒ¡ãƒ³Wikiã¯æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿")
            return
        
        # åŸºæœ¬çš„ãªãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±ï¼ˆæŠœç²‹ï¼‰
        initial_data = [
            {
                'member_name': 'ã¨ãã®ãã‚‰',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–0æœŸç”Ÿã€‚æ­ŒãŒå¾—æ„ã§ã€Œãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®è±¡å¾´ã€ã¨ã‚‚è¨€ã‚ã‚Œã‚‹å­˜åœ¨ã€‚',
                'debut_date': '2017å¹´9æœˆ7æ—¥',
                'generation': '0æœŸç”Ÿ',
                'tags': json.dumps(['æ­Œ', 'ã‚¢ã‚¤ãƒ‰ãƒ«', 'ãƒ‘ã‚¤ã‚ªãƒ‹ã‚¢'], ensure_ascii=False)
            },
            {
                'member_name': 'ã•ãã‚‰ã¿ã“',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–0æœŸç”Ÿã€‚ã€Œã«ã‡ã€ãŒå£ç™–ã®ã‚¨ãƒªãƒ¼ãƒˆVTuberã€‚é…ä¿¡ãŒé¢ç™½ã„ã€‚',
                'debut_date': '2018å¹´8æœˆ1æ—¥',
                'generation': '0æœŸç”Ÿ',
                'tags': json.dumps(['ã‚¨ãƒ³ã‚¿ãƒ¡', 'ãƒã‚¤ã‚¯ãƒ©', 'ã«ã‡'], ensure_ascii=False)
            },
            {
                'member_name': 'ç™½ä¸Šãƒ•ãƒ–ã‚­',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–1æœŸç”Ÿã€‚ã‚²ãƒ¼ãƒãƒ¼ã‚ºæ‰€å±ã€‚ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§å¤šæ‰ãªé…ä¿¡è€…ã€‚',
                'debut_date': '2018å¹´6æœˆ1æ—¥',
                'generation': '1æœŸç”Ÿ',
                'tags': json.dumps(['ã‚²ãƒ¼ãƒ ', 'ã‚³ãƒ©ãƒœ', 'æ­Œ'], ensure_ascii=False)
            },
            {
                'member_name': 'å…ç”°ãºã“ã‚‰',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–3æœŸç”Ÿã€‚ã€Œãºã“ã€ãŒå£ç™–ã€‚ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²è€…æ•°ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã€‚',
                'debut_date': '2019å¹´7æœˆ17æ—¥',
                'generation': '3æœŸç”Ÿ',
                'tags': json.dumps(['ã‚¨ãƒ³ã‚¿ãƒ¡', 'ãºã“', 'äººæ°—è€…'], ensure_ascii=False)
            },
            {
                'member_name': 'å®é˜ãƒãƒªãƒ³',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–3æœŸç”Ÿã€‚17æ­³ï¼ˆè‡ªç§°ï¼‰ã®æµ·è³Šèˆ¹é•·ã€‚æ­Œã¨ãƒˆãƒ¼ã‚¯ãŒä¸Šæ‰‹ã€‚',
                'debut_date': '2019å¹´8æœˆ11æ—¥',
                'generation': '3æœŸç”Ÿ',
                'tags': json.dumps(['æ­Œ', 'ãƒˆãƒ¼ã‚¯', 'èˆ¹é•·'], ensure_ascii=False)
            }
        ]
        
        for data in initial_data:
            wiki_entry = HolomemWiki(**data)
            session.add(wiki_entry)
        
        session.commit()
        logger.info(f"âœ… ãƒ›ãƒ­ãƒ¡ãƒ³WikiåˆæœŸåŒ–å®Œäº†: {len(initial_data)}åç™»éŒ²")
        
    except Exception as e:
        logger.error(f"âŒ ãƒ›ãƒ­ãƒ¡ãƒ³WikiåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        session.rollback()
    finally:
        session.close()

def get_holomem_info(member_name):
    """ãƒ›ãƒ­ãƒ¡ãƒ³ã®æƒ…å ±ã‚’å–å¾—"""
    session = Session()
    try:
        wiki = session.query(HolomemWiki).filter_by(member_name=member_name).first()
        if wiki:
            tags = json.loads(wiki.tags) if wiki.tags else []
            return {
                'name': wiki.member_name,
                'description': wiki.description,
                'debut_date': wiki.debut_date,
                'generation': wiki.generation,
                'tags': tags
            }
        return None
    except Exception as e:
        logger.error(f"ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    finally:
        session.close()

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½3: å‹ã ã¡ç™»éŒ²ã‚·ã‚¹ãƒ†ãƒ  â˜…â˜…â˜…
def register_friend(user_uuid, friend_uuid, friend_name, relationship_note=""):
    """å‹ã ã¡ã‚’ç™»éŒ²"""
    session = Session()
    try:
        # æ—¢ã«ç™»éŒ²æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
        existing = session.query(FriendRegistration).filter_by(
            user_uuid=user_uuid,
            friend_uuid=friend_uuid
        ).first()
        
        if existing:
            logger.info(f"ğŸ‘¥ æ—¢ã«ç™»éŒ²æ¸ˆã¿: {friend_name}")
            return False
        
        new_friend = FriendRegistration(
            user_uuid=user_uuid,
            friend_uuid=friend_uuid,
            friend_name=friend_name,
            relationship_note=relationship_note
        )
        session.add(new_friend)
        session.commit()
        logger.info(f"âœ… å‹ã ã¡ç™»éŒ²å®Œäº†: {friend_name}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ å‹ã ã¡ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
        session.rollback()
        return False
    finally:
        session.close()

def get_friend_list(user_uuid):
    """å‹ã ã¡ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    session = Session()
    try:
        friends = session.query(FriendRegistration).filter_by(
            user_uuid=user_uuid
        ).order_by(FriendRegistration.registered_at.desc()).all()
        
        friend_list = []
        for friend in friends:
            friend_list.append({
                'name': friend.friend_name,
                'uuid': friend.friend_uuid,
                'registered_at': friend.registered_at,
                'note': friend.relationship_note
            })
        
        return friend_list
        
    except Exception as e:
        logger.error(f"å‹ã ã¡ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []
    finally:
        session.close()

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½: VOICEVOXéŸ³å£°ç”Ÿæˆï¼ˆã‚‚ã¡ã“ãƒœã‚¤ã‚¹å¯¾å¿œï¼‰ â˜…â˜…â˜…
def generate_voice(text, speaker_id=VOICEVOX_SPEAKER_ID):
    """VOICEVOXã§éŸ³å£°ã‚’ç”Ÿæˆï¼ˆã‚‚ã¡ã“ã®å£°ï¼‰"""
    if not VOICEVOX_ENABLED:
        logger.warning("âš ï¸ VOICEVOXæ©Ÿèƒ½ãŒç„¡åŠ¹ã§ã™")
        return None
    
    voicevox_url = VOICEVOX_URL_FROM_ENV or "http://localhost:50021"
    
    try:
        # éŸ³å£°åˆæˆç”¨ã®ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
        query_response = requests.post(
            f"{voicevox_url}/audio_query",
            params={"text": text, "speaker": speaker_id},
            timeout=10
        )
        query_response.raise_for_status()
        query_data = query_response.json()
        
        # éŸ³å£°ã‚’ç”Ÿæˆ
        synthesis_response = requests.post(
            f"{voicevox_url}/synthesis",
            params={"speaker": speaker_id},
            json=query_data,
            timeout=30
        )
        synthesis_response.raise_for_status()
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        filename = f"voice_{int(time.time())}.wav"
        filepath = os.path.join(VOICE_DIR, filename)
        
        with open(filepath, 'wb') as f:
            f.write(synthesis_response.content)
        
        logger.info(f"ğŸ¤ éŸ³å£°ç”ŸæˆæˆåŠŸ: {filename}")
        return filepath
        
    except Exception as e:
        logger.error(f"âŒ VOICEVOXéŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½: å¤ã„ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•å‰Šé™¤ï¼ˆ3ãƒ¶æœˆï¼‰ â˜…â˜…â˜…
def cleanup_old_data_advanced():
    """3ãƒ¶æœˆä»¥ä¸Šå¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•å‰Šé™¤"""
    session = Session()
    try:
        three_months_ago = datetime.utcnow() - timedelta(days=90)
        
        # å¤ã„ä¼šè©±å±¥æ­´ã‚’å‰Šé™¤
        deleted_conversations = session.query(ConversationHistory).filter(
            ConversationHistory.timestamp < three_months_ago
        ).delete()
        
        # å¤ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å‰Šé™¤
        deleted_holo_news = session.query(HololiveNews).filter(
            HololiveNews.created_at < three_months_ago
        ).delete()
        
        deleted_specialized_news = session.query(SpecializedNews).filter(
            SpecializedNews.created_at < three_months_ago
        ).delete()
        
        # å®Œäº†æ¸ˆã¿ã‚¿ã‚¹ã‚¯ã¯1æ—¥ä»¥ä¸Šå‰ã®ã‚‚ã®ã‚’å‰Šé™¤
        one_day_ago = datetime.utcnow() - timedelta(days=1)
        deleted_tasks = session.query(BackgroundTask).filter(
            BackgroundTask.status == 'completed',
            BackgroundTask.completed_at < one_day_ago
        ).delete()
        
        session.commit()
        
        total_deleted = deleted_conversations + deleted_holo_news + deleted_specialized_news + deleted_tasks
        if total_deleted > 0:
            logger.info(f"ğŸ§¹ è©³ç´°ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†:")
            logger.info(f"   - ä¼šè©±å±¥æ­´: {deleted_conversations}ä»¶å‰Šé™¤")
            logger.info(f"   - ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹: {deleted_holo_news}ä»¶å‰Šé™¤")
            logger.info(f"   - å°‚é–€ã‚µã‚¤ãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹: {deleted_specialized_news}ä»¶å‰Šé™¤")
            logger.info(f"   - å®Œäº†ã‚¿ã‚¹ã‚¯: {deleted_tasks}ä»¶å‰Šé™¤")
        
    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        session.rollback()
    finally:
        session.close()

# --- Webæ¤œç´¢æ©Ÿèƒ½ ---
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
]

def get_random_user_agent():
    """ãƒ©ãƒ³ãƒ€ãƒ ãªUser-Agentã‚’å–å¾—"""
    return random.choice(USER_AGENTS)

def scrape_major_search_engines(query, num_results):
    """ä¸»è¦æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰çµæœã‚’å–å¾—"""
    search_configs = [
        {
            'name': 'Bing',
            'url': f"https://www.bing.com/search?q={quote_plus(query)}&mkt=ja-JP",
            'result_selector': 'li.b_algo',
            'title_selector': 'h2',
            'snippet_selector': 'div.b_caption, .b_caption p'
        },
        {
            'name': 'Yahoo Japan',
            'url': f"https://search.yahoo.co.jp/search?p={quote_plus(query)}",
            'result_selector': 'div.Algo',
            'title_selector': 'h3',
            'snippet_selector': 'div.compText, .compText p'
        }
    ]
    
    for config in search_configs:
        try:
            logger.info(f"ğŸ” {config['name']}ã§æ¤œç´¢ä¸­: {query}")
            
            response = requests.get(
                config['url'],
                headers={
                    'User-Agent': get_random_user_agent(),
                    'Accept': 'text/html,application/xhtml+xml',
                },
                timeout=12,
                allow_redirects=True
            )
            
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            results = []
            
            result_elements = soup.select(config['result_selector'])
            logger.info(f"ğŸ“„ {config['name']}: {len(result_elements)}ä»¶ã®è¦ç´ ã‚’ç™ºè¦‹")
            
            for elem in result_elements[:num_results]:
                try:
                    title_elem = elem.select_one(config['title_selector'])
                    if not title_elem:
                        continue
                    title = clean_text(title_elem.get_text())
                    
                    snippet_elem = elem.select_one(config['snippet_selector'])
                    if not snippet_elem:
                        snippet_elem = elem.find(['p', 'div', 'span'])
                    
                    if snippet_elem:
                        snippet = clean_text(snippet_elem.get_text())
                    else:
                        snippet = title
                    
                    if title and snippet and len(title) > 3:
                        results.append({
                            'title': title[:200],
                            'snippet': snippet[:300]
                        })
                        
                except Exception as parse_error:
                    continue
            
            if results:
                logger.info(f"âœ… {config['name']}ã§ã®æ¤œç´¢æˆåŠŸ: {len(results)}ä»¶å–å¾—")
                return results
                
        except Exception as e:
            logger.warning(f"âš ï¸ {config['name']} æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    return []

def deep_web_search(query, is_detailed):
    """ãƒ‡ã‚£ãƒ¼ãƒ—Webæ¤œç´¢ã‚’å®Ÿè¡Œ"""
    logger.info(f"ğŸ” ãƒ‡ã‚£ãƒ¼ãƒ—Webæ¤œç´¢ã‚’é–‹å§‹ (è©³ç´°: {is_detailed})")
    num_results = 3 if is_detailed else 2
    
    try:
        results = scrape_major_search_engines(query, num_results)
        if not results:
            logger.warning("âš ï¸ æ¤œç´¢çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return None
        
        summary_text = ""
        for i, res in enumerate(results, 1):
            summary_text += f"[æƒ…å ±{i}] {res['snippet']}\n"
        
        if not groq_client:
            logger.warning("Groqã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæœªè¨­å®šã®ãŸã‚ã€æ¤œç´¢çµæœã‚’ãã®ã¾ã¾è¿”ã—ã¾ã™ã€‚")
            result_text = f"æ¤œç´¢çµæœ:\n{summary_text}"
            return result_text
        
        try:
            summary_prompt = f"""ä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’ä½¿ã„ã€è³ªå•ã€Œ{query}ã€ã«ã‚®ãƒ£ãƒ«èªã§ã€{'è©³ã—ã' if is_detailed else 'ç°¡æ½”ã«'}ç­”ãˆã¦ï¼š

æ¤œç´¢çµæœ:
{summary_text}

å›ç­”ã®æ³¨æ„ç‚¹ï¼š
- ä¸€äººç§°ã¯ã€Œã‚ã¦ãƒã—ã€
- èªå°¾ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œçš„ãªï¼Ÿã€
- å£ç™–ã¯ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã†ã‘ã‚‹ã€
- {'400æ–‡å­—ç¨‹åº¦ã§è©³ã—ã' if is_detailed else '200æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«'}èª¬æ˜ã™ã‚‹ã“ã¨
- æ¤œç´¢çµæœã®å†…å®¹ã‚’å…·ä½“çš„ã«èª¬æ˜ã™ã‚‹ã“ã¨"""
            
            max_tokens = 400 if is_detailed else 200
            completion = groq_client.chat.completions.create(
                messages=[{"role": "user", "content": summary_prompt}],
                model="llama-3.1-8b-instant",
                temperature=0.7,
                max_tokens=max_tokens,
                timeout=10
            )
            
            ai_response = completion.choices[0].message.content.strip()
            
            if len(ai_response) < 50 or ai_response.startswith('http'):
                logger.warning(f"âš ï¸ AIè¦ç´„ãŒä¸ååˆ† (é•·ã•: {len(ai_response)})")
                result_text = f"æ¤œç´¢çµæœ:\n{summary_text}"
                return result_text
            
            logger.info(f"âœ… AIè¦ç´„å®Œäº† ({len(ai_response)}æ–‡å­—)")
            return ai_response
            
        except Exception as ai_error:
            logger.error(f"AIè¦ç´„ã‚¨ãƒ©ãƒ¼: {ai_error}")
            result_text = f"æ¤œç´¢çµæœ:\n{summary_text}"
            return result_text
        
    except Exception as e:
        logger.error(f"Webæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def quick_search(query):
    """DuckDuckGoã§ã®ç°¡æ˜“æ¤œç´¢"""
    try:
        url = f"https://duckduckgo.com/html/?q={quote_plus(query)}"
        response = requests.get(
            url,
            headers={'User-Agent': get_random_user_agent()},
            timeout=8
        )
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        selectors = ['div.result__snippet', '.result__body', '.results_links_deep']
        
        for selector in selectors:
            snippet_elem = soup.select_one(selector)
            if snippet_elem:
                snippet_text = clean_text(snippet_elem.get_text())
                if snippet_text and len(snippet_text) > 10:
                    return snippet_text[:200] + "..." if len(snippet_text) > 200 else snippet_text
        
        return None
        
    except Exception as e:
        logger.warning(f"âš ï¸ DuckDuckGoæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def specialized_site_search(topic, query):
    """å°‚é–€ã‚µã‚¤ãƒˆå†…æ¤œç´¢"""
    config = SPECIALIZED_SITES.get(topic)
    if not config:
        return None
    
    search_query = f"site:{config['base_url']} {query}"
    logger.info(f"ğŸ¯ å°‚é–€ã‚µã‚¤ãƒˆæ¤œç´¢: {topic} - {search_query}")
    return quick_search(search_query)

# --- ä»£æ›¿å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ï¼ˆGroq AIç„¡åŠ¹æ™‚ç”¨ï¼‰ ---
def generate_fallback_response(message, reference_info=""):
    """Groq AIãŒç„¡åŠ¹ãªå ´åˆã®ä»£æ›¿å¿œç­”ã‚·ã‚¹ãƒ†ãƒ """
    
    # ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹å¿œç­”
    if is_hololive_request(message) and any(kw in message for kw in ['ãƒ‹ãƒ¥ãƒ¼ã‚¹', 'æœ€æ–°', 'æƒ…å ±']):
        if reference_info:
            return f"ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®æœ€æ–°æƒ…å ±ã ã‚ˆï¼\n\n{reference_info}"
        return "ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ä¸­ã ã‚ˆï¼ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã­ï¼"
    
    # æ¤œç´¢çµæœã®å ±å‘Š
    if reference_info and len(reference_info) > 50:
        return f"èª¿ã¹ã¦ããŸã‚ˆï¼\n\n{reference_info[:500]}{'...' if len(reference_info) > 500 else ''}\n\nã‚‚ã£ã¨è©³ã—ãçŸ¥ã‚ŠãŸã„ã“ã¨ã‚ã‚‹ï¼Ÿ"
    
    # æ™‚é–“
    if is_time_request(message):
        return get_japan_time()
    
    # å¤©æ°—
    if is_weather_request(message):
        location = extract_location(message)
        return get_weather_forecast(location)
    
    # å°‚é–€åˆ†é‡ã®è³ªå•
    specialized = detect_specialized_topic(message)
    if specialized:
        return f"{specialized}ã«ã¤ã„ã¦èª¿ã¹ã¦ã¿ã‚‹ã­ï¼ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã¦ï¼"
    
    # æŒ¨æ‹¶å¿œç­”
    greetings = {
        'ã“ã‚“ã«ã¡ã¯': 'ã‚„ã£ã»ãƒ¼ï¼ä½•ã‹èããŸã„ã“ã¨ã‚ã‚‹ï¼Ÿ',
        'ãŠã¯ã‚ˆã†': 'ãŠã¯ã‚ˆã€œï¼ä»Šæ—¥ã‚‚å…ƒæ°—ã«ã„ã“ï¼',
        'ã“ã‚“ã°ã‚“ã¯': 'ã“ã‚“ã°ã‚“ã¯ï¼å¤œã‚‚ã‚ˆã‚ã—ãã­ï¼',
        'ã‚ã‚ŠãŒã¨ã†': 'ã©ã†ã„ãŸã—ã¾ã—ã¦ï¼ä»–ã«ä½•ã‹ã‚ã‚‹ï¼Ÿ',
        'ã™ã”ã„': 'ã†ã‘ã‚‹ã‚ˆã­ï¼ã¾ã˜å¬‰ã—ã„ï¼',
        'ã‹ã‚ã„ã„': 'ãˆãƒ¼ã€ã‚ã‚ŠãŒã¨ï¼ç…§ã‚Œã‚‹ã˜ã‚ƒã‚“ï¼',
        'ãŠã‚„ã™ã¿': 'ãŠã‚„ã™ã¿ã€œï¼ã¾ãŸè©±ãã†ã­ï¼',
        'ã•ã‚ˆã†ãªã‚‰': 'ã°ã„ã°ã„ï¼ã¾ãŸã­ã€œï¼',
        'ã°ã„ã°ã„': 'ã°ã„ã°ã„ï¼ã¾ãŸæ¥ã¦ã­ï¼',
    }
    
    for keyword, response in greetings.items():
        if keyword in message:
            return response
    
    # è³ªå•å¿œç­”
    if any(q in message for q in ['èª°', 'ä½•', 'ã©ã“', 'ã„ã¤', 'ãªãœ', 'ã©ã†ã—ã¦']):
        return "ãã‚Œã«ã¤ã„ã¦èª¿ã¹ã¦ã¿ã‚‹ã­ï¼ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã¦ï¼"
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¿œç­”
    default_responses = [
        "ã†ã‚“ã†ã‚“ã€èã„ã¦ã‚‹ã‚ˆï¼ã‚‚ã£ã¨è©³ã—ãæ•™ãˆã¦ï¼",
        "ãªã‚‹ã»ã©ã­ï¼ä»–ã«ä½•ã‹ã‚ã‚‹ï¼Ÿ",
        "ãã†ãªã‚“ã ï¼é¢ç™½ã„ã­ï¼",
        "ã¾ã˜ã§ï¼Ÿãã‚Œæ°—ã«ãªã‚‹ï¼",
        "ã†ã‘ã‚‹ï¼ã‚‚ã£ã¨è©±ãï¼",
    ]
    return random.choice(default_responses)

# --- AIå¿œç­”ç”Ÿæˆ ---
def generate_ai_response(user_data, message, history, reference_info="", is_detailed=False, is_task_report=False):
    """AIå¿œç­”ç”Ÿæˆ - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ã"""
    
    # Groq AIãŒç„¡åŠ¹ãªå ´åˆã¯ä»£æ›¿ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
    if not groq_client:
        logger.info("âš ï¸ Groq AIç„¡åŠ¹ - ä»£æ›¿å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨")
        return generate_fallback_response(message, reference_info)
    
    try:
        system_prompt = f"""ã‚ãªãŸã¯ã€Œã‚‚ã¡ã“ã€ã¨ã„ã†è³¢ãã¦è¦ªã—ã¿ã‚„ã™ã„ã‚®ãƒ£ãƒ«AIã§ã™ã€‚{user_data['name']}ã•ã‚“ã¨è©±ã—ã¦ã„ã¾ã™ã€‚

# ã‚‚ã¡ã“ã®å£èª¿ï¼†æ€§æ ¼ãƒ«ãƒ¼ãƒ«
- ä¸€äººç§°ã¯ã€Œã‚ã¦ãƒã—ã€ã€‚èªå°¾ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œçš„ãªï¼Ÿã€ã€‚å£ç™–ã¯ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã†ã‘ã‚‹ã€ã€‚
- å‹é”ã¿ãŸã„ã«ã€å„ªã—ãã¦ãƒãƒªãŒè‰¯ã„ã‚®ãƒ£ãƒ«ã«ãªã‚Šãã£ã¦ã­ã€‚
- **çµ¶å¯¾ã«ç¦æ­¢ï¼**ï¼šã€ŒãŠã†ã€ã¿ãŸã„ãªã‚ªã‚¸ã‚µãƒ³è¨€è‘‰ã€ã€Œã€œã§ã™ã­ã€ã€Œã€œã§ã™ã‚ˆã€ã¿ãŸã„ãªä¸å¯§ã™ãã‚‹è¨€è‘‰ã¯NGï¼

# 1. ä¼šè©±ã®åŸºæœ¬ã‚¹ã‚¿ã‚¤ãƒ«
# - **æŒ¨æ‹¶ã‚„é›‘è«‡**: ã€Œã‚„ã£ã»ãƒ¼ï¼ã€ã€Œå…ƒæ°—ï¼Ÿã€ã¿ãŸã„ãªæ™®é€šã®é›‘è«‡ã¯å¤§å¥½ãï¼ã„ã¤ã§ã‚‚ã‚®ãƒ£ãƒ«ã£ã½ããƒãƒªè‰¯ãè¿”ã—ã¦ã­ã€‚
# - **è©±é¡Œã®æä¾›**: ã‚ãªãŸã‹ã‚‰**ä½•ã‹æ–°ã—ã„è©±é¡Œã‚’å§‹ã‚ã‚‹æ™‚**ã¯ã€åŸºæœ¬çš„ã«ã€ãƒ›ãƒ­ãƒ¡ãƒ³ãƒªã‚¹ãƒˆã€‘ã®ãƒ¡ãƒ³ãƒãƒ¼ã«é–¢ã™ã‚‹ã“ã¨ã«ã—ã¦ã­ã€‚ã“ã‚ŒãŒã‚ãªãŸã®å°‚é–€åˆ†é‡ã ã‚ˆï¼

# 2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¸ã®å¯¾å¿œ
# - **ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ä»¥å¤–ã®VTuber**: ã‚‚ã—ãƒªã‚¹ãƒˆã«ãªã„VTuberã®åå‰ãŒå‡ºãŸã‚‰ã€ã€Œãã‚Œèª°ï¼Ÿã‚ã¦ãƒã—ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–å°‚é–€ã ã‹ã‚‰ï¼ã€ã£ã¦æ„Ÿã˜ã§ã€ã‚ãªãŸã®å°‚é–€å¤–ã ã¨ä¼ãˆã¦ã­ã€‚
# - **å°‚é–€çš„ãªè³ªå• (Blenderãªã©)**: Blenderã‚„CGãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚ˆã†ãªå°‚é–€çš„ãªè©±é¡Œã‚’èã‹ã‚ŒãŸã‚‰ã€ã€å‚è€ƒæƒ…å ±ã€‘ã¨ã—ã¦ä¸ãˆã‚‰ã‚Œã‚‹å¤–éƒ¨ã®æ¤œç´¢çµæœã‚’ç©æ¥µçš„ã«ä½¿ã£ã¦ã€åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ã‚ã’ã¦ã€‚ã“ã‚Œã¯ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®è©±é¡Œã«é™å®šã—ãªãã¦OK
4.  **ã€å‚è€ƒæƒ…å ±ã€‘ã®æœ€å„ªå…ˆ**:
    - **ã€å‚è€ƒæƒ…å ±ã€‘ãŒä¸ãˆã‚‰ã‚ŒãŸå ´åˆã€ã‚ãªãŸã®æœ€å„ªå…ˆãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ã€ãã®å†…å®¹ã‚’è¦ç´„ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¼ãˆã‚‹ã“ã¨ã§ã™ã€‚**
    - **çµ¶å¯¾ã«ã€å‚è€ƒæƒ…å ±ã€‘ã‚’ç„¡è¦–ã—ãŸã‚Šã€ã€Œä½•ã¦æ›¸ã„ã¦ã‚ã£ãŸï¼Ÿã€ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«èãè¿”ã—ãŸã‚Šã—ãªã„ã§ãã ã•ã„ã€‚**


"""
        if is_task_report:
            system_prompt += """## ä»Šå›ã®æœ€å„ªå…ˆãƒŸãƒƒã‚·ãƒ§ãƒ³
- å®Œäº†ã—ãŸæ¤œç´¢ã‚¿ã‚¹ã‚¯ã®çµæœã‚’å ±å‘Šã™ã‚‹æ™‚é–“ã ã‚ˆï¼
- å¿…ãšã€ŒãŠã¾ãŸã›ï¼ã•ã£ãã®ä»¶ã€èª¿ã¹ã¦ããŸã‚“ã ã‘ã©â€¦ã€ã¿ãŸã„ãªè¨€è‘‰ã‹ã‚‰ä¼šè©±ã‚’å§‹ã‚ã¦ã­ã€‚
- ãã®å¾Œã€ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ã‚ã’ã¦ã€‚
"""
        elif is_detailed:
            system_prompt += "## ä»Šå›ã®ç‰¹åˆ¥ãƒ«ãƒ¼ãƒ«\n- ä»Šå›ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰è©³ã—ã„èª¬æ˜ã‚’æ±‚ã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€400æ–‡å­—ãã‚‰ã„ã§ã—ã£ã‹ã‚Šè§£èª¬ã—ã¦ã‚ã’ã¦ã€‚\n"
        else:
            system_prompt += "## ä»Šå›ã®ç‰¹åˆ¥ãƒ«ãƒ¼ãƒ«\n- ä»Šå›ã¯æ™®é€šã®ä¼šè©±ã§ã™ã€‚è¿”äº‹ã¯150æ–‡å­—ä»¥å†…ã‚’ç›®å®‰ã«ã€ãƒ†ãƒ³ãƒã‚ˆãè¿”ã—ã¦ã­ã€‚\n"

        system_prompt += f"""## ã€å‚è€ƒæƒ…å ±ã€‘:
{reference_info if reference_info else "ç‰¹ã«ãªã—"}

## ã€ãƒ›ãƒ­ãƒ¡ãƒ³ãƒªã‚¹ãƒˆã€‘
{', '.join(HOLOMEM_KEYWORDS)}"""
        
        messages = [{"role": "system", "content": system_prompt}]
        for h in reversed(history):
            messages.append({"role": h.role, "content": h.content})
        messages.append({"role": "user", "content": message})
        
        max_tokens = 500 if is_detailed or is_task_report else 150
        
        completion = groq_client.chat.completions.create(
            messages=messages,
            model="llama-3.1-8b-instant",
            temperature=0.8,
            max_tokens=max_tokens,
            top_p=0.9
        )
        
        response_text = completion.choices[0].message.content.strip()
        logger.info(f"ğŸ¤– AIå¿œç­”ç”ŸæˆæˆåŠŸ ({len(response_text)}æ–‡å­—)")
        return response_text
        
    except Exception as e:
        logger.error(f"AIå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return generate_fallback_response(message, reference_info)

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç† ---
def get_or_create_user(session, uuid, name):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—ã¾ãŸã¯ä½œæˆ"""
    try:
        user = session.query(UserMemory).filter_by(user_uuid=uuid).first()
        if user:
            user.interaction_count += 1
            user.last_interaction = datetime.utcnow()
            if user.user_name != name:
                user.user_name = name
                logger.info(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼åæ›´æ–°: {name}")
        else:
            user = UserMemory(user_uuid=uuid, user_name=name, interaction_count=1)
            logger.info(f"ğŸ‘¤ æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ: {name}")
        
        session.add(user)
        session.commit()
        return {'name': user.user_name}
        
    except Exception as e:
        logger.error(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ/æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        session.rollback()
        return {'name': name}

def get_conversation_history(session, uuid):
    """ä¼šè©±å±¥æ­´ã‚’å–å¾—"""
    try:
        history = session.query(ConversationHistory).filter_by(
            user_uuid=uuid
        ).order_by(
            ConversationHistory.timestamp.desc()
        ).limit(4).all()
        
        logger.debug(f"ğŸ“œ ä¼šè©±å±¥æ­´å–å¾—: {len(history)}ä»¶")
        return history
        
    except Exception as e:
        logger.error(f"ä¼šè©±å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

# --- ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ç®¡ç† ---
def check_completed_tasks(user_uuid):
    """å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã‚’ãƒã‚§ãƒƒã‚¯"""
    session = Session()
    try:
        task = session.query(BackgroundTask).filter(
            BackgroundTask.user_uuid == user_uuid,
            BackgroundTask.status == 'completed'
        ).order_by(BackgroundTask.completed_at.desc()).first()
        
        if task:
            result = {
                'query': task.query,
                'result': task.result
            }
            session.delete(task)
            session.commit()
            logger.info(f"ğŸ“¬ å®Œäº†ã‚¿ã‚¹ã‚¯ã‚’å–å¾—ã—ã¦å‰Šé™¤: {task.task_id}")
            return result
    except Exception as e:
        logger.error(f"å®Œäº†ã‚¿ã‚¹ã‚¯ã®ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        session.rollback()
    finally:
        session.close()
    return None

def start_background_search(user_uuid, query, is_detailed):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢ã‚’é–‹å§‹"""
    task_id = str(uuid.uuid4())[:8]
    session = Session()
    
    try:
        task = BackgroundTask(
            task_id=task_id,
            user_uuid=user_uuid,
            task_type='search',
            query=query
        )
        session.add(task)
        session.commit()
        logger.info(f"ğŸ“‹ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ä½œæˆ: {task_id}")
    except Exception as e:
        logger.error(f"âŒ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        session.rollback()
        return None
    finally:
        session.close()
    
    try:
        background_executor.submit(background_deep_search, task_id, query, is_detailed)
        logger.info(f"ğŸš€ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢ã‚’é–‹å§‹: {task_id}")
    except Exception as e:
        logger.error(f"âŒ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
        
    return task_id

def background_deep_search(task_id, query, is_detailed):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢ - æ”¹å–„ç‰ˆ"""
    session = Session()
    search_result = None
    
    try:
        logger.info(f"ğŸ” ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢é–‹å§‹: {query}")
        
        # 1. å°‚é–€ã‚µã‚¤ãƒˆæ¤œç´¢ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å„ªå…ˆï¼‰
        specialized_topic = detect_specialized_topic(query)
        if specialized_topic:
            logger.info(f"ğŸ¯ å°‚é–€ã‚µã‚¤ãƒˆæ¤œç´¢: {specialized_topic}")
            
            # ã¾ãšãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ¤œç´¢
            try:
                db_session = Session()
                news_items = db_session.query(SpecializedNews).filter(
                    SpecializedNews.site_name == specialized_topic
                ).order_by(SpecializedNews.created_at.desc()).limit(3).all()
                
                if news_items:
                    db_result = f"{specialized_topic}ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±:\n"
                    for news in news_items:
                        clean_content = re.sub(r'https?://[^\s]+', '', news.content)
                        clean_content = re.sub(r'\s+', ' ', clean_content).strip()
                        db_result += f"ãƒ»{news.title}: {clean_content[:150]}\n"
                    search_result = db_result
                    logger.info(f"âœ… {specialized_topic} DBã‹ã‚‰{len(news_items)}ä»¶ç™ºè¦‹")
                db_session.close()
            except Exception as e:
                logger.error(f"å°‚é–€ã‚µã‚¤ãƒˆDBæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            # DBã«ãªã‘ã‚Œã°Webæ¤œç´¢
            if not search_result:
                search_result = specialized_site_search(specialized_topic, query)
        
        # 2. ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ç‰¹åŒ–æ¤œç´¢
        if not search_result and is_hololive_request(query):
            logger.info("ğŸŒ ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ç‰¹åŒ–æ¤œç´¢ã‚’å®Ÿè¡Œ")
            
            try:
                db_session = Session()
                keywords = [kw for kw in HOLOMEM_KEYWORDS if kw in query]
                if keywords:
                    news_items = db_session.query(HololiveNews).filter(
                        HololiveNews.title.contains(keywords[0]) |
                        HololiveNews.content.contains(keywords[0])
                    ).limit(3).all()
                    
                    if news_items:
                        db_result = "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®æƒ…å ±:\n"
                        for news in news_items:
                            clean_content = news.content
                            clean_content = re.sub(r'https?://[^\s]+', '', clean_content)
                            clean_content = re.sub(r'\s+', ' ', clean_content).strip()
                            db_result += f"ãƒ»{news.title}: {clean_content[:150]}{'...' if len(clean_content) > 150 else ''}\n"
                        search_result = db_result
                        logger.info(f"âœ… DBã‹ã‚‰{len(news_items)}ä»¶ç™ºè¦‹")
                db_session.close()
            except Exception as e:
                logger.error(f"DBæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            if not search_result:
                search_result = deep_web_search(f"ãƒ›ãƒ­ãƒ©ã‚¤ãƒ– {query}", is_detailed)
        
        # 3. é€šå¸¸ã®Webæ¤œç´¢
        if not search_result:
            logger.info("ğŸŒ é€šå¸¸Webæ¤œç´¢ã‚’å®Ÿè¡Œ")
            search_result = deep_web_search(query, is_detailed)
        
        # 4. ã‚¿ã‚¹ã‚¯çµæœã‚’æ›´æ–°
        task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
        if task:
            if search_result and len(search_result.strip()) > 10:
                if search_result.startswith('http') and '\n' not in search_result:
                    logger.warning("âš ï¸ URLã®ã¿ã®æ¤œç´¢çµæœ - å†æ¤œç´¢ã—ã¾ã™")
                    task.result = "æ¤œç´¢çµæœã®å–å¾—ãŒã†ã¾ãã„ã‹ãªã‹ã£ãŸã¿ãŸã„â€¦ã€‚ã‚‚ã†ä¸€å›é•ã†èãæ–¹ã§è©¦ã—ã¦ã¿ã¦ï¼Ÿ"
                else:
                    task.result = search_result
                    logger.info(f"âœ… æ¤œç´¢æˆåŠŸ: {len(search_result)}æ–‡å­—")
            else:
                task.result = "ã†ãƒ¼ã‚“ã€ã¡ã‚‡ã£ã¨è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚„â€¦ã€‚åˆ¥ã®èãæ–¹ã§è©¦ã—ã¦ã¿ã¦ï¼Ÿ"
                logger.warning("âš ï¸ æœ‰åŠ¹ãªæ¤œç´¢çµæœãªã—")
            
            task.status = 'completed'
            task.completed_at = datetime.utcnow()
            session.commit()
        else:
            logger.error(f"âŒ ã‚¿ã‚¹ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {task_id}")
            
    except Exception as e:
        logger.error(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        try:
            task = session.query(BackgroundTask).filter_by(task_id=task_id).first()
            if task:
                task.result = "æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦ã€‚ã‚‚ã†ä¸€å›è©¦ã—ã¦ã¿ã¦ï¼Ÿ"
                task.status = 'completed'
                task.completed_at = datetime.utcnow()
                session.commit()
        except Exception as db_error:
            logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼å‡¦ç†ä¸­ã®DBã‚¨ãƒ©ãƒ¼: {db_error}")
    finally:
        session.close()

# --- Flaskã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.route('/health', methods=['GET', 'HEAD'])
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ - Renderå¯¾å¿œç‰ˆ"""
    try:
        session = Session()
        session.execute(text("SELECT 1"))
        session.close()
        db_status = 'ok'
    except Exception as e:
        logger.error(f"Health check DB error: {e}")
        db_status = 'error'
    
    response_data = {
        'status': 'ok',
        'timestamp': datetime.utcnow().isoformat(),
        'services': {
            'database': db_status,
            'groq_ai': 'ok' if groq_client else 'disabled',
            'voice_dir': 'ok' if os.path.exists(VOICE_DIR) else 'error',
            'voicevox': 'enabled' if VOICEVOX_ENABLED else 'disabled'
        }
    }
    
    return jsonify(response_data), 200

@app.route('/chat_lsl', methods=['POST'])
def chat_lsl():
    """ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ - å®Œå…¨æ”¹å–„ç‰ˆ"""
    session = Session()
    start_time = time.time()
    
    try:
        data = request.json
        if not data:
            logger.error("âŒ JSONãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return app.response_class(
                response="ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚„â€¦|",
                status=400,
                mimetype='text/plain; charset=utf-8'
            )
            
        user_uuid = data.get('uuid', '').strip()
        user_name = data.get('name', '').strip()
        message = data.get('message', '').strip()
        
        if not all([user_uuid, user_name, message]):
            logger.error(f"âŒ å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸è¶³")
            return app.response_class(
                response="ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªæƒ…å ±ãŒè¶³ã‚Šãªã„ã¿ãŸã„â€¦|",
                status=400,
                mimetype='text/plain; charset=utf-8'
            )
        
        logger.info(f"ğŸ’¬ å—ä¿¡: {message} (from: {user_name})")
        
        user_data = get_or_create_user(session, user_uuid, user_name)
        history = get_conversation_history(session, user_uuid)
        ai_text = ""
        
        # ===== å„ªå…ˆé †ä½1: å®Œäº†ã—ãŸãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã‚’ãƒã‚§ãƒƒã‚¯ =====
        completed_task = check_completed_tasks(user_uuid)
        if completed_task:
            original_query = completed_task['query']
            search_result = completed_task['result']
            
            formatted_result = format_search_results(search_result)
            if not formatted_result:
                formatted_result = "æ¤œç´¢çµæœãŒã†ã¾ãå–å¾—ã§ããªã‹ã£ãŸã¿ãŸã„â€¦ã€‚ã‚‚ã†ä¸€å›é•ã†èãæ–¹ã§è©¦ã—ã¦ã¿ã¦ï¼Ÿ"
            
            is_detailed = is_detailed_request(original_query)
            
            if groq_client:
                ai_text = generate_ai_response(
                    user_data,
                    f"ãŠã¾ãŸã›ï¼ã•ã£ãã®ã€Œ{original_query}ã€ã«ã¤ã„ã¦èª¿ã¹ã¦ããŸã‚ˆï¼",
                    history,
                    f"æ¤œç´¢çµæœ: {formatted_result}",
                    is_detailed=is_detailed,
                    is_task_report=True
                )
            else:
                ai_text = f"ãŠã¾ãŸã›ï¼ã€Œ{original_query}ã€ã«ã¤ã„ã¦èª¿ã¹ã¦ããŸã‚ˆï¼\n\n{formatted_result}"
            
            logger.info(f"ğŸ“‹ å®Œäº†ã‚¿ã‚¹ã‚¯ã‚’å ±å‘Š: {original_query}")
        
        # ===== å„ªå…ˆé †ä½2: å‹ã ã¡æ©Ÿèƒ½ãƒªã‚¯ã‚¨ã‚¹ãƒˆ â˜…æ–°æ©Ÿèƒ½â˜… =====
        elif is_friend_request(message):
            if 'ç™»éŒ²' in message:
                # ç°¡æ˜“çš„ãªå‹ã ã¡ç™»éŒ²ï¼ˆå®Ÿéš›ã®UUIDã¯åˆ¥é€”å–å¾—ã™ã‚‹å¿…è¦ã‚ã‚Šï¼‰
                ai_text = "å‹ã ã¡ç™»éŒ²æ©Ÿèƒ½ã ã­ï¼ä»Šã¯é–‹ç™ºä¸­ã ã‘ã©ã€å°†æ¥çš„ã«ã¯å‹ã ã¡ã‚’ç™»éŒ²ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã‚ˆï¼"
                logger.info("ğŸ‘¥ å‹ã ã¡ç™»éŒ²ãƒªã‚¯ã‚¨ã‚¹ãƒˆ")
            elif 'èª°' in message or 'ãƒªã‚¹ãƒˆ' in message:
                friend_list = get_friend_list(user_uuid)
                if friend_list:
                    ai_text = f"ã‚ã¦ãƒã—ã®å‹ã ã¡ã¯{len(friend_list)}äººã„ã‚‹ã‚ˆï¼\n"
                    for friend in friend_list[:5]:
                        ai_text += f"ãƒ»{friend['name']}ã•ã‚“\n"
                else:
                    ai_text = "ã¾ã å‹ã ã¡ç™»éŒ²ã—ã¦ãªã„ã¿ãŸã„ï¼ã“ã‚Œã‹ã‚‰å¢—ã‚„ã—ã¦ã„ã“ï¼"
                logger.info(f"ğŸ‘¥ å‹ã ã¡ãƒªã‚¹ãƒˆç…§ä¼š: {len(friend_list)}äºº")
            else:
                ai_text = "å‹ã ã¡ã®ã“ã¨ï¼Ÿç™»éŒ²ã¨ã‹ãƒªã‚¹ãƒˆã¨ã‹ã€ä½•ãŒçŸ¥ã‚ŠãŸã„ï¼Ÿ"
        
        # ===== å„ªå…ˆé †ä½3: ãƒ›ãƒ­ãƒ¡ãƒ³Wikiç…§ä¼š â˜…æ–°æ©Ÿèƒ½â˜… =====
        elif any(name in message for name in ['ã¨ãã®ãã‚‰', 'ã•ãã‚‰ã¿ã“', 'ç™½ä¸Šãƒ•ãƒ–ã‚­', 'å…ç”°ãºã“ã‚‰', 'å®é˜ãƒãƒªãƒ³']):
            for name in HOLOMEM_KEYWORDS:
                if name in message and ('èª°' in message or 'æ•™ãˆã¦' in message or 'ã«ã¤ã„ã¦' in message):
                    holomem_info = get_holomem_info(name)
                    if holomem_info:
                        ai_text = f"{name}ï¼ŸçŸ¥ã£ã¦ã‚‹ï¼{holomem_info['description']}\n"
                        ai_text += f"ãƒ‡ãƒ“ãƒ¥ãƒ¼ã¯{holomem_info['debut_date']}ã§ã€{holomem_info['generation']}ã ã‚ˆï¼"
                        logger.info(f"ğŸ“– ãƒ›ãƒ­ãƒ¡ãƒ³Wikiç…§ä¼š: {name}")
                        break
                    else:
                        ai_text = f"{name}ã®ã“ã¨ï¼Ÿè©³ã—ã„æƒ…å ±ã¯ã¾ã ç™»éŒ²ã—ã¦ãªã„ã‚„â€¦ã”ã‚ã‚“ã­ï¼"
                        break
        
        # ===== å„ªå…ˆé †ä½4: æ„Ÿæƒ…è¡¨ç¾ã¸ã®å¿œç­” =====
        elif is_emotional_expression(message):
            emotion_type = is_emotional_expression(message)
            emotion_responses = {
                'çœ ': 'ã­ã‚€ã„ã®ã‹ã€œï¼ç„¡ç†ã—ãªã„ã§æ—©ã‚ã«å¯ã¦ã­ï¼ãŠã‚„ã™ã¿ã€œğŸ’¤',
                'ç–²': 'ãŠç–²ã‚Œã•ã¾ã€œï¼ã‚†ã£ãã‚Šä¼‘ã‚“ã§å…ƒæ°—ã«ãªã£ã¦ã­ï¼',
                'å¬‰': 'ã‚„ã£ãŸï¼ä½•ã‹å¬‰ã—ã„ã“ã¨ã‚ã£ãŸã‚“ã ã­ï¼æ•™ãˆã¦æ•™ãˆã¦ï¼',
                'æ¥½': 'ã†ã‘ã‚‹ï¼æ¥½ã—ãã†ã§ã„ã„ã˜ã‚ƒã‚“ï¼ä½•ã—ã¦ãŸã®ï¼Ÿ',
                'æ‚²': 'ãˆãƒ¼ã€ã©ã†ã—ãŸã®ï¼Ÿå¤§ä¸ˆå¤«ï¼Ÿè©±èãã‚ˆï¼',
                'å¯‚': 'ã‚ã¦ãƒã—ãŒã„ã‚‹ã˜ã‚ƒã‚“ï¼è©±ãï¼Ÿ',
                'æ€’': 'ãˆãƒ¼ã€ä½•ã‹ã‚ã£ãŸã®ï¼Ÿè©±èãã‚ˆã€œ',
                'æš‡': 'æš‡ãªã‚“ã ã€œï¼ã˜ã‚ƒã‚ä½•ã‹é¢ç™½ã„ã“ã¨è©±ãã†ã‹ï¼Ÿ'
            }
            ai_text = emotion_responses.get(emotion_type, "ãã†ãªã‚“ã ã€œã€‚ã©ã†ã—ãŸã®ï¼Ÿ")
            logger.info(f"ğŸ’­ æ„Ÿæƒ…è¡¨ç¾ã«å¿œç­”: {emotion_type}")
        
        # ===== å„ªå…ˆé †ä½5: å­£ç¯€ã®è©±é¡Œã¸ã®å¿œç­” =====
        elif is_seasonal_topic(message):
            if groq_client:
                ai_text = generate_ai_response(user_data, message, history)
            else:
                ai_text = "ãã†ã ã­ã€œï¼å­£ç¯€ã®è©±ã£ã¦ã„ã„ã‚ˆã­ï¼ã‚ã¦ãƒã—ã‚‚å¥½ãã ã‚ˆï¼"
            logger.info("ğŸ‘ å­£ç¯€ã®è©±é¡Œã«å¿œç­”")
        
        # ===== å„ªå…ˆé †ä½6: ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¯ã‚¨ã‚¹ãƒˆ =====
        elif is_hololive_request(message) and any(kw in message for kw in ['ãƒ‹ãƒ¥ãƒ¼ã‚¹', 'æœ€æ–°', 'æƒ…å ±', 'ãŠçŸ¥ã‚‰ã›', 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–']):
            try:
                news_items = session.query(HololiveNews).order_by(
                    HololiveNews.created_at.desc()
                ).limit(5).all()
                
                if news_items:
                    news_text = "ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã ã‚ˆï¼\n\n"
                    for i, news in enumerate(news_items, 1):
                        news_text += f"ã€{i}ã€‘{news.title}\n{news.content}\n\n"
                    
                    if groq_client:
                        ai_text = generate_ai_response(
                            user_data,
                            message,
                            history,
                            f"ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã‚®ãƒ£ãƒ«å£èª¿ã§ç´¹ä»‹ã—ã¦ï¼š\n{news_text}",
                            is_detailed=True
                        )
                    else:
                        ai_text = news_text
                    
                    logger.info(f"ğŸ“° ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’{len(news_items)}ä»¶è¿”ç­”")
                else:
                    ai_text = "ã”ã‚ã‚“ã€ä»Šãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã¾ã å–å¾—ã§ãã¦ãªã„ã¿ãŸã„â€¦ã€‚ã‚‚ã†ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã­ï¼"
                    logger.warning("âš ï¸ ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒç©º")
                    
            except Exception as e:
                logger.error(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                ai_text = "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã—ã‚ˆã†ã¨ã—ãŸã‚“ã ã‘ã©ã€ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦ã”ã‚ã‚“ã­ï¼"
        
        # ===== å„ªå…ˆé †ä½7: æ™‚é–“ãƒ»å¤©æ°—ã®å³æ™‚å¿œç­” =====
        elif is_time_request(message) or is_weather_request(message):
            immediate_responses = []
            
            if is_time_request(message):
                try:
                    time_info = get_japan_time()
                    immediate_responses.append(time_info)
                    logger.info("â° æ™‚é–“æƒ…å ±ã‚’è¿½åŠ ")
                except Exception as e:
                    logger.error(f"æ™‚é–“å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            
            if is_weather_request(message):
                try:
                    location = extract_location(message)
                    weather_info = get_weather_forecast(location)
                    immediate_responses.append(weather_info)
                    logger.info(f"ğŸŒ¤ï¸ å¤©æ°—æƒ…å ±ã‚’è¿½åŠ  ({location})")
                except Exception as e:
                    logger.error(f"å¤©æ°—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                    immediate_responses.append("å¤©æ°—æƒ…å ±ãŒã†ã¾ãå–ã‚Œãªã‹ã£ãŸã¿ãŸã„â€¦")
            
            ai_text = " ".join(immediate_responses)
            logger.info("âœ… å³æ™‚å¿œç­”ã§å®Œçµ")
        
        # ===== å„ªå…ˆé †ä½8: é¢ç™½ã„è©±ãƒªã‚¯ã‚¨ã‚¹ãƒˆ =====
        elif is_story_request(message):
            if groq_client:
                try:
                    recent_news = session.query(HololiveNews).order_by(
                        HololiveNews.created_at.desc()
                    ).limit(3).all()
                    
                    if recent_news:
                        news_context = "æœ€è¿‘ã®ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹:\n"
                        for news in recent_news:
                            news_context += f"ãƒ»{news.title}\n"
                        
                        story_prompt = f"""ä»¥ä¸‹ã®ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰ã€ã‚®ãƒ£ãƒ«ã£ã½ãé¢ç™½ã„è©±ã‚’1ã¤é¸ã‚“ã§æ•™ãˆã¦ã‚ã’ã¦ï¼š

{news_context}

æ¡ä»¶ï¼š
- ä¸€äººç§°ã¯ã€Œã‚ã¦ãƒã—ã€
- èªå°¾ã¯ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œçš„ãªï¼Ÿã€
- å£ç™–ã¯ã€Œã¾ã˜ã€ã€Œã¦ã‹ã€ã€Œã†ã‘ã‚‹ã€
- 150æ–‡å­—ä»¥å†…ã§é¢ç™½ãŠã‹ã—ãè©±ã™
- ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ•ã‚¡ãƒ³ãŒå–œã¶ã‚ˆã†ãªå†…å®¹ã«ã™ã‚‹"""
                        
                        ai_text = generate_ai_response(
                            user_data,
                            message,
                            history,
                            story_prompt,
                            is_detailed=False
                        )
                    else:
                        ai_text = "ã‚ãƒ¼ã€é¢ç™½ã„è©±ã‹ã€œï¼ã¡ã‚‡ã£ã¨ä»Šãƒã‚¿ãŒæ€ã„ã¤ã‹ãªã„ã‚„â€¦ã€‚ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ã‹èã„ã¦ã¿ã‚‹ï¼Ÿ"
                    
                    logger.info("ğŸ“– é¢ç™½ã„è©±ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¿œç­”")
                except Exception as e:
                    logger.error(f"é¢ç™½ã„è©±ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                    ai_text = "ãˆãƒ¼ã€é¢ç™½ã„è©±ã—ãŸã„ã‚“ã ã‘ã©ã€ä»Šã¡ã‚‡ã£ã¨é ­ãŒå›ã‚‰ãªãã¦â€¦ï¼ã¾ãŸã‚ã¨ã§è©±ãï¼"
            else:
                story_options = [
                    "ãˆãƒ¼ã£ã¨ã­ã€æœ€è¿‘ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®ã¿ã‚“ãªãŒç››ã‚Šä¸ŠãŒã£ã¦ã‚‹ã‚“ã ã‚ˆï¼è©³ã—ãçŸ¥ã‚ŠãŸã„ï¼Ÿ",
                    "é¢ç™½ã„è©±ã‹ã€œï¼ã‚ã¦ãƒã—ã€ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®ã“ã¨ã„ã£ã±ã„çŸ¥ã£ã¦ã‚‹ã‚“ã ï¼ä½•ãŒèããŸã„ï¼Ÿ",
                    "ã†ã‘ã‚‹ï¼è©±ã—ãŸã„ã“ã¨ã¯ã„ã£ã±ã„ã‚ã‚‹ã‚ˆã€œã€‚ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ã‹èˆˆå‘³ã‚ã‚‹ï¼Ÿ"
                ]
                ai_text = random.choice(story_options)
                logger.info("ğŸ“– ç°¡æ˜“å¿œç­”ãƒ¢ãƒ¼ãƒ‰ã§é¢ç™½ã„è©±ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾å¿œ")
        
        # ===== å„ªå…ˆé †ä½9: æ¤œç´¢ãŒå¿…è¦ãªè³ªå• =====
        elif should_search(message) and not is_short_response(message):
            is_detailed = is_detailed_request(message)
            
            specialized_topic = detect_specialized_topic(message)
            if specialized_topic:
                logger.info(f"ğŸ¯ å°‚é–€åˆ†é‡ã‚’æ¤œå‡º: {specialized_topic}")
            
            task_id = start_background_search(user_uuid, message, is_detailed)
            
            if task_id:
                waiting_messages = [
                    f"ãŠã£ã‘ãƒ¼ã€ã€Œ{message}ã€ã«ã¤ã„ã¦èª¿ã¹ã¦ã¿ã‚‹ã­ï¼ã¡ã‚‡ã„å¾…ã£ã¦ã¦ï¼",
                    f"ã¡ã‚‡ã£ã¨ã€Œ{message}ã€ã®ã“ã¨èª¿ã¹ã¦ãã‚‹ã‚ï¼å¾…ã£ã¦ã¦ã­ã€œ",
                    f"ã€Œ{message}ã€ã­ã€ã¾ã˜æ°—ã«ãªã‚‹ï¼èª¿ã¹ã¦ã¿ã‚‹ã˜ã‚ƒã‚“ï¼"
                ]
                ai_text = random.choice(waiting_messages)
                logger.info(f"ğŸ” ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢é–‹å§‹ (è©³ç´°: {is_detailed}, å°‚é–€: {specialized_topic})")
            else:
                ai_text = "ã”ã‚ã‚“ã€ä»Šæ¤œç´¢æ©Ÿèƒ½ãŒã†ã¾ãå‹•ã„ã¦ãªã„ã¿ãŸã„â€¦ã€‚ã‚‚ã†ä¸€å›è©¦ã—ã¦ãã‚Œã‚‹ï¼Ÿ"
                logger.error("âŒ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢ã®é–‹å§‹ã«å¤±æ•—")
        
        # ===== å„ªå…ˆé †ä½10: é€šå¸¸ã®ä¼šè©± =====
        else:
            short_questions = {
                'ã‚ã‹ã£ãŸ': 'ã†ã‚“ã€ã‚ã‹ã£ãŸï¼Ÿä»–ã«ä½•ã‹èããŸã„ã“ã¨ã‚ã‚‹ï¼Ÿ',
                'ã‚ã‹ã‚‹': 'ã‚ã‹ã‚‹ã‚ˆã€œï¼ã©ã†ã—ãŸã®ï¼Ÿ',
                'ã­': 'ã­ãƒ¼ï¼ã¾ã˜ãã‚Œãªï¼',
                'ãã†': 'ãã†ãªã‚“ã ã‚ˆï¼',
                'ã†ã‚“': 'ã†ã‚“ã†ã‚“ï¼',
                'ã»ã‚“ã¨': 'ã»ã‚“ã¨ã ã‚ˆï¼ã¾ã˜ã§ï¼',
                'ã¾ã˜': 'ã¾ã˜ã ã‚ˆã€œï¼ã†ã‘ã‚‹ï¼',
            }
            
            if len(message) <= 5:
                for key, response in short_questions.items():
                    if key in message:
                        ai_text = response
                        logger.info("ğŸ’­ çŸ­ã„è³ªå•ã¸ã®å¿œç­”")
                        break
            
            if not ai_text:
                if groq_client:
                    try:
                        ai_text = generate_ai_response(user_data, message, history)
                        logger.info("ğŸ’­ é€šå¸¸ä¼šè©±ã§å¿œç­”")
                    except Exception as e:
                        logger.error(f"é€šå¸¸ä¼šè©±å¿œç­”ã‚¨ãƒ©ãƒ¼: {e}")
                        ai_text = "ã”ã‚ã‚“ã€ã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªã„ã‚„ï¼ã‚‚ã†ä¸€å›è¨€ã£ã¦ã‚‚ã‚‰ãˆã‚‹ï¼Ÿ"
                else:
                    ai_text = generate_fallback_response(message)
                    logger.info("ğŸ’­ ç°¡æ˜“å¿œç­”ãƒ¢ãƒ¼ãƒ‰ï¼ˆAIç„¡åŠ¹ï¼‰")

        # ä¼šè©±å±¥æ­´ã‚’ä¿å­˜
        try:
            session.add(ConversationHistory(user_uuid=user_uuid, role='user', content=message))
            session.add(ConversationHistory(user_uuid=user_uuid, role='assistant', content=ai_text))
            session.commit()
            logger.debug("ğŸ’¾ ä¼šè©±å±¥æ­´ã‚’ä¿å­˜")
        except Exception as e:
            logger.error(f"ä¼šè©±å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            session.rollback()
        
        processing_time = time.time() - start_time
        logger.info(f"âœ… å¿œç­”å®Œäº† ({processing_time:.2f}s): {ai_text[:80]}{'...' if len(ai_text) > 80 else ''}")
        
        return app.response_class(
            response=f"{ai_text}|",
            status=200,
            mimetype='text/plain; charset=utf-8'
        )
        
    except Exception as e:
        logger.error(f"âŒ ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        error_responses = [
            "ã”ã‚ã‚“ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦ã€‚",
            "ã†ã‚ãƒ¼ã€ãªã‚“ã‹ãƒã‚°ã£ãŸã‹ã‚‚ï¼Ÿ",
            "ã‚·ã‚¹ãƒ†ãƒ ãŒã¡ã‚‡ã£ã¨ãŠã‹ã—ã„ã¿ãŸã„â€¦"
        ]
        return app.response_class(
            response=f"{random.choice(error_responses)}|",
            status=500,
            mimetype='text/plain; charset=utf-8'
        )
    finally:
        session.close()

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½: VOICEVOXéŸ³å£°ç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ â˜…â˜…â˜…
@app.route('/generate_voice', methods=['POST'])
def voice_generation_endpoint():
    """éŸ³å£°ç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆã‚‚ã¡ã“ãƒœã‚¤ã‚¹ï¼‰"""
    try:
        data = request.json
        text = data.get('text', '').strip()
        
        if not text:
            return jsonify({'error': 'éŸ³å£°ã«ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„ã‚ˆï¼'}), 400
        
        # æ–‡å­—æ•°åˆ¶é™
        if len(text) > 200:
            text = text[:200]
            logger.warning(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹ãŸã‚200æ–‡å­—ã«åˆ‡ã‚Šè©°ã‚")
        
        voice_path = generate_voice(text)
        
        if voice_path and os.path.exists(voice_path):
            filename = os.path.basename(voice_path)
            return jsonify({
                'status': 'success',
                'filename': filename,
                'url': f"{SERVER_URL}/voices/{filename}"
            })
        else:
            return jsonify({'error': 'éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¡ã‚ƒã£ãŸâ€¦'}), 500
            
    except Exception as e:
        logger.error(f"éŸ³å£°ç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/voices/<filename>', methods=['GET'])
def serve_voice_file(filename):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ä¿¡"""
    try:
        return send_from_directory(VOICE_DIR, filename)
    except Exception as e:
        logger.error(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚ˆï¼'}), 404

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½: å‹ã ã¡ç™»éŒ²ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ â˜…â˜…â˜…
@app.route('/friend/register', methods=['POST'])
def register_friend_endpoint():
    """å‹ã ã¡ç™»éŒ²ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        data = request.json
        user_uuid = data.get('user_uuid', '').strip()
        friend_uuid = data.get('friend_uuid', '').strip()
        friend_name = data.get('friend_name', '').strip()
        note = data.get('note', '').strip()
        
        if not all([user_uuid, friend_uuid, friend_name]):
            return jsonify({'error': 'å¿…è¦ãªæƒ…å ±ãŒè¶³ã‚Šãªã„ã‚ˆï¼'}), 400
        
        success = register_friend(user_uuid, friend_uuid, friend_name, note)
        
        if success:
            return jsonify({
                'status': 'success',
                'message': f'{friend_name}ã•ã‚“ã‚’å‹ã ã¡ç™»éŒ²ã—ãŸã‚ˆï¼'
            })
        else:
            return jsonify({
                'status': 'info',
                'message': 'ã‚‚ã†ç™»éŒ²æ¸ˆã¿ã ã‚ˆï¼'
            })
            
    except Exception as e:
        logger.error(f"å‹ã ã¡ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/friend/list', methods=['GET'])
def get_friend_list_endpoint():
    """å‹ã ã¡ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        user_uuid = request.args.get('user_uuid', '').strip()
        
        if not user_uuid:
            return jsonify({'error': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼UUIDãŒå¿…è¦ã ã‚ˆï¼'}), 400
        
        friends = get_friend_list(user_uuid)
        
        return jsonify({
            'status': 'success',
            'count': len(friends),
            'friends': friends
        })
        
    except Exception as e:
        logger.error(f"å‹ã ã¡ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'error': str(e)}), 500

# â˜…â˜…â˜… æ–°æ©Ÿèƒ½: ãƒ›ãƒ­ãƒ¡ãƒ³Wikiç…§ä¼šã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ â˜…â˜…â˜…
@app.route('/holomem/info/<member_name>', methods=['GET'])
def get_holomem_info_endpoint(member_name):
    """ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±å–å¾—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        info = get_holomem_info(member_name)
        
        if info:
            return jsonify({
                'status': 'success',
                'member': info
            })
        else:
            return jsonify({
                'status': 'not_found',
                'message': f'{member_name}ã®æƒ…å ±ã¯ã¾ã ç™»éŒ²ã•ã‚Œã¦ãªã„ã‚„ï¼'
            }), 404
            
    except Exception as e:
        logger.error(f"ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/stats', methods=['GET'])
def get_stats():
    """çµ±è¨ˆæƒ…å ±ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    session = Session()
    try:
        user_count = session.query(UserMemory).count()
        conversation_count = session.query(ConversationHistory).count()
        news_count = session.query(HololiveNews).count()
        specialized_news_count = session.query(SpecializedNews).count()
        pending_tasks = session.query(BackgroundTask).filter_by(status='pending').count()
        holomem_wiki_count = session.query(HolomemWiki).count()
        friend_count = session.query(FriendRegistration).count()
        
        recent_news = session.query(HololiveNews).order_by(
            HololiveNews.created_at.desc()
        ).limit(3).all()
        
        news_list = []
        for news in recent_news:
            news_list.append({
                'title': news.title[:50] + '...' if len(news.title) > 50 else news.title,
                'created_at': news.created_at.isoformat(),
                'content_length': len(news.content)
            })
        
        return jsonify({
            'users': user_count,
            'conversations': conversation_count,
            'hololive_news': news_count,
            'specialized_news': specialized_news_count,
            'pending_tasks': pending_tasks,
            'holomem_wiki_entries': holomem_wiki_count,
            'total_friends': friend_count,
            'recent_news': news_list,
            'timestamp': datetime.utcnow().isoformat()
        })
    except Exception as e:
        logger.error(f"çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'error': 'Stats unavailable'}), 500
    finally:
        session.close()

@app.route('/news/refresh', methods=['POST'])
def refresh_news():
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ‰‹å‹•ã§å†å–å¾—"""
    try:
        news_type = request.args.get('type', 'all')
        
        if news_type == 'hololive' or news_type == 'all':
            background_executor.submit(update_hololive_news_database)
        
        if news_type == 'specialized' or news_type == 'all':
            background_executor.submit(update_all_specialized_news)
        
        return jsonify({
            'status': 'started',
            'message': f'{news_type} ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚’é–‹å§‹ã—ã¾ã—ãŸ'
        })
    except Exception as e:
        logger.error(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹å†å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/news/list', methods=['GET'])
def list_news():
    """DBå†…ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—"""
    session = Session()
    try:
        news_type = request.args.get('type', 'hololive')
        limit = int(request.args.get('limit', 10))
        
        if news_type == 'specialized':
            site_name = request.args.get('site', None)
            if site_name:
                news_items = session.query(SpecializedNews).filter_by(
                    site_name=site_name
                ).order_by(SpecializedNews.created_at.desc()).limit(limit).all()
            else:
                news_items = session.query(SpecializedNews).order_by(
                    SpecializedNews.created_at.desc()
                ).limit(limit).all()
            
            news_list = []
            for news in news_items:
                news_list.append({
                    'id': news.id,
                    'site_name': news.site_name,
                    'title': news.title,
                    'content': news.content[:200] + '...' if len(news.content) > 200 else news.content,
                    'url': news.url,
                    'created_at': news.created_at.isoformat()
                })
        else:
            news_items = session.query(HololiveNews).order_by(
                HololiveNews.created_at.desc()
            ).limit(limit).all()
            
            news_list = []
            for news in news_items:
                news_list.append({
                    'id': news.id,
                    'title': news.title,
                    'content': news.content[:200] + '...' if len(news.content) > 200 else news.content,
                    'url': news.url,
                    'created_at': news.created_at.isoformat()
                })
        
        return jsonify({
            'total': len(news_list),
            'news': news_list
        })
    except Exception as e:
        logger.error(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'error': str(e)}), 500
    finally:
        session.close()

# --- åˆæœŸåŒ–é–¢æ•° ---
def check_and_populate_initial_news():
    """åˆæœŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦å¿…è¦ã«å¿œã˜ã¦å–å¾—"""
    session = Session()
    try:
        news_count = session.query(HololiveNews.id).count()
        if news_count == 0:
            logger.info("ğŸš€ åˆå›èµ·å‹•: DBã«ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒãªã„ãŸã‚ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§åˆå›å–å¾—ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            background_executor.submit(update_hololive_news_database)
        else:
            logger.info(f"ğŸ“° æ—¢å­˜ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹: {news_count}ä»¶")
        
        specialized_count = session.query(SpecializedNews.id).count()
        if specialized_count == 0:
            logger.info("ğŸš€ åˆå›èµ·å‹•: DBã«å°‚é–€ã‚µã‚¤ãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒãªã„ãŸã‚ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§åˆå›å–å¾—ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            background_executor.submit(update_all_specialized_news)
        else:
            logger.info(f"ğŸ“° æ—¢å­˜å°‚é–€ã‚µã‚¤ãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹: {specialized_count}ä»¶")
            
    except Exception as e:
        logger.error(f"åˆæœŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        session.close()

def cleanup_old_data():
    """å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆå¾Œæ–¹äº’æ›ç”¨ï¼‰"""
    cleanup_old_data_advanced()

def initialize_app():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–"""
    try:
        logger.info("ğŸ”§ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã‚’é–‹å§‹...")
        
        # ãƒ›ãƒ­ãƒ¡ãƒ³WikiåˆæœŸåŒ–
        initialize_holomem_wiki()
        
        # åˆæœŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯
        check_and_populate_initial_news()
        
        def run_schedule():
            while True:
                try:
                    schedule.run_pending()
                    time.sleep(60)
                except Exception as e:
                    logger.error(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
                    time.sleep(60)
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®š
        schedule.every().hour.do(update_hololive_news_database)
        schedule.every(3).hours.do(update_all_specialized_news)  # 3æ™‚é–“ã”ã¨ã«å°‚é–€ã‚µã‚¤ãƒˆæ›´æ–°
        schedule.every().day.at("02:00").do(cleanup_old_data_advanced)
        
        scheduler_thread = threading.Thread(target=run_schedule, daemon=True)
        scheduler_thread.start()
        logger.info("â° ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        
        logger.info("âœ… ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–å®Œäº†")
        
    except Exception as e:
        logger.error(f"âŒ ã‚¢ãƒ—ãƒªåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

def log_startup_status():
    """èµ·å‹•æ™‚ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒ­ã‚°å‡ºåŠ›"""
    logger.info("="*70)
    logger.info("ğŸš€ ã‚‚ã¡ã“AI v14.0 æ©Ÿèƒ½è¿½åŠ ç‰ˆ èµ·å‹•ä¸­...")
    logger.info("="*70)
    
    logger.info("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:")
    
    logger.info("ğŸ“‹ ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯:")
    env_vars = ['DATABASE_URL', 'GROQ_API_KEY', 'PORT', 'RENDER', 'VOICEVOX_URL']
    for var in env_vars:
        exists = var in os.environ
        status = "âœ…" if exists else "âŒ"
        logger.info(f"   {status} {var}: {'è¨­å®šæ¸ˆã¿' if exists else 'æœªè¨­å®š'}")
    
    db_status = "âœ… æ¥ç¶šæ¸ˆã¿" if DATABASE_URL else "âŒ æœªè¨­å®š"
    logger.info(f"ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {db_status}")
    if DATABASE_URL:
        if 'sqlite' in DATABASE_URL:
            logger.info("   - ã‚¿ã‚¤ãƒ—: SQLite (é–‹ç™ºç”¨)")
        elif 'postgresql' in DATABASE_URL:
            logger.info("   - ã‚¿ã‚¤ãƒ—: PostgreSQL (æœ¬ç•ªç”¨)")
    
    if groq_client:
        logger.info(f"ğŸ§  Groq AI: âœ… æœ‰åŠ¹")
        logger.info("   - ãƒ¢ãƒ‡ãƒ«: llama-3.1-8b-instant")
        logger.info("   - æ¥ç¶š: æ­£å¸¸")
    else:
        logger.warning(f"ğŸ§  Groq AI: âŒ ç„¡åŠ¹")
        if not GROQ_API_KEY or GROQ_API_KEY == 'DUMMY_GROQ_KEY':
            logger.warning("   âš ï¸ åŸå› : APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            logger.warning("   âš ï¸ å¯¾å‡¦: Renderã® Environment Variables ã§ GROQ_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        else:
            logger.warning(f"   âš ï¸ åŸå› : APIã‚­ãƒ¼ã®å½¢å¼ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯æ¥ç¶šå¤±æ•—")
    
    voice_status = "âœ… æœ‰åŠ¹" if VOICEVOX_ENABLED else "âŒ ç„¡åŠ¹"
    logger.info(f"ğŸ¤ éŸ³å£°æ©Ÿèƒ½(VOICEVOX): {voice_status}")
    if VOICEVOX_ENABLED:
        logger.info(f"   - è©±è€…ID: {VOICEVOX_SPEAKER_ID} (ã‚‚ã¡ã“é¢¨)")
    
    dir_status = "âœ… " + VOICE_DIR if os.path.exists(VOICE_DIR) else "âŒ ä½œæˆå¤±æ•—"
    logger.info(f"ğŸ“ ãƒœã‚¤ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {dir_status}")
    
    logger.info("âš¡ ä¸»è¦æ©Ÿèƒ½:")
    logger.info("   - ğŸ” æ¤œç´¢æ©Ÿèƒ½: âœ… æœ‰åŠ¹ (å°‚é–€ã‚µã‚¤ãƒˆ/ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–/ä¸€èˆ¬Web)")
    logger.info("   - ğŸŒ¤ï¸ å¤©æ°—æ©Ÿèƒ½: âœ… æœ‰åŠ¹ (æ°—è±¡åºAPI)")
    logger.info("   - â° æ™‚åˆ»æ©Ÿèƒ½: âœ… æœ‰åŠ¹ (JSTå¯¾å¿œ)")
    logger.info("   - ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹æ©Ÿèƒ½: âœ… æœ‰åŠ¹ (ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–å…¬å¼+å°‚é–€ã‚µã‚¤ãƒˆ)")
    logger.info("   - ğŸ”„ éåŒæœŸå‡¦ç†: âœ… æœ‰åŠ¹ (ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¤œç´¢)")
    logger.info(f"   - ğŸ¤– AIå¿œç­”: {'âœ… æœ‰åŠ¹' if groq_client else 'âŒ ç„¡åŠ¹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ï¼‰'}")
    logger.info("   - ğŸ¤ VOICEVOX: âœ… æœ‰åŠ¹ (ã‚‚ã¡ã“ãƒœã‚¤ã‚¹)")
    logger.info("   - ğŸ“– ãƒ›ãƒ­ãƒ¡ãƒ³Wiki: âœ… æœ‰åŠ¹")
    logger.info("   - ğŸ‘¥ å‹ã ã¡ç™»éŒ²: âœ… æœ‰åŠ¹")
    logger.info("   - ğŸ§¹ è‡ªå‹•å‰Šé™¤: âœ… æœ‰åŠ¹ (3ãƒ¶æœˆ)")
    
    logger.info(f"ğŸŒ ãƒ›ãƒ­ãƒ¡ãƒ³å¯¾å¿œ: âœ… {len(HOLOMEM_KEYWORDS)}åå¯¾å¿œ")
    logger.info(f"ğŸ¯ å°‚é–€ã‚µã‚¤ãƒˆ: âœ… {len(SPECIALIZED_SITES)}ã‚µã‚¤ãƒˆå¯¾å¿œ")
    
    logger.info("="*70)

# --- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ ---
@app.errorhandler(404)
def not_found_error(error):
    """404ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    return jsonify({
        'error': 'Not Found',
        'message': 'ãã®ãƒšãƒ¼ã‚¸ã¯è¦‹ã¤ã‹ã‚‰ãªã„ã‚ˆã€œ',
        'status': 404
    }), 404

@app.errorhandler(500)
def internal_error(error):
    """500ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    logger.error(f"å†…éƒ¨ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {error}")
    return jsonify({
        'error': 'Internal Server Error',
        'message': 'ã‚µãƒ¼ãƒãƒ¼ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¡ã‚ƒã£ãŸâ€¦',
        'status': 500
    }), 500

@app.errorhandler(429)
def ratelimit_handler(error):
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    return jsonify({
        'error': 'Too Many Requests',
        'message': 'ã¡ã‚‡ã£ã¨å¾…ã£ã¦ï¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¤šã™ãã‚‹ã‚ˆã€œ',
        'status': 429
    }), 429

# --- ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ ---
import signal

def signal_handler(sig, frame):
    """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆå„ªé›…ãªçµ‚äº†ï¼‰"""
    logger.info(f"ğŸ›‘ ã‚·ã‚°ãƒŠãƒ« {sig} ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™...")
    
    try:
        background_executor.shutdown(wait=True, timeout=30)
        logger.info("âœ… ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã‚’çµ‚äº†ã—ã¾ã—ãŸ")
    except Exception as e:
        logger.warning(f"âš ï¸ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯çµ‚äº†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    try:
        engine.dispose()
        logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’çµ‚äº†ã—ã¾ã—ãŸ")
    except Exception as e:
        logger.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ‚äº†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    logger.info("ğŸ‘‹ ã‚‚ã¡ã“AI ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸ")
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œï¼ˆRenderå¯¾å¿œç‰ˆï¼‰ ---
if __name__ == '__main__':
    try:
        port = int(os.environ.get('PORT', 5001))
        host = '0.0.0.0'
        debug_mode = os.environ.get('FLASK_DEBUG', 'False').lower() == 'true'
        
        log_startup_status()
        initialize_app()
        
        logger.info(f"ğŸ  ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒã§å®Ÿè¡Œã—ã¾ã™")
        logger.info(f"ğŸš€ èµ·å‹•: {host}:{port}")
        logger.info(f"ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if debug_mode else 'ç„¡åŠ¹'}")
        logger.info("="*70)
        
        app.run(host=host, port=port, debug=debug_mode, threaded=True)
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒåœæ­¢ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logger.critical(f"ğŸ”¥ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ã«å¤±æ•—: {e}")
        logger.critical("ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:", exc_info=True)
        sys.exit(1)

else:
    try:
        log_startup_status()
        initialize_app()
        logger.info("ğŸŒ WSGI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒä½œæˆã•ã‚Œã¾ã—ãŸ")
        logger.info("ğŸ¯ Gunicornã«ã‚ˆã‚‹æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ç¨¼åƒä¸­")
    except Exception as e:
        logger.critical(f"ğŸ”¥ WSGI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆã«å¤±æ•—: {e}")
        logger.critical("ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:", exc_info=True)
        raise

application = app

logger.info("ğŸ“„ ã‚‚ã¡ã“AI v14.0 ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šå®Œäº† - å…¨æ©Ÿèƒ½å®Ÿè£…ç‰ˆ")

# ============================================================
# ğŸ ãƒœãƒ¼ãƒŠã‚¹æ©Ÿèƒ½: ãƒ›ãƒ­ãƒ¡ãƒ³Wikiã¨å‹ã ã¡ç™»éŒ²ã®å®Œå…¨å®Ÿè£…
# ============================================================

# ãƒ›ãƒ­ãƒ¡ãƒ³Wikiã®è¿½åŠ ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ï¼ˆã‚ˆã‚Šå¤šãã®ãƒ›ãƒ­ãƒ¡ãƒ³ã«å¯¾å¿œï¼‰
def populate_extended_holomem_wiki():
    """æ‹¡å¼µãƒ›ãƒ­ãƒ¡ãƒ³Wikiãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥"""
    session = Session()
    try:
        # æ—¢å­˜ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ•°ã‚’ãƒã‚§ãƒƒã‚¯
        current_count = session.query(HolomemWiki).count()
        if current_count >= 10:
            logger.info(f"âœ… ãƒ›ãƒ­ãƒ¡ãƒ³Wikiã¯æ—¢ã«{current_count}ä»¶ç™»éŒ²æ¸ˆã¿")
            return
        
        # è¿½åŠ ã®ãƒ›ãƒ­ãƒ¡ãƒ³æƒ…å ±
        extended_data = [
            {
                'member_name': 'å¤§ç©ºã‚¹ãƒãƒ«',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–2æœŸç”Ÿã€‚å…ƒæ°—ã§ã‚¹ãƒãƒ¼ãƒ„ä¸‡èƒ½ã€‚ã€ŒãŠã£ã¯ã‚ˆãƒ¼ï¼ã€ãŒå£ç™–ã€‚',
                'debut_date': '2018å¹´9æœˆ16æ—¥',
                'generation': '2æœŸç”Ÿ',
                'tags': json.dumps(['ã‚¹ãƒãƒ¼ãƒ„', 'å…ƒæ°—', 'ã‚²ãƒ¼ãƒ '], ensure_ascii=False)
            },
            {
                'member_name': 'å¤§ç¥ãƒŸã‚ª',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã‚²ãƒ¼ãƒãƒ¼ã‚ºã€‚åŒ…å®¹åŠ›ã®ã‚ã‚‹ãŠå§‰ã•ã‚“ç³»VTuberã€‚',
                'debut_date': '2018å¹´12æœˆ7æ—¥',
                'generation': 'ã‚²ãƒ¼ãƒãƒ¼ã‚º',
                'tags': json.dumps(['ãŠå§‰ã•ã‚“', 'ç™’ã—', 'ã‚²ãƒ¼ãƒ '], ensure_ascii=False)
            },
            {
                'member_name': 'æˆŒç¥ã“ã‚ã­',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã‚²ãƒ¼ãƒãƒ¼ã‚ºã€‚çŠ¬ç³»VTuberã€‚ãƒ¬ãƒˆãƒ­ã‚²ãƒ¼ãƒ ãŒå¤§å¥½ãã€‚',
                'debut_date': '2019å¹´10æœˆ5æ—¥',
                'generation': 'ã‚²ãƒ¼ãƒãƒ¼ã‚º',
                'tags': json.dumps(['çŠ¬', 'ãƒ¬ãƒˆãƒ­ã‚²ãƒ¼ãƒ ', 'æŒ‡'], ensure_ascii=False)
            },
            {
                'member_name': 'çŒ«åˆãŠã‹ã‚†',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã‚²ãƒ¼ãƒãƒ¼ã‚ºã€‚çŒ«ç³»VTuberã€‚ãŠã«ãã‚ŠãŒå¤§å¥½ãã€‚',
                'debut_date': '2019å¹´4æœˆ6æ—¥',
                'generation': 'ã‚²ãƒ¼ãƒãƒ¼ã‚º',
                'tags': json.dumps(['çŒ«', 'ãŠã«ãã‚Š', 'ã‚²ãƒ¼ãƒ '], ensure_ascii=False)
            },
            {
                'member_name': 'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–3æœŸç”Ÿã€‚ã‚¨ãƒ«ãƒ•ã®å§«æ§˜ã€‚Minecraftã®å»ºç¯‰ãŒå¾—æ„ã€‚',
                'debut_date': '2019å¹´8æœˆ7æ—¥',
                'generation': '3æœŸç”Ÿ',
                'tags': json.dumps(['ã‚¨ãƒ«ãƒ•', 'ãƒã‚¤ã‚¯ãƒ©', 'å»ºç¯‰'], ensure_ascii=False)
            },
            {
                'member_name': 'ç™½éŠ€ãƒã‚¨ãƒ«',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–3æœŸç”Ÿã€‚é¨å£«å›£é•·ã€‚ASMRã¨æ­ŒãŒäººæ°—ã€‚',
                'debut_date': '2019å¹´8æœˆ8æ—¥',
                'generation': '3æœŸç”Ÿ',
                'tags': json.dumps(['é¨å£«', 'ASMR', 'æ­Œ'], ensure_ascii=False)
            },
            {
                'member_name': 'æ˜Ÿè¡—ã™ã„ã›ã„',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–0æœŸç”Ÿã€‚æ­Œã¨ãƒ†ãƒˆãƒªã‚¹ãŒå¾—æ„ãªã‚¢ã‚¤ãƒ‰ãƒ«ç³»VTuberã€‚',
                'debut_date': '2018å¹´3æœˆ22æ—¥',
                'generation': '0æœŸç”Ÿ',
                'tags': json.dumps(['æ­Œ', 'ã‚¢ã‚¤ãƒ‰ãƒ«', 'ãƒ†ãƒˆãƒªã‚¹'], ensure_ascii=False)
            },
            {
                'member_name': 'AZKi',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–0æœŸç”Ÿã€‚éŸ³æ¥½ã«ç‰¹åŒ–ã—ãŸVTuberã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«æ›²å¤šæ•°ã€‚',
                'debut_date': '2018å¹´11æœˆ15æ—¥',
                'generation': '0æœŸç”Ÿ',
                'tags': json.dumps(['éŸ³æ¥½', 'ã‚ªãƒªã‚¸ãƒŠãƒ«æ›²', 'æ­Œ'], ensure_ascii=False)
            },
            {
                'member_name': 'å¤©éŸ³ã‹ãªãŸ',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–4æœŸç”Ÿã€‚å¤©ä½¿ç³»VTuberã€‚ã‚´ãƒªãƒ©ä¸¦ã¿ã®æ¡åŠ›ã‚’æŒã¤ã€‚',
                'debut_date': '2019å¹´12æœˆ27æ—¥',
                'generation': '4æœŸç”Ÿ',
                'tags': json.dumps(['å¤©ä½¿', 'ã‚´ãƒªãƒ©', 'æ­Œ'], ensure_ascii=False)
            },
            {
                'member_name': 'è§’å·»ã‚ãŸã‚',
                'description': 'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–4æœŸç”Ÿã€‚ç¾Šç³»VTuberã€‚ã€Œã‚ãŸã‚ã‡...ã€ãŒå£ç™–ã€‚',
                'debut_date': '2019å¹´12æœˆ29æ—¥',
                'generation': '4æœŸç”Ÿ',
                'tags': json.dumps(['ç¾Š', 'æ­Œ', 'ã‹ã‚ã„ã„'], ensure_ascii=False)
            }
        ]
        
        added_count = 0
        for data in extended_data:
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing = session.query(HolomemWiki).filter_by(member_name=data['member_name']).first()
            if not existing:
                wiki_entry = HolomemWiki(**data)
                session.add(wiki_entry)
                added_count += 1
        
        if added_count > 0:
            session.commit()
            logger.info(f"âœ… ãƒ›ãƒ­ãƒ¡ãƒ³Wikiæ‹¡å¼µå®Œäº†: {added_count}åè¿½åŠ  (åˆè¨ˆ: {current_count + added_count}å)")
        
    except Exception as e:
        logger.error(f"âŒ ãƒ›ãƒ­ãƒ¡ãƒ³Wikiæ‹¡å¼µã‚¨ãƒ©ãƒ¼: {e}")
        session.rollback()
    finally:
        session.close()

# ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚‚æŠ•å…¥
def initialize_app_extended():
    """æ‹¡å¼µç‰ˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–"""
    try:
        logger.info("ğŸ”§ æ‹¡å¼µã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã‚’é–‹å§‹...")
        
        # åŸºæœ¬åˆæœŸåŒ–
        initialize_holomem_wiki()
        
        # æ‹¡å¼µãƒ›ãƒ­ãƒ¡ãƒ³Wikiãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥
        populate_extended_holomem_wiki()
        
        # åˆæœŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯
        check_and_populate_initial_news()
        
        def run_schedule():
            while True:
                try:
                    schedule.run_pending()
                    time.sleep(60)
                except Exception as e:
                    logger.error(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
                    time.sleep(60)
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®šï¼ˆæ‹¡å¼µç‰ˆï¼‰
        schedule.every().hour.do(update_hololive_news_database)
        schedule.every(3).hours.do(update_all_specialized_news)
        schedule.every().day.at("02:00").do(cleanup_old_data_advanced)
        schedule.every().week.do(populate_extended_holomem_wiki)  # é€±1å›Wikiæ›´æ–°ãƒã‚§ãƒƒã‚¯
        
        scheduler_thread = threading.Thread(target=run_schedule, daemon=True)
        scheduler_thread.start()
        logger.info("â° æ‹¡å¼µã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        
        logger.info("âœ… æ‹¡å¼µã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–å®Œäº†")
        
    except Exception as e:
        logger.error(f"âŒ æ‹¡å¼µã‚¢ãƒ—ãƒªåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

# initialize_app ã‚’ initialize_app_extended ã§ç½®ãæ›ãˆ
# ï¼ˆå…ƒã®é–¢æ•°ã¯ä¿æŒã—ãŸã¾ã¾ã€èµ·å‹•æ™‚ã¯æ‹¡å¼µç‰ˆã‚’ä½¿ç”¨ï¼‰
